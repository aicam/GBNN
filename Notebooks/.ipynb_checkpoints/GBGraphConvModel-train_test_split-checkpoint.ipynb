{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Installing RDKit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add /home/ali/miniconda/lib/python3.8/site-packages to PYTHONPATH\n",
      "all packages are already installed\n"
     ]
    }
   ],
   "source": [
    "# !curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
    "import conda_installer\n",
    "# conda_installer.install()\n",
    "conda_installer.install()\n",
    "# !/root/miniconda/bin/conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 07:21:39.456029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-26 07:21:39.456046: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/molecule_parameters_final.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex-name</th>\n",
       "      <th>gb-complex-etot</th>\n",
       "      <th>gb-complex-1-4-eel</th>\n",
       "      <th>gb-complex-eelec</th>\n",
       "      <th>gb-complex-egb</th>\n",
       "      <th>gb-complex-esurf</th>\n",
       "      <th>gb-protein-etot</th>\n",
       "      <th>gb-protein-1-4-eel</th>\n",
       "      <th>gb-protein-eelect</th>\n",
       "      <th>gb-protein-egb</th>\n",
       "      <th>...</th>\n",
       "      <th>pb-protein-vdwaals</th>\n",
       "      <th>pb-protein-eelec</th>\n",
       "      <th>pb-protein-epb</th>\n",
       "      <th>pb-protein-ecavity</th>\n",
       "      <th>pb-ligand-etot</th>\n",
       "      <th>pb-ligand-vdwaals</th>\n",
       "      <th>pb-ligand-eelec</th>\n",
       "      <th>pb-ligand-epb</th>\n",
       "      <th>pb-ligand-ecavity</th>\n",
       "      <th>ddg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10gs</td>\n",
       "      <td>-16145.9190</td>\n",
       "      <td>18478.8142</td>\n",
       "      <td>-31052.1742</td>\n",
       "      <td>-3659.4630</td>\n",
       "      <td>86.9041</td>\n",
       "      <td>-16042.9095</td>\n",
       "      <td>18034.9833</td>\n",
       "      <td>-30493.1722</td>\n",
       "      <td>-3672.7126</td>\n",
       "      <td>...</td>\n",
       "      <td>-4077.8698</td>\n",
       "      <td>-30493.1722</td>\n",
       "      <td>-3650.6491</td>\n",
       "      <td>87.9920</td>\n",
       "      <td>-565.1881</td>\n",
       "      <td>-10.1928</td>\n",
       "      <td>-416.8647</td>\n",
       "      <td>-141.8681</td>\n",
       "      <td>3.7375</td>\n",
       "      <td>-8.841927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a1e</td>\n",
       "      <td>-9777.1684</td>\n",
       "      <td>7030.7012</td>\n",
       "      <td>-13515.0036</td>\n",
       "      <td>-3349.3791</td>\n",
       "      <td>56.5130</td>\n",
       "      <td>-9499.3955</td>\n",
       "      <td>7189.5223</td>\n",
       "      <td>-13366.9577</td>\n",
       "      <td>-3378.1703</td>\n",
       "      <td>...</td>\n",
       "      <td>-1901.0486</td>\n",
       "      <td>-13366.9577</td>\n",
       "      <td>-3333.0961</td>\n",
       "      <td>56.2103</td>\n",
       "      <td>-173.5190</td>\n",
       "      <td>-11.4008</td>\n",
       "      <td>-96.6715</td>\n",
       "      <td>-69.9064</td>\n",
       "      <td>4.4598</td>\n",
       "      <td>-8.289306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a30</td>\n",
       "      <td>-6925.5462</td>\n",
       "      <td>9349.4510</td>\n",
       "      <td>-14111.7670</td>\n",
       "      <td>-2211.3839</td>\n",
       "      <td>48.1538</td>\n",
       "      <td>-6881.3365</td>\n",
       "      <td>8949.8465</td>\n",
       "      <td>-13675.6929</td>\n",
       "      <td>-2204.7807</td>\n",
       "      <td>...</td>\n",
       "      <td>-1777.0400</td>\n",
       "      <td>-13675.6929</td>\n",
       "      <td>-2179.8309</td>\n",
       "      <td>49.2906</td>\n",
       "      <td>-645.4443</td>\n",
       "      <td>-9.3186</td>\n",
       "      <td>-381.1129</td>\n",
       "      <td>-257.9893</td>\n",
       "      <td>2.9765</td>\n",
       "      <td>-5.940670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a4k</td>\n",
       "      <td>-29413.8956</td>\n",
       "      <td>40100.7078</td>\n",
       "      <td>-61088.2896</td>\n",
       "      <td>-8626.6708</td>\n",
       "      <td>200.3571</td>\n",
       "      <td>-29189.9201</td>\n",
       "      <td>40319.8406</td>\n",
       "      <td>-60991.3946</td>\n",
       "      <td>-8719.3884</td>\n",
       "      <td>...</td>\n",
       "      <td>-1084.3398</td>\n",
       "      <td>-60991.3946</td>\n",
       "      <td>-8730.0602</td>\n",
       "      <td>201.0222</td>\n",
       "      <td>-27.4572</td>\n",
       "      <td>-6.0182</td>\n",
       "      <td>74.3491</td>\n",
       "      <td>-99.2366</td>\n",
       "      <td>3.4485</td>\n",
       "      <td>-11.052408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4r</td>\n",
       "      <td>-14436.7381</td>\n",
       "      <td>16726.9825</td>\n",
       "      <td>-26744.9283</td>\n",
       "      <td>-4516.3615</td>\n",
       "      <td>97.5691</td>\n",
       "      <td>-13647.6149</td>\n",
       "      <td>18021.0326</td>\n",
       "      <td>-27237.1053</td>\n",
       "      <td>-4529.6519</td>\n",
       "      <td>...</td>\n",
       "      <td>-1733.7572</td>\n",
       "      <td>-27237.1053</td>\n",
       "      <td>-4478.1330</td>\n",
       "      <td>98.1097</td>\n",
       "      <td>486.8763</td>\n",
       "      <td>-5.8718</td>\n",
       "      <td>583.2385</td>\n",
       "      <td>-93.5441</td>\n",
       "      <td>3.0538</td>\n",
       "      <td>-9.201130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>7std</td>\n",
       "      <td>-20699.0549</td>\n",
       "      <td>21176.0749</td>\n",
       "      <td>-35706.5273</td>\n",
       "      <td>-6267.2953</td>\n",
       "      <td>98.6928</td>\n",
       "      <td>-20681.1007</td>\n",
       "      <td>21209.5397</td>\n",
       "      <td>-35704.9166</td>\n",
       "      <td>-6285.3439</td>\n",
       "      <td>...</td>\n",
       "      <td>-5167.3253</td>\n",
       "      <td>-35704.9166</td>\n",
       "      <td>-6203.5215</td>\n",
       "      <td>99.6200</td>\n",
       "      <td>-14.5959</td>\n",
       "      <td>-4.6906</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>-12.7624</td>\n",
       "      <td>2.7350</td>\n",
       "      <td>-14.810227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>7upj</td>\n",
       "      <td>-7203.9558</td>\n",
       "      <td>8347.2909</td>\n",
       "      <td>-13713.5975</td>\n",
       "      <td>-1887.4373</td>\n",
       "      <td>49.7881</td>\n",
       "      <td>-7088.4059</td>\n",
       "      <td>8615.8940</td>\n",
       "      <td>-13766.9993</td>\n",
       "      <td>-1988.7703</td>\n",
       "      <td>...</td>\n",
       "      <td>-1672.4526</td>\n",
       "      <td>-13766.9993</td>\n",
       "      <td>-1966.3313</td>\n",
       "      <td>51.4697</td>\n",
       "      <td>66.5143</td>\n",
       "      <td>-7.2150</td>\n",
       "      <td>102.8524</td>\n",
       "      <td>-32.7172</td>\n",
       "      <td>3.5941</td>\n",
       "      <td>-11.729368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>8a3h</td>\n",
       "      <td>-11311.9593</td>\n",
       "      <td>14514.5548</td>\n",
       "      <td>-17122.3046</td>\n",
       "      <td>-8760.1462</td>\n",
       "      <td>55.9367</td>\n",
       "      <td>-11349.4465</td>\n",
       "      <td>14306.8313</td>\n",
       "      <td>-16401.8897</td>\n",
       "      <td>-9310.9686</td>\n",
       "      <td>...</td>\n",
       "      <td>-3055.0110</td>\n",
       "      <td>-16401.8897</td>\n",
       "      <td>-9229.1824</td>\n",
       "      <td>56.5806</td>\n",
       "      <td>-199.9330</td>\n",
       "      <td>-6.2099</td>\n",
       "      <td>-84.0375</td>\n",
       "      <td>-112.4157</td>\n",
       "      <td>2.7302</td>\n",
       "      <td>-5.609097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>8cpa</td>\n",
       "      <td>-10896.0768</td>\n",
       "      <td>13847.1770</td>\n",
       "      <td>-22434.5575</td>\n",
       "      <td>-2366.9434</td>\n",
       "      <td>58.2471</td>\n",
       "      <td>-10848.4034</td>\n",
       "      <td>13472.1409</td>\n",
       "      <td>-21904.4816</td>\n",
       "      <td>-2475.0882</td>\n",
       "      <td>...</td>\n",
       "      <td>-2292.8024</td>\n",
       "      <td>-21904.4816</td>\n",
       "      <td>-2442.5401</td>\n",
       "      <td>59.0256</td>\n",
       "      <td>-544.4429</td>\n",
       "      <td>-8.5007</td>\n",
       "      <td>-439.7892</td>\n",
       "      <td>-99.9047</td>\n",
       "      <td>3.7517</td>\n",
       "      <td>-12.641192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>966c</td>\n",
       "      <td>-6118.8907</td>\n",
       "      <td>6310.2596</td>\n",
       "      <td>-9039.2312</td>\n",
       "      <td>-3431.0677</td>\n",
       "      <td>41.1486</td>\n",
       "      <td>-6153.6352</td>\n",
       "      <td>6133.6566</td>\n",
       "      <td>-8847.2589</td>\n",
       "      <td>-3481.9968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1385.5069</td>\n",
       "      <td>-8847.2589</td>\n",
       "      <td>-3429.8390</td>\n",
       "      <td>41.9639</td>\n",
       "      <td>-206.1268</td>\n",
       "      <td>-5.0006</td>\n",
       "      <td>-166.0323</td>\n",
       "      <td>-38.1590</td>\n",
       "      <td>3.0651</td>\n",
       "      <td>-10.555050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2735 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     complex-name  gb-complex-etot  gb-complex-1-4-eel  gb-complex-eelec  \\\n",
       "0            10gs      -16145.9190          18478.8142       -31052.1742   \n",
       "1            1a1e       -9777.1684           7030.7012       -13515.0036   \n",
       "2            1a30       -6925.5462           9349.4510       -14111.7670   \n",
       "3            1a4k      -29413.8956          40100.7078       -61088.2896   \n",
       "4            1a4r      -14436.7381          16726.9825       -26744.9283   \n",
       "...           ...              ...                 ...               ...   \n",
       "2909         7std      -20699.0549          21176.0749       -35706.5273   \n",
       "2910         7upj       -7203.9558           8347.2909       -13713.5975   \n",
       "2911         8a3h      -11311.9593          14514.5548       -17122.3046   \n",
       "2912         8cpa      -10896.0768          13847.1770       -22434.5575   \n",
       "2913         966c       -6118.8907           6310.2596        -9039.2312   \n",
       "\n",
       "      gb-complex-egb  gb-complex-esurf  gb-protein-etot  gb-protein-1-4-eel  \\\n",
       "0         -3659.4630           86.9041      -16042.9095          18034.9833   \n",
       "1         -3349.3791           56.5130       -9499.3955           7189.5223   \n",
       "2         -2211.3839           48.1538       -6881.3365           8949.8465   \n",
       "3         -8626.6708          200.3571      -29189.9201          40319.8406   \n",
       "4         -4516.3615           97.5691      -13647.6149          18021.0326   \n",
       "...              ...               ...              ...                 ...   \n",
       "2909      -6267.2953           98.6928      -20681.1007          21209.5397   \n",
       "2910      -1887.4373           49.7881       -7088.4059           8615.8940   \n",
       "2911      -8760.1462           55.9367      -11349.4465          14306.8313   \n",
       "2912      -2366.9434           58.2471      -10848.4034          13472.1409   \n",
       "2913      -3431.0677           41.1486       -6153.6352           6133.6566   \n",
       "\n",
       "      gb-protein-eelect  gb-protein-egb  ...  pb-protein-vdwaals  \\\n",
       "0           -30493.1722      -3672.7126  ...          -4077.8698   \n",
       "1           -13366.9577      -3378.1703  ...          -1901.0486   \n",
       "2           -13675.6929      -2204.7807  ...          -1777.0400   \n",
       "3           -60991.3946      -8719.3884  ...          -1084.3398   \n",
       "4           -27237.1053      -4529.6519  ...          -1733.7572   \n",
       "...                 ...             ...  ...                 ...   \n",
       "2909        -35704.9166      -6285.3439  ...          -5167.3253   \n",
       "2910        -13766.9993      -1988.7703  ...          -1672.4526   \n",
       "2911        -16401.8897      -9310.9686  ...          -3055.0110   \n",
       "2912        -21904.4816      -2475.0882  ...          -2292.8024   \n",
       "2913         -8847.2589      -3481.9968  ...          -1385.5069   \n",
       "\n",
       "      pb-protein-eelec  pb-protein-epb  pb-protein-ecavity  pb-ligand-etot  \\\n",
       "0          -30493.1722      -3650.6491             87.9920       -565.1881   \n",
       "1          -13366.9577      -3333.0961             56.2103       -173.5190   \n",
       "2          -13675.6929      -2179.8309             49.2906       -645.4443   \n",
       "3          -60991.3946      -8730.0602            201.0222        -27.4572   \n",
       "4          -27237.1053      -4478.1330             98.1097        486.8763   \n",
       "...                ...             ...                 ...             ...   \n",
       "2909       -35704.9166      -6203.5215             99.6200        -14.5959   \n",
       "2910       -13766.9993      -1966.3313             51.4697         66.5143   \n",
       "2911       -16401.8897      -9229.1824             56.5806       -199.9330   \n",
       "2912       -21904.4816      -2442.5401             59.0256       -544.4429   \n",
       "2913        -8847.2589      -3429.8390             41.9639       -206.1268   \n",
       "\n",
       "      pb-ligand-vdwaals  pb-ligand-eelec  pb-ligand-epb  pb-ligand-ecavity  \\\n",
       "0              -10.1928        -416.8647      -141.8681             3.7375   \n",
       "1              -11.4008         -96.6715       -69.9064             4.4598   \n",
       "2               -9.3186        -381.1129      -257.9893             2.9765   \n",
       "3               -6.0182          74.3491       -99.2366             3.4485   \n",
       "4               -5.8718         583.2385       -93.5441             3.0538   \n",
       "...                 ...              ...            ...                ...   \n",
       "2909            -4.6906           0.1221       -12.7624             2.7350   \n",
       "2910            -7.2150         102.8524       -32.7172             3.5941   \n",
       "2911            -6.2099         -84.0375      -112.4157             2.7302   \n",
       "2912            -8.5007        -439.7892       -99.9047             3.7517   \n",
       "2913            -5.0006        -166.0323       -38.1590             3.0651   \n",
       "\n",
       "            ddg  \n",
       "0     -8.841927  \n",
       "1     -8.289306  \n",
       "2     -5.940670  \n",
       "3    -11.052408  \n",
       "4     -9.201130  \n",
       "...         ...  \n",
       "2909 -14.810227  \n",
       "2910 -11.729368  \n",
       "2911  -5.609097  \n",
       "2912 -12.641192  \n",
       "2913 -10.555050  \n",
       "\n",
       "[2735 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [col for col in df.columns if (col[:3] == 'gb-' and not col.__contains__('etot')) or (col.__contains__('vdwaals'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading Mobley PDB files</h1>\n",
    "<p>Here each PDB file will be read and saved in Mol data type defined in RDKit and used by DeepChem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDBs = {}\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# mypath = '../Datasets/pdb-test/'\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# for f in onlyfiles:\n",
    "#     PDBs.update({f.split('.')[0] : rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + '/' + f)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save PDB\n",
    "# import pickle\n",
    "# with open('PDBs.pkl', 'wb') as file:\n",
    "#     pickle.dump(PDBs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load PDB\n",
    "import pickle\n",
    "PDBs = {}\n",
    "with open('PDBs.pkl', 'rb') as file:\n",
    "    PDBs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Featurizing</h1>\n",
    "<p>GraphConv model needs ConvMolFeaturizer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "TRAIN_SET = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_ids = []\n",
    "# one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "for k in PDBs.keys():\n",
    "    X_ids.append(k)\n",
    "    X.append(featurizer.featurize(PDBs[k]))\n",
    "split_index = int(len(X) * TRAIN_SET)\n",
    "X = [x[0] for x in X]\n",
    "X_train_featurized = X[:split_index]\n",
    "X_test_featurized = X[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_names = [i for i in X_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_names_train = pdb_names[:split_index]\n",
    "pdb_names_test = pdb_names[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_add_train, x_add_test, y_train, y_test = [], [], [], []\n",
    "for i in range(len(pdb_names_train)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "    y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_train.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_train = np.array(y_train)\n",
    "    \n",
    "for i in range(len(pdb_names_test)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "#     print(pdb_names_test[i])\n",
    "#     print(new_df['ddg'].to_numpy())\n",
    "    y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_test.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "x_preprocessed_train, x_preprocessed_test = [], []\n",
    "\n",
    "## for X train\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "## for X test\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_test.append(np.array(x_add_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a compatible input\n",
    "x_c2 = []\n",
    "all_data_input_shapes = []\n",
    "for i in range(len(x_add_train)):\n",
    "    multiConvMol = ConvMol.agglomerate_mols([X_train_featurized[i]])\n",
    "    x_int = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_int.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_int.append(np.array(x_add_train[i]))\n",
    "    all_data_input_shapes.append([list(e.shape) for e in x_int])\n",
    "    x_c2.append(x_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c3 = []\n",
    "for x_p in x_c2:\n",
    "    x_train = np.full([14, np.max([v.shape[0] for v in x_p]),\n",
    "                      np.max([v.shape[1] for v in x_p if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_p):\n",
    "        if len(j.shape) > 1:\n",
    "            x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "#     x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "    x_c3.append(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.full([14, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_train):\n",
    "    if len(j.shape) > 1:\n",
    "        x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "x_test = np.full([14, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_test):\n",
    "    if len(j.shape) > 1:\n",
    "        x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_test = x_test.reshape([1] + list(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-417.71807647]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0.5],\n",
    " [-0.996837735],\n",
    " [-1.00316226],\n",
    " [-1.00316226],\n",
    " [-0.996837735],\n",
    " [1.00316226],\n",
    " [0.996837735],\n",
    " [0.996837735],\n",
    " [1.00316226],\n",
    " [1.00316226],\n",
    " [0.996837735],\n",
    " [0.996837735],\n",
    " [1.00316226],\n",
    " [-1.00316226],\n",
    " [0.996837735],\n",
    " [0.996837735]]).reshape([1, 16])\n",
    "b = np.array([0, \n",
    "              -22429.1641,\n",
    "              31704.5664,\n",
    "              6376.16797,\n",
    "              -98.806,\n",
    "              -22328.2461,\n",
    "              31535.8613,\n",
    "              6404.65771,\n",
    "              -99.1117,\n",
    "              -100.9188,\n",
    "              120.542702,\n",
    "              40.4809,\n",
    "              -2.0526,\n",
    "              4539.74316,\n",
    "              4513.25146,\n",
    "              2.3544]).reshape([16, 1])\n",
    "np.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.688158]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0.5],\n",
    " [1],\n",
    " [1],\n",
    " [1],\n",
    " [1],\n",
    " [-1],\n",
    " [-1],\n",
    " [-1],\n",
    " [-1],\n",
    " [-1],\n",
    " [-1],\n",
    " [-1],\n",
    " [-1],\n",
    " [1],\n",
    " [-1],\n",
    " [-1]]).reshape([1, 16])\n",
    "np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 07:39:05.821564: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-02-26 07:39:05.821631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ali-09212982058): /proc/driver/nvidia/version does not exist\n",
      "2022-02-26 07:39:05.822529: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def __init__(self, batch_size):\n",
    "    super(GBGraphConvModel, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(64, activation=tf.nn.sigmoid)\n",
    "    self.dense3 = layers.Dense(1)\n",
    "    self.dense4 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([.5, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1]),\n",
    "         bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     x_feat, x_add = inputs[0], inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 15])\n",
    "\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    model_var = self.dense3(model_var)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    ddg = self.dense4(binding_affinity)\n",
    "    tf.print(self.dense4.weights, output_stream=\"file://weights.txt\", summarize=30)\n",
    "    tf.print(binding_affinity[0], output_stream=\"file://binding_a.txt\", summarize=30)\n",
    "    tf.print(ddg[0], output_stream=\"file://ddg.txt\")\n",
    "    tf.print(model_var, output_stream=\"file://model_var.txt\", summarize=30)\n",
    "    tf.print(\"-------------------------\", output_stream=sys.stdout)\n",
    "    return ddg\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "model = GBGraphConvModel(split_index)\n",
    "model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
    "K.set_value(model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.9933\n",
      "Epoch 2/3\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.9933\n",
      "Epoch 3/3\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.9933\n"
     ]
    }
   ],
   "source": [
    "model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148767.0008"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['gb-complex-1-4-eel'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "model.modify_graphgather(len(X) - split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.496837735]\n",
      " [1.00316226]\n",
      " [0.996837735]\n",
      " ...\n",
      " [0.996837735]\n",
      " [-1.00316226]\n",
      " [-1.00316226]], [-0.0031622753]]\n",
      "[0.650298357 -16127.6348 19940.8438 ... 2215.14038 2134.90894 13.8664]\n",
      "[0]\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 9.0176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.017557144165039"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test.reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.220932405998316"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(38.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f474a0e0cc0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'dataset group name', 'Dataset Name', 'Host', 'Guest',\n",
       "       'Ex _G_(kcal/mol)', 'Ex _G_SEM', 'EX _H_(kcal/mol)', 'EX _H_SEM',\n",
       "       'pb_guest_Etot', 'pb_guest_VDWAALS', 'pb_guest_EELEC', 'pb_guest_EPB',\n",
       "       'pb_guest_ECAVITY', 'pb_host_Etot', 'pb_host_VDWAALS', 'pb_host_EELEC',\n",
       "       'pb_host_EPB', 'pb_host_ECAVITY', 'pb_complex_Etot',\n",
       "       'pb_complex_VDWAALS', 'pb_complex_EELEC', 'pb_complex_EPB',\n",
       "       'pb_complex_ECAVITY', 'gb_Complex_Etot', 'gb_Complex_1-4EEL',\n",
       "       'gb_Complex_EELEC', 'gb_Complex_EGB', 'gb_Complex_ESURF',\n",
       "       'gb_guest_Etot', 'gb_guest_1-4EEL', 'gb_guest_EELEC', 'gb_guest_EGB',\n",
       "       'gb_guest_ESURF', 'gb_host_Etot', 'gb_host_1-4EEL', 'gb_host_EELEC',\n",
       "       'gb_host_EGB', 'gb_host_ESURF', 'gb_delta_H', 'pb_delta_H',\n",
       "       'EX _delta_H_(kcal/mol)', 'gb_Ex_difference',\n",
       "       'SQR_gbnsr6_Ex_difference', 'pb_Ex_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.485930943559929"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((df['EX _H_(kcal/mol)'].to_numpy() - df['gb_delta_H'].to_numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6500000000000004"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8.48 - 5.83)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
