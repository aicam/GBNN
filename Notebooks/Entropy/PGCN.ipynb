{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b398ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 19:51:26.252442: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-02 19:51:26.469763: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-02 19:51:26.472339: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-02 19:51:27.470903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#ante-MMPBSA.py -p 0.15_80_10_pH7.5_6m0j_trunc_final.top -r ACE2_dry_trunc.prmtop -l SARS-CoV-2-spike_dry_trunc.prmtop -m :1-339\n",
    "# WARNING: -m is recepter residue number not atom number\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import conda_installer\n",
    "from rdkit import Chem\n",
    "from deepchem.feat.graph_features import atom_features as get_atom_features\n",
    "import rdkit\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9af576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs = pickle.load(open('PDBs_RDKit.pkl', 'rb'))\n",
    "PDBs_BRD4 = pickle.load(open('PDBs_BRD4.pkl', 'rb'))\n",
    "df = pd.read_csv('T_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07cd29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ali/GBNN/PGGCN\n"
     ]
    }
   ],
   "source": [
    "%cd ../../PGGCN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3e9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "for pdb in list(PDBs.keys()):\n",
    "    info.append(df[df['Id'] == pdb][['TS_comp', 'TS_host', 'TS_ligand']].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1c5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dcFeaturizer import atom_features as get_atom_features\n",
    "def featurize(molecule, info):\n",
    "    \n",
    "    atom_features = []\n",
    "    for atom in molecule.GetAtoms():\n",
    "        new_feature = get_atom_features(atom).tolist()\n",
    "        position = molecule.GetConformer().GetAtomPosition(atom.GetIdx())\n",
    "        new_feature += [atom.GetMass(), atom.GetAtomicNum()]\n",
    "        new_feature += [position.x, position.y, position.z]\n",
    "        for neighbor in atom.GetNeighbors()[:2]:\n",
    "            neighbor_idx = neighbor.GetIdx()\n",
    "            new_feature += [neighbor_idx]\n",
    "        for i in range(2 - len(atom.GetNeighbors())):\n",
    "            new_feature += [-1]\n",
    "        atom_features.append(np.concatenate([new_feature, info], 0))\n",
    "    return np.array(atom_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6e0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i, pdb in enumerate(list(PDBs.keys())):\n",
    "    X.append(featurize(PDBs[pdb], info[i]))\n",
    "    y.append(df[df['Id'] == pdb]['exp'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d57538-5ffc-4df1-9a79-fcaffd3d37b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 41)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b36fc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_brd4 = []\n",
    "y_brd4 = []\n",
    "info_brd4 = []\n",
    "for i,pdb in enumerate(list(PDBs_BRD4.keys())):\n",
    "    info_brd4.append(df[df['Id'] == pdb][['TS_comp', 'TS_host', 'TS_ligand']].to_numpy()[0])\n",
    "for i,pdb in enumerate(list(PDBs_BRD4.keys())):\n",
    "    X_brd4.append(featurize(PDBs_BRD4[pdb], info_brd4[i]))\n",
    "    y_brd4.append(df[df['Id'] == pdb]['exp'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8dca819",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X, y\n",
    "info_train = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac98d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = X.copy()\n",
    "y_c = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "981c3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a7111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 20:40:57.037924: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 20:40:57.279448: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26568000 exceeds 10% of free system memory.\n",
      "2023-08-02 20:42:22.474766: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26568000 exceeds 10% of free system memory.\n",
      "2023-08-02 20:42:22.475084: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26568000 exceeds 10% of free system memory.\n",
      "2023-08-02 20:42:22.477393: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26568000 exceeds 10% of free system memory.\n",
      "2023-08-02 20:42:22.477508: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26568000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 86s 86s/step - loss: 2.1296\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.1279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 2.1263\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 2.1246\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 2.1230\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 2.1214\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 2.1197\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 2.1181\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 2.1165\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 2.1149\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 2.1133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 2.1117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 2.1101\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 2.1085\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 2.1069\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 2.1054\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 2.1038\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 2.1023\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 2.1007\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 2.0992\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 2.0977\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 2.0962\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 2.0947\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 2.0932\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 2.0917\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 2.0903\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 2.0888\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 2.0874\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 2.0860\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 2.0846\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 2.0832\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 2.0818\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 2.0804\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 2.0790\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 2.0777\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 2.0764\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 2.0751\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 2.0738\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 2.0725\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 2.0713\n"
     ]
    }
   ],
   "source": [
    "import models.layers_update_mobley as layers\n",
    "import importlib\n",
    "# import tensorflow_addons as tfa\n",
    "importlib.reload(layers)\n",
    "\n",
    "\n",
    "class PGGCNModel(tf.keras.Model):\n",
    "    def __init__(self, num_atom_features = 36, r_out_channel = 20, c_out_channel = 128):\n",
    "        super().__init__()\n",
    "        self.ruleGraphConvLayer = layers.RuleGraphConvLayer(r_out_channel, num_atom_features, 0)\n",
    "        self.ruleGraphConvLayer.combination_rules = []\n",
    "        self.conv = layers.ConvLayer(c_out_channel)\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1')\n",
    "#         self.dense2 = tf.keras.layers.Dense(32, activation='sigmoid')\n",
    "#         self.dense3 = tf.keras.layers.Dense(100, activation='relu')\n",
    "#         self.dense4 = tf.keras.layers.Dense(80, activation='relu')\n",
    "        self.dense5 = tf.keras.layers.Dense(16, name='relu')\n",
    "        self.dense6 = tf.keras.layers.Dense(1, name='dense6')\n",
    "#         self.dense7 = tf.keras.layers.Dense(1, name='dense7',\n",
    "#                  kernel_initializer=tf.keras.initializers.Constant([-.2, -1, 1, 1]),\n",
    "#                  bias_initializer=tf.keras.initializers.Zeros())\n",
    "        self.all_layer_1_weights = []\n",
    "        \n",
    "    def addRule(self, rule, start_index, end_index = None):\n",
    "        self.ruleGraphConvLayer.addRule(rule, start_index, end_index)\n",
    "    \n",
    "    def set_input_shapes(self, i_s):\n",
    "        self.i_s = i_s\n",
    "\n",
    "    def call(self, inputs):\n",
    "        physics_info = inputs[:,0,38:]\n",
    "        x_a = []\n",
    "        for i in range(len(self.i_s)):\n",
    "            x_a.append(inputs[i][:self.i_s[i], :38])\n",
    "#         agg = []\n",
    "#         for i in range(len(x_a)):\n",
    "#             agg.append([x_a[i], self.a_l[i]])\n",
    "        x = self.ruleGraphConvLayer(x_a)\n",
    "        self.all_layer_1_weights.append(self.ruleGraphConvLayer.w_s)\n",
    "        x = self.conv(x)\n",
    "        x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dense3(x)\n",
    "#         x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        model_var = self.dense6(x)\n",
    "#         merged = tf.concat([model_var, physics_info], axis=1)\n",
    "#         out = self.dense7(merged)\n",
    "        return model_var\n",
    "\n",
    "m = PGGCNModel()\n",
    "m.addRule(\"sum\", 0, 31)\n",
    "m.addRule(\"multiply\", 31, 33)\n",
    "m.addRule(\"distance\", 33, 36)\n",
    "\n",
    "import keras.backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred[0] - y_true))) + K.abs(1 / K.mean(.2 + y_pred[1]))\n",
    "def pure_rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "\n",
    "# optimizers = [\n",
    "#     tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "#     tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "# ]\n",
    "# optimizers_and_layers = [(optimizers[0], m.layers[:len(m.layers) - 1]), \n",
    "#                          (optimizers[1], m.layers[len(m.layers) - 1])]    \n",
    "# optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "m.compile(loss=pure_rmse, optimizer='adam')#opt)\n",
    "X_train, y_train = X, y\n",
    "info_train = info\n",
    "\n",
    "input_shapes = []\n",
    "for i in range(len(X_train)):\n",
    "    input_shapes.append(np.array(X_train[i]).shape[0])\n",
    "m.set_input_shapes(input_shapes)\n",
    "for i in range(len(X_train)):\n",
    "    if X_train[i].shape[0] < 2000:\n",
    "        new_list = np.zeros([2000 - X_train[i].shape[0], 41])\n",
    "        X_train[i] = np.concatenate([X_train[i], new_list], 0)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "hist = m.fit(X_train, y_train, epochs = 40, batch_size=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2728f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 2.7530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7529828548431396"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_brd4\n",
    "y_test = y_brd4\n",
    "info_test = info_brd4\n",
    "input_shapes = []\n",
    "for i in range(len(X_test)):\n",
    "    input_shapes.append(np.array(X_test[i]).shape[0])\n",
    "m.set_input_shapes(input_shapes)\n",
    "for i in range(len(X_test)):\n",
    "    if X_test[i].shape[0] < 2000:\n",
    "        new_list = np.zeros([2000 - X_test[i].shape[0], 41])\n",
    "        X_test[i] = np.concatenate([X_test[i], new_list], 0)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6c4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PGCN_DD_single.pkl', 'wb') as f:\n",
    "    pickle.dump([hist.history['loss'], 3.01], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBNN",
   "language": "python",
   "name": "gbnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
