{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ante-MMPBSA.py -p 0.15_80_10_pH7.5_6m0j_trunc_final.top -r ACE2_dry_trunc.prmtop -l SARS-CoV-2-spike_dry_trunc.prmtop -m :1-339\n",
    "# WARNING: -m is recepter residue number not atom number\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import conda_installer\n",
    "from rdkit import Chem\n",
    "from deepchem.feat.graph_features import atom_features as get_atom_features\n",
    "import rdkit\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import keras.backend as K\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# %cd ../../PGGCN/\n",
    "import models.layers_update_mobley as layers\n",
    "importlib.reload(layers)\n",
    "from models.dcFeaturizer import atom_features as get_atom_features\n",
    "# %cd ../Notebooks/Entropy\n",
    "PDBs = pickle.load(open('PDBs_RDKit.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(molecule, info, exclude=None):\n",
    "    \n",
    "    atom_features = []\n",
    "    for atom in molecule.GetAtoms():\n",
    "        new_feature = get_atom_features(atom).tolist()\n",
    "        position = molecule.GetConformer().GetAtomPosition(atom.GetIdx())\n",
    "        new_feature += [atom.GetMass(), atom.GetAtomicNum()]\n",
    "        new_feature += [position.x, position.y, position.z]\n",
    "        for neighbor in atom.GetNeighbors()[:2]:\n",
    "            neighbor_idx = neighbor.GetIdx()\n",
    "            new_feature += [neighbor_idx]\n",
    "        for i in range(2 - len(atom.GetNeighbors())):\n",
    "            new_feature += [-1]\n",
    "\n",
    "        if exclude != None:\n",
    "            for i in exclude:\n",
    "                new_feature.pop(i)\n",
    "\n",
    "        atom_features.append(np.concatenate([new_feature, info], 0))\n",
    "    return np.array(atom_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PGGCNModel(tf.keras.Model):\n",
    "    def __init__(self, num_atom_features = 36, r_out_channel = 20, c_out_channel = 128):\n",
    "        super().__init__()\n",
    "        self.ruleGraphConvLayer = layers.RuleGraphConvLayer(r_out_channel, num_atom_features, 0)\n",
    "        self.ruleGraphConvLayer.combination_rules = []\n",
    "        self.conv = layers.ConvLayer(c_out_channel)\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1')\n",
    "        self.dense5 = tf.keras.layers.Dense(16, name='relu')\n",
    "        self.dense6 = tf.keras.layers.Dense(1, name='dense6')\n",
    "        self.dense7 = tf.keras.layers.Dense(1, name='dense7',\n",
    "                 kernel_initializer=tf.keras.initializers.Constant([-.2, -1, 1, 1]),\n",
    "                 bias_initializer=tf.keras.initializers.Zeros())\n",
    "        self.all_layer_1_weights = []\n",
    "        \n",
    "    def addRule(self, rule, start_index, end_index = None):\n",
    "        self.ruleGraphConvLayer.addRule(rule, start_index, end_index)\n",
    "    \n",
    "    def set_input_shapes(self, i_s):\n",
    "        self.i_s = i_s\n",
    "\n",
    "    def call(self, inputs):\n",
    "        physics_info = inputs[:,0,38-1:]\n",
    "        x_a = []\n",
    "        for i in range(len(self.i_s)):\n",
    "            x_a.append(inputs[i][:self.i_s[i], :38])\n",
    "        x = self.ruleGraphConvLayer(x_a)\n",
    "        self.all_layer_1_weights.append(self.ruleGraphConvLayer.w_s)\n",
    "        x = self.conv(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense5(x)\n",
    "        model_var = self.dense6(x)\n",
    "        merged = tf.concat([model_var, physics_info], axis=1)\n",
    "        out = self.dense7(merged)\n",
    "        return model_var\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred[0] - y_true))) + K.abs(1 / K.mean(.2 + y_pred[1]))\n",
    "def pure_rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, excelude):\n",
    "    ex = len(excelude)\n",
    "    m = PGGCNModel(num_atom_features = 36-ex)\n",
    "    m.addRule(\"sum\", 0, 31-ex)\n",
    "    m.addRule(\"multiply\", 31-ex, 33-ex)\n",
    "    m.addRule(\"distance\", 33-ex, 36-ex)\n",
    "\n",
    "    m.compile(loss=pure_rmse, optimizer='adam')\n",
    "    X_train, X_test, y_train, y_test = X[:int(.8*len(X))], X[int(.8*len(X)):], y[:int(.8*len(X))], y[int(.8*len(X)):]\n",
    "\n",
    "    input_shapes = []\n",
    "    for i in range(len(X_train)):\n",
    "        input_shapes.append(np.array(X_train[i]).shape[0])\n",
    "    m.set_input_shapes(input_shapes)\n",
    "    for i in range(len(X_train)):\n",
    "        if X_train[i].shape[0] < 2000:\n",
    "            new_list = np.zeros([2000 - X_train[i].shape[0], X_train[i].shape[-1]])\n",
    "            X_train[i] = np.concatenate([X_train[i], new_list], 0)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    hist = m.fit(X_train, y_train, epochs = 10, batch_size=100)\n",
    "\n",
    "    input_shapes = []\n",
    "    y_test = y[int(.8*len(X)):]\n",
    "    for i in range(len(X_test)):\n",
    "        input_shapes.append(np.array(X_test[i]).shape[0])\n",
    "    m.set_input_shapes(input_shapes)\n",
    "    for i in range(len(X_test)):\n",
    "        if X_test[i].shape[0] < 2000:\n",
    "            new_list = np.zeros([2000 - X_test[i].shape[0], 40])\n",
    "            X_test[i] = np.concatenate([X_test[i], new_list], 0)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return m.evaluate(X_test, y_test), hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(excelude):\n",
    "    PDBs = pickle.load(open('PDBs_RDKit.pkl', 'rb'))\n",
    "    df = pd.read_csv('T_data.csv')\n",
    "    info = []\n",
    "    for pdb in list(PDBs.keys()):\n",
    "        info.append(df[df['Id'] == pdb][['TS_comp', 'TS_host', 'TS_ligand']].to_numpy()[0])\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i, pdb in enumerate(list(PDBs.keys())):\n",
    "        X.append(featurize(PDBs[pdb], info[i], excelude))\n",
    "        y.append(df[df['Id'] == pdb]['exp'].to_numpy()[0])\n",
    "\n",
    "\n",
    "    return train(X, y , excelude)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pggcn_model_2/dense7/kernel:0', 'pggcn_model_2/dense7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pggcn_model_2/dense7/kernel:0', 'pggcn_model_2/dense7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pggcn_model_2/dense7/kernel:0', 'pggcn_model_2/dense7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pggcn_model_2/dense7/kernel:0', 'pggcn_model_2/dense7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "1/1 [==============================] - 115s 115s/step - loss: 1.9509\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.9496\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 1.9483\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 1.9471\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 1.9458\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9446\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9434\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 1.9422\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 1.9410\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 1.9399\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.1269\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pggcn_model_3/dense7/kernel:0', 'pggcn_model_3/dense7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pggcn_model_3/dense7/kernel:0', 'pggcn_model_3/dense7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "excelude_list = [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 18, 19]\n",
    "dic = {}\n",
    "for ex in excelude_list:\n",
    "    hist, res = experiment([ex])\n",
    "    dic[ex] = [hist, res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Carbon', 'Nitrogen', 'Oxygen', 'Sulfur', 'Fluorine', 'Degree 0', 'Degree 1', 'Degree 2',\n",
    "    'implicit valence 0', 'implicit valence 1', 'implicit valence 2', '# electrons', 'charge']\n",
    "indices = [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 18, 19]\n",
    "feature_dict = {indices[i]: features[i] for i in range(len(indices))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = {0: 3.18877, 1:3.19272, 2:3.18746, 3:3.18861, 4:3.18948, 6:3.19349, 7:3.18948, 8:3.18737, 10:3.1909, 11:3.18954, 12: 3.18494, 18: 3.18945, 19:3.19223}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ali/GBNN/Datasets/VM2_data\n"
     ]
    }
   ],
   "source": [
    "%cd ../../Datasets/VM2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_acd = pd.read_csv('taproom_ACD/MGO_vm2_complex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     188.818600\n",
       "1     181.732404\n",
       "2     179.633618\n",
       "3     197.382305\n",
       "4     204.160569\n",
       "5     185.191885\n",
       "6     201.804227\n",
       "7     196.301052\n",
       "8     192.270888\n",
       "9     192.987463\n",
       "10    204.398609\n",
       "11    184.153308\n",
       "12    188.391336\n",
       "13    197.095563\n",
       "14    205.087795\n",
       "15    212.337217\n",
       "16    196.399300\n",
       "17    206.323149\n",
       "18    210.181435\n",
       "19    197.099926\n",
       "20    196.755623\n",
       "21    185.458198\n",
       "Name:  S, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acd[' S']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBNN",
   "language": "python",
   "name": "gbnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
