{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Installing RDKit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add /home/ali/miniconda/lib/python3.8/site-packages to PYTHONPATH\n",
      "all packages are already installed\n"
     ]
    }
   ],
   "source": [
    "# !curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
    "import conda_installer\n",
    "# conda_installer.install()\n",
    "conda_installer.install()\n",
    "# !/root/miniconda/bin/conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 19:32:55.346708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-18 19:32:55.346728: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/molecule_parameters_final.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex-name</th>\n",
       "      <th>gb-complex-etot</th>\n",
       "      <th>gb-complex-1-4-eel</th>\n",
       "      <th>gb-complex-eelec</th>\n",
       "      <th>gb-complex-egb</th>\n",
       "      <th>gb-complex-esurf</th>\n",
       "      <th>gb-protein-etot</th>\n",
       "      <th>gb-protein-1-4-eel</th>\n",
       "      <th>gb-protein-eelect</th>\n",
       "      <th>gb-protein-egb</th>\n",
       "      <th>...</th>\n",
       "      <th>pb-protein-vdwaals</th>\n",
       "      <th>pb-protein-eelec</th>\n",
       "      <th>pb-protein-epb</th>\n",
       "      <th>pb-protein-ecavity</th>\n",
       "      <th>pb-ligand-etot</th>\n",
       "      <th>pb-ligand-vdwaals</th>\n",
       "      <th>pb-ligand-eelec</th>\n",
       "      <th>pb-ligand-epb</th>\n",
       "      <th>pb-ligand-ecavity</th>\n",
       "      <th>ddg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10gs</td>\n",
       "      <td>-16145.9190</td>\n",
       "      <td>18478.8142</td>\n",
       "      <td>-31052.1742</td>\n",
       "      <td>-3659.4630</td>\n",
       "      <td>86.9041</td>\n",
       "      <td>-16042.9095</td>\n",
       "      <td>18034.9833</td>\n",
       "      <td>-30493.1722</td>\n",
       "      <td>-3672.7126</td>\n",
       "      <td>...</td>\n",
       "      <td>-4077.8698</td>\n",
       "      <td>-30493.1722</td>\n",
       "      <td>-3650.6491</td>\n",
       "      <td>87.9920</td>\n",
       "      <td>-565.1881</td>\n",
       "      <td>-10.1928</td>\n",
       "      <td>-416.8647</td>\n",
       "      <td>-141.8681</td>\n",
       "      <td>3.7375</td>\n",
       "      <td>-8.841927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a1e</td>\n",
       "      <td>-9777.1684</td>\n",
       "      <td>7030.7012</td>\n",
       "      <td>-13515.0036</td>\n",
       "      <td>-3349.3791</td>\n",
       "      <td>56.5130</td>\n",
       "      <td>-9499.3955</td>\n",
       "      <td>7189.5223</td>\n",
       "      <td>-13366.9577</td>\n",
       "      <td>-3378.1703</td>\n",
       "      <td>...</td>\n",
       "      <td>-1901.0486</td>\n",
       "      <td>-13366.9577</td>\n",
       "      <td>-3333.0961</td>\n",
       "      <td>56.2103</td>\n",
       "      <td>-173.5190</td>\n",
       "      <td>-11.4008</td>\n",
       "      <td>-96.6715</td>\n",
       "      <td>-69.9064</td>\n",
       "      <td>4.4598</td>\n",
       "      <td>-8.289306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a30</td>\n",
       "      <td>-6925.5462</td>\n",
       "      <td>9349.4510</td>\n",
       "      <td>-14111.7670</td>\n",
       "      <td>-2211.3839</td>\n",
       "      <td>48.1538</td>\n",
       "      <td>-6881.3365</td>\n",
       "      <td>8949.8465</td>\n",
       "      <td>-13675.6929</td>\n",
       "      <td>-2204.7807</td>\n",
       "      <td>...</td>\n",
       "      <td>-1777.0400</td>\n",
       "      <td>-13675.6929</td>\n",
       "      <td>-2179.8309</td>\n",
       "      <td>49.2906</td>\n",
       "      <td>-645.4443</td>\n",
       "      <td>-9.3186</td>\n",
       "      <td>-381.1129</td>\n",
       "      <td>-257.9893</td>\n",
       "      <td>2.9765</td>\n",
       "      <td>-5.940670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a4k</td>\n",
       "      <td>-29413.8956</td>\n",
       "      <td>40100.7078</td>\n",
       "      <td>-61088.2896</td>\n",
       "      <td>-8626.6708</td>\n",
       "      <td>200.3571</td>\n",
       "      <td>-29189.9201</td>\n",
       "      <td>40319.8406</td>\n",
       "      <td>-60991.3946</td>\n",
       "      <td>-8719.3884</td>\n",
       "      <td>...</td>\n",
       "      <td>-1084.3398</td>\n",
       "      <td>-60991.3946</td>\n",
       "      <td>-8730.0602</td>\n",
       "      <td>201.0222</td>\n",
       "      <td>-27.4572</td>\n",
       "      <td>-6.0182</td>\n",
       "      <td>74.3491</td>\n",
       "      <td>-99.2366</td>\n",
       "      <td>3.4485</td>\n",
       "      <td>-11.052408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4r</td>\n",
       "      <td>-14436.7381</td>\n",
       "      <td>16726.9825</td>\n",
       "      <td>-26744.9283</td>\n",
       "      <td>-4516.3615</td>\n",
       "      <td>97.5691</td>\n",
       "      <td>-13647.6149</td>\n",
       "      <td>18021.0326</td>\n",
       "      <td>-27237.1053</td>\n",
       "      <td>-4529.6519</td>\n",
       "      <td>...</td>\n",
       "      <td>-1733.7572</td>\n",
       "      <td>-27237.1053</td>\n",
       "      <td>-4478.1330</td>\n",
       "      <td>98.1097</td>\n",
       "      <td>486.8763</td>\n",
       "      <td>-5.8718</td>\n",
       "      <td>583.2385</td>\n",
       "      <td>-93.5441</td>\n",
       "      <td>3.0538</td>\n",
       "      <td>-9.201130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>7std</td>\n",
       "      <td>-20699.0549</td>\n",
       "      <td>21176.0749</td>\n",
       "      <td>-35706.5273</td>\n",
       "      <td>-6267.2953</td>\n",
       "      <td>98.6928</td>\n",
       "      <td>-20681.1007</td>\n",
       "      <td>21209.5397</td>\n",
       "      <td>-35704.9166</td>\n",
       "      <td>-6285.3439</td>\n",
       "      <td>...</td>\n",
       "      <td>-5167.3253</td>\n",
       "      <td>-35704.9166</td>\n",
       "      <td>-6203.5215</td>\n",
       "      <td>99.6200</td>\n",
       "      <td>-14.5959</td>\n",
       "      <td>-4.6906</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>-12.7624</td>\n",
       "      <td>2.7350</td>\n",
       "      <td>-14.810227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>7upj</td>\n",
       "      <td>-7203.9558</td>\n",
       "      <td>8347.2909</td>\n",
       "      <td>-13713.5975</td>\n",
       "      <td>-1887.4373</td>\n",
       "      <td>49.7881</td>\n",
       "      <td>-7088.4059</td>\n",
       "      <td>8615.8940</td>\n",
       "      <td>-13766.9993</td>\n",
       "      <td>-1988.7703</td>\n",
       "      <td>...</td>\n",
       "      <td>-1672.4526</td>\n",
       "      <td>-13766.9993</td>\n",
       "      <td>-1966.3313</td>\n",
       "      <td>51.4697</td>\n",
       "      <td>66.5143</td>\n",
       "      <td>-7.2150</td>\n",
       "      <td>102.8524</td>\n",
       "      <td>-32.7172</td>\n",
       "      <td>3.5941</td>\n",
       "      <td>-11.729368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>8a3h</td>\n",
       "      <td>-11311.9593</td>\n",
       "      <td>14514.5548</td>\n",
       "      <td>-17122.3046</td>\n",
       "      <td>-8760.1462</td>\n",
       "      <td>55.9367</td>\n",
       "      <td>-11349.4465</td>\n",
       "      <td>14306.8313</td>\n",
       "      <td>-16401.8897</td>\n",
       "      <td>-9310.9686</td>\n",
       "      <td>...</td>\n",
       "      <td>-3055.0110</td>\n",
       "      <td>-16401.8897</td>\n",
       "      <td>-9229.1824</td>\n",
       "      <td>56.5806</td>\n",
       "      <td>-199.9330</td>\n",
       "      <td>-6.2099</td>\n",
       "      <td>-84.0375</td>\n",
       "      <td>-112.4157</td>\n",
       "      <td>2.7302</td>\n",
       "      <td>-5.609097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>8cpa</td>\n",
       "      <td>-10896.0768</td>\n",
       "      <td>13847.1770</td>\n",
       "      <td>-22434.5575</td>\n",
       "      <td>-2366.9434</td>\n",
       "      <td>58.2471</td>\n",
       "      <td>-10848.4034</td>\n",
       "      <td>13472.1409</td>\n",
       "      <td>-21904.4816</td>\n",
       "      <td>-2475.0882</td>\n",
       "      <td>...</td>\n",
       "      <td>-2292.8024</td>\n",
       "      <td>-21904.4816</td>\n",
       "      <td>-2442.5401</td>\n",
       "      <td>59.0256</td>\n",
       "      <td>-544.4429</td>\n",
       "      <td>-8.5007</td>\n",
       "      <td>-439.7892</td>\n",
       "      <td>-99.9047</td>\n",
       "      <td>3.7517</td>\n",
       "      <td>-12.641192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>966c</td>\n",
       "      <td>-6118.8907</td>\n",
       "      <td>6310.2596</td>\n",
       "      <td>-9039.2312</td>\n",
       "      <td>-3431.0677</td>\n",
       "      <td>41.1486</td>\n",
       "      <td>-6153.6352</td>\n",
       "      <td>6133.6566</td>\n",
       "      <td>-8847.2589</td>\n",
       "      <td>-3481.9968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1385.5069</td>\n",
       "      <td>-8847.2589</td>\n",
       "      <td>-3429.8390</td>\n",
       "      <td>41.9639</td>\n",
       "      <td>-206.1268</td>\n",
       "      <td>-5.0006</td>\n",
       "      <td>-166.0323</td>\n",
       "      <td>-38.1590</td>\n",
       "      <td>3.0651</td>\n",
       "      <td>-10.555050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2735 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     complex-name  gb-complex-etot  gb-complex-1-4-eel  gb-complex-eelec  \\\n",
       "0            10gs      -16145.9190          18478.8142       -31052.1742   \n",
       "1            1a1e       -9777.1684           7030.7012       -13515.0036   \n",
       "2            1a30       -6925.5462           9349.4510       -14111.7670   \n",
       "3            1a4k      -29413.8956          40100.7078       -61088.2896   \n",
       "4            1a4r      -14436.7381          16726.9825       -26744.9283   \n",
       "...           ...              ...                 ...               ...   \n",
       "2909         7std      -20699.0549          21176.0749       -35706.5273   \n",
       "2910         7upj       -7203.9558           8347.2909       -13713.5975   \n",
       "2911         8a3h      -11311.9593          14514.5548       -17122.3046   \n",
       "2912         8cpa      -10896.0768          13847.1770       -22434.5575   \n",
       "2913         966c       -6118.8907           6310.2596        -9039.2312   \n",
       "\n",
       "      gb-complex-egb  gb-complex-esurf  gb-protein-etot  gb-protein-1-4-eel  \\\n",
       "0         -3659.4630           86.9041      -16042.9095          18034.9833   \n",
       "1         -3349.3791           56.5130       -9499.3955           7189.5223   \n",
       "2         -2211.3839           48.1538       -6881.3365           8949.8465   \n",
       "3         -8626.6708          200.3571      -29189.9201          40319.8406   \n",
       "4         -4516.3615           97.5691      -13647.6149          18021.0326   \n",
       "...              ...               ...              ...                 ...   \n",
       "2909      -6267.2953           98.6928      -20681.1007          21209.5397   \n",
       "2910      -1887.4373           49.7881       -7088.4059           8615.8940   \n",
       "2911      -8760.1462           55.9367      -11349.4465          14306.8313   \n",
       "2912      -2366.9434           58.2471      -10848.4034          13472.1409   \n",
       "2913      -3431.0677           41.1486       -6153.6352           6133.6566   \n",
       "\n",
       "      gb-protein-eelect  gb-protein-egb  ...  pb-protein-vdwaals  \\\n",
       "0           -30493.1722      -3672.7126  ...          -4077.8698   \n",
       "1           -13366.9577      -3378.1703  ...          -1901.0486   \n",
       "2           -13675.6929      -2204.7807  ...          -1777.0400   \n",
       "3           -60991.3946      -8719.3884  ...          -1084.3398   \n",
       "4           -27237.1053      -4529.6519  ...          -1733.7572   \n",
       "...                 ...             ...  ...                 ...   \n",
       "2909        -35704.9166      -6285.3439  ...          -5167.3253   \n",
       "2910        -13766.9993      -1988.7703  ...          -1672.4526   \n",
       "2911        -16401.8897      -9310.9686  ...          -3055.0110   \n",
       "2912        -21904.4816      -2475.0882  ...          -2292.8024   \n",
       "2913         -8847.2589      -3481.9968  ...          -1385.5069   \n",
       "\n",
       "      pb-protein-eelec  pb-protein-epb  pb-protein-ecavity  pb-ligand-etot  \\\n",
       "0          -30493.1722      -3650.6491             87.9920       -565.1881   \n",
       "1          -13366.9577      -3333.0961             56.2103       -173.5190   \n",
       "2          -13675.6929      -2179.8309             49.2906       -645.4443   \n",
       "3          -60991.3946      -8730.0602            201.0222        -27.4572   \n",
       "4          -27237.1053      -4478.1330             98.1097        486.8763   \n",
       "...                ...             ...                 ...             ...   \n",
       "2909       -35704.9166      -6203.5215             99.6200        -14.5959   \n",
       "2910       -13766.9993      -1966.3313             51.4697         66.5143   \n",
       "2911       -16401.8897      -9229.1824             56.5806       -199.9330   \n",
       "2912       -21904.4816      -2442.5401             59.0256       -544.4429   \n",
       "2913        -8847.2589      -3429.8390             41.9639       -206.1268   \n",
       "\n",
       "      pb-ligand-vdwaals  pb-ligand-eelec  pb-ligand-epb  pb-ligand-ecavity  \\\n",
       "0              -10.1928        -416.8647      -141.8681             3.7375   \n",
       "1              -11.4008         -96.6715       -69.9064             4.4598   \n",
       "2               -9.3186        -381.1129      -257.9893             2.9765   \n",
       "3               -6.0182          74.3491       -99.2366             3.4485   \n",
       "4               -5.8718         583.2385       -93.5441             3.0538   \n",
       "...                 ...              ...            ...                ...   \n",
       "2909            -4.6906           0.1221       -12.7624             2.7350   \n",
       "2910            -7.2150         102.8524       -32.7172             3.5941   \n",
       "2911            -6.2099         -84.0375      -112.4157             2.7302   \n",
       "2912            -8.5007        -439.7892       -99.9047             3.7517   \n",
       "2913            -5.0006        -166.0323       -38.1590             3.0651   \n",
       "\n",
       "            ddg  \n",
       "0     -8.841927  \n",
       "1     -8.289306  \n",
       "2     -5.940670  \n",
       "3    -11.052408  \n",
       "4     -9.201130  \n",
       "...         ...  \n",
       "2909 -14.810227  \n",
       "2910 -11.729368  \n",
       "2911  -5.609097  \n",
       "2912 -12.641192  \n",
       "2913 -10.555050  \n",
       "\n",
       "[2735 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder():\n",
    "    input_g = keras.Input(shape=(15,))\n",
    "    encoded = layers.Dense(10, activation='relu')(input_g)\n",
    "    encoded = layers.Dense(10, activation='sigmoid')(encoded)\n",
    "    decoded = layers.Dense(10, activation = 'relu')(encoded)\n",
    "    decoded = layers.Dense(15)(decoded)\n",
    "    return keras.Model(input_g, encoded), keras.Model(input_g, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, m = create_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.absolute(df[training_columns][:2000].to_numpy())\n",
    "from scipy import stats\n",
    "x_train = stats.zscore(x_train)\n",
    "y_train = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam', loss='MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 696us/step - loss: 0.9737\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.8815\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 667us/step - loss: 0.7446\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.6401\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.5643\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.5024\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.4559\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.4231\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.3989\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.3800\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.3631\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 715us/step - loss: 0.3485\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.3362\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.3260\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.3165\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 715us/step - loss: 0.3097\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 749us/step - loss: 0.3036\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 690us/step - loss: 0.2986\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.2942\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 698us/step - loss: 0.2894\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.2857\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 724us/step - loss: 0.2822\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 687us/step - loss: 0.2789\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 723us/step - loss: 0.2759\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.2732\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.2702\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 701us/step - loss: 0.2672\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.2647\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.2621\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 733us/step - loss: 0.2592\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 736us/step - loss: 0.2567\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.2533\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 725us/step - loss: 0.2498\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 719us/step - loss: 0.2465\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.2432\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 720us/step - loss: 0.2404\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.2376\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.2334\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 754us/step - loss: 0.2301\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 773us/step - loss: 0.2259\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 768us/step - loss: 0.2225\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.2181\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.2140\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.2101\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 759us/step - loss: 0.2062\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 694us/step - loss: 0.2020\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 746us/step - loss: 0.1987\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 732us/step - loss: 0.1944\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 741us/step - loss: 0.1903\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 722us/step - loss: 0.1866\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 775us/step - loss: 0.1831\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 686us/step - loss: 0.1795\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 769us/step - loss: 0.1763\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.1728\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 748us/step - loss: 0.1698\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 752us/step - loss: 0.1662\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 719us/step - loss: 0.1629\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 708us/step - loss: 0.1606\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 698us/step - loss: 0.1575\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 717us/step - loss: 0.1548\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.1519\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.1494\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 709us/step - loss: 0.1468\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 770us/step - loss: 0.1440\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.1411\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.1385\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.1366\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 731us/step - loss: 0.1338\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.1314\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 691us/step - loss: 0.1292\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.1273\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.1241\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 748us/step - loss: 0.1221\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 749us/step - loss: 0.1197\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 736us/step - loss: 0.1174\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 703us/step - loss: 0.1157\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.1128\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 740us/step - loss: 0.1106\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 713us/step - loss: 0.1090\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 734us/step - loss: 0.1065\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 738us/step - loss: 0.1044\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.1020\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 719us/step - loss: 0.1007\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 720us/step - loss: 0.0981\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.0962\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 675us/step - loss: 0.0944\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 671us/step - loss: 0.0921\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 708us/step - loss: 0.0898\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 708us/step - loss: 0.0882\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.0865\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.0847\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.0828\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 730us/step - loss: 0.0813\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.0798\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.0778\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.0761\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 743us/step - loss: 0.0748\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 764us/step - loss: 0.0728\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 755us/step - loss: 0.0715\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.0702\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.0683\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.0669\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.0656\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 709us/step - loss: 0.0642\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 690us/step - loss: 0.0630\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 695us/step - loss: 0.0619\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 687us/step - loss: 0.0609\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 687us/step - loss: 0.0595\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 667us/step - loss: 0.0582\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 717us/step - loss: 0.0572\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 743us/step - loss: 0.0561\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 740us/step - loss: 0.0550\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 737us/step - loss: 0.0541\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.0532\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.0522\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 689us/step - loss: 0.0512\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 721us/step - loss: 0.0503\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 716us/step - loss: 0.0493\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.0486\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 680us/step - loss: 0.0482\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.0478\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 679us/step - loss: 0.0468\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 691us/step - loss: 0.0453\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0450\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 751us/step - loss: 0.0443\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 754us/step - loss: 0.0437\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 754us/step - loss: 0.0430\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 762us/step - loss: 0.0424\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 687us/step - loss: 0.0419\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 668us/step - loss: 0.0412\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.0409\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 720us/step - loss: 0.0402\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 672us/step - loss: 0.0397\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 715us/step - loss: 0.0394\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 765us/step - loss: 0.0389\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.0389\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 763us/step - loss: 0.0385\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 761us/step - loss: 0.0377\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 719us/step - loss: 0.0377\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 688us/step - loss: 0.0370\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 677us/step - loss: 0.0366\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 685us/step - loss: 0.0363\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 701us/step - loss: 0.0362\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.0357\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.0356\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 703us/step - loss: 0.0349\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 772us/step - loss: 0.0350\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 774us/step - loss: 0.0349\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.0360\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.0342\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 736us/step - loss: 0.0339\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.0337\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 714us/step - loss: 0.0333\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 707us/step - loss: 0.0331\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.0329\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 672us/step - loss: 0.0326\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 703us/step - loss: 0.0328\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 726us/step - loss: 0.0325\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 673us/step - loss: 0.0328\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 712us/step - loss: 0.0321\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 701us/step - loss: 0.0325\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.0318\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.0316\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.0321\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.0321\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.0315\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 683us/step - loss: 0.0312\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 735us/step - loss: 0.0317\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.0309\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 711us/step - loss: 0.0311\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.0309\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.0304\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 718us/step - loss: 0.0306\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.0310\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 748us/step - loss: 0.0307\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 768us/step - loss: 0.0306\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 753us/step - loss: 0.0309\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 739us/step - loss: 0.0304\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 748us/step - loss: 0.0302\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 767us/step - loss: 0.0300\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 708us/step - loss: 0.0295\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 710us/step - loss: 0.0299\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 693us/step - loss: 0.0300\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 687us/step - loss: 0.0292\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 706us/step - loss: 0.0295\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 715us/step - loss: 0.0302\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 700us/step - loss: 0.0295\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 697us/step - loss: 0.0296\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 677us/step - loss: 0.0293\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 708us/step - loss: 0.0293\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 699us/step - loss: 0.0294\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 672us/step - loss: 0.0294\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 705us/step - loss: 0.0292\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 686us/step - loss: 0.0287\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 681us/step - loss: 0.0292\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 686us/step - loss: 0.0298\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 731us/step - loss: 0.0288\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 727us/step - loss: 0.0293\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 674us/step - loss: 0.0290\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 692us/step - loss: 0.0294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7effd6f6ff40>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [col for col in df.columns if (col[:3] == 'gb-' and not col.__contains__('etot')) or (col.__contains__('vdwaals'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gb-overall-1-4-eel'] = df.apply(lambda row: row['gb-complex-1-4-eel'] - row['gb-protein-1-4-eel'] - row['gb-ligand-1-4-eel'], axis=1)\n",
    "df['gb-overall-eelec'] = df.apply(lambda row: row['gb-complex-eelec'] - row['gb-protein-eelect'] - row['gb-ligand-eelec'], axis=1)\n",
    "df['gb-overall-egb'] = df.apply(lambda row: row['gb-complex-egb'] - row['gb-protein-egb'] - row['gb-ligand-egb'], axis=1)\n",
    "df['gb-overall-esurf'] = df.apply(lambda row: row['gb-complex-esurf'] - row['gb-protein-esurf'] - row['gb-ligand-esurf'], axis=1)\n",
    "df['pb-overall-vdwaals'] = df.apply(lambda row: row['pb-complex-vdwaals'] - row['pb-protein-vdwaals'] - row['pb-ligand-vdwaals'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['gb-overall-eelec'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pb-overall-vdwaals', ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('pb-overall-vdwaals')\n",
    "df['pb-overall-vdwaals'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [f for f in df.columns if f.__contains__('overall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gb-overall-eelec', ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('gb-overall-eelec')\n",
    "df['gb-overall-eelec'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gb-overall-eelec normalized', ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('gb-overall-eelec normalized')\n",
    "((df['gb-overall-eelec'] - df['gb-overall-eelec'].std()) / df['gb-overall-eelec'].mean()).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading Mobley PDB files</h1>\n",
    "<p>Here each PDB file will be read and saved in Mol data type defined in RDKit and used by DeepChem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDBs = {}\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# mypath = '../Datasets/pdb-test/'\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# for f in onlyfiles:\n",
    "#     PDBs.update({f.split('.')[0] : rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + '/' + f)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save PDB\n",
    "# import pickle\n",
    "# with open('PDBs.pkl', 'wb') as file:\n",
    "#     pickle.dump(PDBs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load PDB\n",
    "import pickle\n",
    "PDBs = {}\n",
    "with open('PDBs.pkl', 'rb') as file:\n",
    "    PDBs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Featurizing</h1>\n",
    "<p>GraphConv model needs ConvMolFeaturizer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "TRAIN_SET = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[training_columns]),\n",
    "                   columns=training_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gb-overall-1-4-eel', ylabel='Frequency'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('gb-overall-1-4-eel')\n",
    "df_scaled['gb-overall-1-4-eel'].plot.hist(range=[0.9999, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_ids = []\n",
    "# one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "for k in PDBs.keys():\n",
    "    X_ids.append(k)\n",
    "    X.append(featurizer.featurize(PDBs[k]))\n",
    "split_index = int(len(X) * TRAIN_SET)\n",
    "X = [x[0] for x in X]\n",
    "X_train_featurized = X[:split_index]\n",
    "X_test_featurized = X[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_names = [i for i in X_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_names_train = pdb_names[:split_index]\n",
    "pdb_names_test = pdb_names[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_add_train, x_add_test, y_train, y_test = [], [], [], []\n",
    "for i in range(len(pdb_names_train)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "    y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_train.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_train = np.array(y_train)\n",
    "    \n",
    "for i in range(len(pdb_names_test)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "#     print(pdb_names_test[i])\n",
    "#     print(new_df['ddg'].to_numpy())\n",
    "    y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_test.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "x_preprocessed_train, x_preprocessed_test = [], []\n",
    "\n",
    "## for X train\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "## for X test\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_test.append(np.array(x_add_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.full([14, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_train):\n",
    "    if len(j.shape) > 1:\n",
    "        x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "x_test = np.full([14, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_test):\n",
    "    if len(j.shape) > 1:\n",
    "        x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_test = x_test.reshape([1] + list(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def __init__(self, batch_size):\n",
    "    super(GBGraphConvModel, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(64, activation=tf.nn.sigmoid)\n",
    "    self.dense3 = layers.Dense(1)\n",
    "    \n",
    "    ## Dense for overall\n",
    "    self.dense4 = layers.Dense(1, \n",
    "     kernel_initializer=initializers.Constant([.5, 1, 1, 1, 1, 1]),\n",
    "     bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "#     self.dense4 = layers.Dense(1, \n",
    "#          kernel_initializer=initializers.Constant([.5, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1]),\n",
    "#          bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     x_feat, x_add = inputs[0], inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\n",
    "\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    model_var = self.dense3(model_var)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    ddg = self.dense4(binding_affinity)\n",
    "    tf.print(self.dense4.weights, output_stream=\"file://weights.txt\", summarize=30)\n",
    "    tf.print(binding_affinity[0], output_stream=\"file://binding_a.txt\", summarize=30)\n",
    "    tf.print(ddg[0], output_stream=\"file://ddg.txt\")\n",
    "    tf.print(model_var, output_stream=\"file://model_var.txt\", summarize=30)\n",
    "    tf.print(\"-------------------------\", output_stream=sys.stdout)\n",
    "    return ddg\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "model = GBGraphConvModel(split_index)\n",
    "model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
    "K.set_value(model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_14:0\", shape=(34113,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_13:0\", shape=(34113, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_17:0\", shape=(82976,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_16:0\", shape=(82976, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_20:0\", shape=(118143,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_19:0\", shape=(118143, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_23:0\", shape=(60,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_22:0\", shape=(60, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_11:0\", shape=(34113,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_10:0\", shape=(34113, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_13:0\", shape=(82976,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_12:0\", shape=(82976, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_15:0\", shape=(118143,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_14:0\", shape=(118143, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_17:0\", shape=(60,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_16:0\", shape=(60, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_14:0\", shape=(34113,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_13:0\", shape=(34113, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_17:0\", shape=(82976,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_16:0\", shape=(82976, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_20:0\", shape=(118143,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_19:0\", shape=(118143, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_23:0\", shape=(60,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_22:0\", shape=(60, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gb_graph_conv_model_1/Reshape_14' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/ali/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/ali/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_9023/85814939.py\", line 2, in <module>\n      history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_9023/1980227167.py\", line 54, in call\n      x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\nNode: 'gb_graph_conv_model_1/Reshape_14'\nInput to reshape is a tensor with 465 values, but the requested shape has 155\n\t [[{{node gb_graph_conv_model_1/Reshape_14}}]] [Op:__inference_train_function_20732]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39minput_shapes \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x_preprocessed_train]\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gb_graph_conv_model_1/Reshape_14' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/ali/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/ali/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n      await self.process_one()\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 450, in process_one\n      await dispatch(*args)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n      await result\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n      reply_content = await reply_content\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/ali/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ali/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_9023/85814939.py\", line 2, in <module>\n      history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/ali/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_9023/1980227167.py\", line 54, in call\n      x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\nNode: 'gb_graph_conv_model_1/Reshape_14'\nInput to reshape is a tensor with 465 values, but the requested shape has 155\n\t [[{{node gb_graph_conv_model_1/Reshape_14}}]] [Op:__inference_train_function_20732]"
     ]
    }
   ],
   "source": [
    "model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148767.0008"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['gb-complex-1-4-eel'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "model.modify_graphgather(len(X) - split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.496837735]\n",
      " [1.00316226]\n",
      " [0.996837735]\n",
      " ...\n",
      " [0.996837735]\n",
      " [-1.00316226]\n",
      " [-1.00316226]], [-0.0031622753]]\n",
      "[0.650298357 -16127.6348 19940.8438 ... 2215.14038 2134.90894 13.8664]\n",
      "[0]\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 9.0176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.017557144165039"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test.reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.220932405998316"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(38.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f474a0e0cc0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'dataset group name', 'Dataset Name', 'Host', 'Guest',\n",
       "       'Ex _G_(kcal/mol)', 'Ex _G_SEM', 'EX _H_(kcal/mol)', 'EX _H_SEM',\n",
       "       'pb_guest_Etot', 'pb_guest_VDWAALS', 'pb_guest_EELEC', 'pb_guest_EPB',\n",
       "       'pb_guest_ECAVITY', 'pb_host_Etot', 'pb_host_VDWAALS', 'pb_host_EELEC',\n",
       "       'pb_host_EPB', 'pb_host_ECAVITY', 'pb_complex_Etot',\n",
       "       'pb_complex_VDWAALS', 'pb_complex_EELEC', 'pb_complex_EPB',\n",
       "       'pb_complex_ECAVITY', 'gb_Complex_Etot', 'gb_Complex_1-4EEL',\n",
       "       'gb_Complex_EELEC', 'gb_Complex_EGB', 'gb_Complex_ESURF',\n",
       "       'gb_guest_Etot', 'gb_guest_1-4EEL', 'gb_guest_EELEC', 'gb_guest_EGB',\n",
       "       'gb_guest_ESURF', 'gb_host_Etot', 'gb_host_1-4EEL', 'gb_host_EELEC',\n",
       "       'gb_host_EGB', 'gb_host_ESURF', 'gb_delta_H', 'pb_delta_H',\n",
       "       'EX _delta_H_(kcal/mol)', 'gb_Ex_difference',\n",
       "       'SQR_gbnsr6_Ex_difference', 'pb_Ex_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.485930943559929"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((df['EX _H_(kcal/mol)'].to_numpy() - df['gb_delta_H'].to_numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6500000000000004"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8.48 - 5.83)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
