{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Installing RDKit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all packages are already installed\n"
     ]
    }
   ],
   "source": [
    "# !curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
    "import conda_installer\n",
    "# conda_installer.install()\n",
    "conda_installer.install()\n",
    "# !/root/miniconda/bin/conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/pdbbind_300.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Reading Mobley PDB files</h1>\n",
    "<p>Here each PDB file will be read and saved in Mol data type defined in RDKit and used by DeepChem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "complex_names_df = df['complex-name'].to_numpy()\n",
    "PDBs = {}\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '../Datasets/pdbbind_complex'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "for f in onlyfiles:\n",
    "    if f.split('.')[0] in complex_names_df:\n",
    "        PDBs.update({f.split('.')[0] : rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + '/' + f)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Featurizing</h1>\n",
    "<p>GraphConv model needs ConvMolFeaturizer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "TRAIN_SET = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X_ids = []\n",
    "# one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "for k in PDBs.keys():\n",
    "    X_ids.append(k)\n",
    "    X.append(featurizer.featurize(PDBs[k]))\n",
    "split_index = int(len(X) * TRAIN_SET)\n",
    "X = [x[0] for x in X]\n",
    "X_train_featurized = X[:split_index]\n",
    "X_test_featurized = X[split_index:]\n",
    "X_ids_train = X_ids[:split_index]\n",
    "X_ids_test = X_ids[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_disk = []\n",
    "y_disk = []\n",
    "for i in range(len(X_ids)):\n",
    "    X_disk.append(X[i])\n",
    "    y_disk.append(df[df['complex-name'] == X_ids[i]]['ddg'].to_numpy()[0])\n",
    "w_disk = np.ones([5,12])\n",
    "X_add = []\n",
    "for i in range(len(X_ids)):\n",
    "    X_add.append(df[df['complex-name'] == X_ids[i]][[i for i in df.columns if ((('gb-' in i))\n",
    "                                                          and ('-etot' not in i)) or ('-vdwaals' in i)]].to_numpy()[0])\n",
    "train_dataset = dc.data.DiskDataset.from_numpy(X=X_disk, y=y_disk, w=w_disk, ids=X_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_add_train, x_add_test, y_train, y_test = [], [], [], []\n",
    "for i in range(len(X_ids_train)):\n",
    "    new_df = df[(df['complex-name'] == X_ids_train[i])]\n",
    "    y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_train.append(new_df[[i for i in df.columns if ((('gb-' in i))\n",
    "                                                          and ('-etot' not in i)) or ('-vdwaals' in i)]].to_numpy()[0])\n",
    "y_train = np.array(y_train)\n",
    "    \n",
    "for i in range(len(X_ids_test)):\n",
    "    new_df = df[(df['complex-name'] == X_ids_train[i])]\n",
    "    y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_test.append(new_df[[i for i in df.columns if ((('gb-' in i))\n",
    "                                                          and ('-etot' not in i)) or ('-vdwaals' in i)]].to_numpy()[0])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "x_preprocessed_train, x_preprocessed_test = [], []\n",
    "\n",
    "## for X train\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "## for X test\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_test.append(np.array(x_add_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>Creating Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "del(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_add = np.array(X_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(GBGraphConvModel, self).__init__()\n",
    "    self.counter = 0\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(64, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([.5, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     inputs = inputs[0]\n",
    "    x = inputs\n",
    "    x_add = X_add\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "#     for i in range(len(self.input_shapes)):\n",
    "#         x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "#     for i in range(1, len(self.input_shapes)):\n",
    "#         x[i] = tf.cast(x[i], tf.int32)\n",
    "#     x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 15])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    ans = self.dense3(binding_affinity)\n",
    "    ans = tf.reshape(ans, [1, -1])\n",
    "    print(ans)\n",
    "    return ans\n",
    "model = GBGraphConvModel(split_index)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(y, y_hat, w):\n",
    "    return tf.keras.losses.mse(y_hat, y)\n",
    "loss_func = lambda y, y_hat, w: tf.keras.losses.mse(y_hat, y)\n",
    "model2 = dc.models.KerasModel(GBGraphConvModel(len(df)), loss = loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "import numpy as np\n",
    "batch_size = len(df)\n",
    "def data_generator(dataset, epochs=30):\n",
    "    for ind, (X_b, y_b, w_b, ids_b) in enumerate(dataset.iterbatches(batch_size, epochs,\n",
    "                                                                   deterministic=False, pad_batches=True)):\n",
    "        multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
    "        inputs = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "        for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "            inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "#        inputs.append(X_add)\n",
    "#         print(inputs[13])\n",
    "        labels = y_b\n",
    "        weights = [w_b]\n",
    "        yield (inputs, labels, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gb_graph_conv_model_5/Reshape:0\", shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_14:0\", shape=(1497,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_13:0\", shape=(1497, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_17:0\", shape=(3636,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_16:0\", shape=(3636, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_20:0\", shape=(5109,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_19:0\", shape=(5109, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_23:0\", shape=(4,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Reshape_22:0\", shape=(4, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_11:0\", shape=(1497,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_10:0\", shape=(1497, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_13:0\", shape=(3636,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_12:0\", shape=(3636, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_15:0\", shape=(5109,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_14:0\", shape=(5109, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_17:0\", shape=(4,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_16:0\", shape=(4, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_conv_11/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_14:0\", shape=(1497,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_13:0\", shape=(1497, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_17:0\", shape=(3636,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_16:0\", shape=(3636, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_20:0\", shape=(5109,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_19:0\", shape=(5109, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/ali/.local/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_23:0\", shape=(4,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Reshape_22:0\", shape=(4, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_5/graph_pool_10/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gb_graph_conv_model_5/Reshape:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "his = model2.fit_generator(data_generator(train_dataset, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3130712.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 13236, 11, 13236, 3940, 4760, 4534, 2, 0, 0, 0, 0, 0, 0, 4\n  y sizes: 1\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [126]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# model.input_shapes = [i.shape for i in x_preprocessed_train]\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_preprocessed_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1653\u001B[0m, in \u001B[0;36m_check_data_cardinality\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1649\u001B[0m   msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m sizes: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1650\u001B[0m       label, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m   1651\u001B[0m                        \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(single_data)))\n\u001B[1;32m   1652\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure all arrays contain the same number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1653\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[0;31mValueError\u001B[0m: Data cardinality is ambiguous:\n  x sizes: 13236, 11, 13236, 3940, 4760, 4534, 2, 0, 0, 0, 0, 0, 0, 4\n  y sizes: 1\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "history = model.fit([x_preprocessed_train], y_train.reshape([1, -1]), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "model.modify_graphgather(len(X) - split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 55.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.7400016784668"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test.reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.220932405998316"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(38.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f474a0e0cc0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'dataset group name', 'Dataset Name', 'Host', 'Guest',\n",
       "       'Ex _G_(kcal/mol)', 'Ex _G_SEM', 'EX _H_(kcal/mol)', 'EX _H_SEM',\n",
       "       'pb_guest_Etot', 'pb_guest_VDWAALS', 'pb_guest_EELEC', 'pb_guest_EPB',\n",
       "       'pb_guest_ECAVITY', 'pb_host_Etot', 'pb_host_VDWAALS', 'pb_host_EELEC',\n",
       "       'pb_host_EPB', 'pb_host_ECAVITY', 'pb_complex_Etot',\n",
       "       'pb_complex_VDWAALS', 'pb_complex_EELEC', 'pb_complex_EPB',\n",
       "       'pb_complex_ECAVITY', 'gb_Complex_Etot', 'gb_Complex_1-4EEL',\n",
       "       'gb_Complex_EELEC', 'gb_Complex_EGB', 'gb_Complex_ESURF',\n",
       "       'gb_guest_Etot', 'gb_guest_1-4EEL', 'gb_guest_EELEC', 'gb_guest_EGB',\n",
       "       'gb_guest_ESURF', 'gb_host_Etot', 'gb_host_1-4EEL', 'gb_host_EELEC',\n",
       "       'gb_host_EGB', 'gb_host_ESURF', 'gb_delta_H', 'pb_delta_H',\n",
       "       'EX _delta_H_(kcal/mol)', 'gb_Ex_difference',\n",
       "       'SQR_gbnsr6_Ex_difference', 'pb_Ex_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.485930943559929"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((df['EX _H_(kcal/mol)'].to_numpy() - df['gb_delta_H'].to_numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6500000000000004"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8.48 - 5.83)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}