{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17170b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import time\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "#K-fold\n",
    "k_fold = 4\n",
    "k = k_fold\n",
    "max_epoch = 100\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c7f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021.03.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb59be0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2615840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89409172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c61ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading molecular data\n",
    "df = pd.read_csv('molecule_parameters.csv')\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b598e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.697637870606162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DDG Standard deviation\n",
    "np.std(df.ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c59241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing entropy and add some noise\n",
    "df['entropy'] = df['entropy'].astype(np.float) + np.random.normal(np.sqrt(df['entropy'].astype(np.float).mean()), 1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642ead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [col for col in df.columns if (col[:3] == 'gb-' and not col.__contains__('etot')) or (col.__contains__('vdwaals'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9826fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb-complex-1-4-eel',\n",
       " 'gb-complex-eelec',\n",
       " 'gb-complex-egb',\n",
       " 'gb-complex-esurf',\n",
       " 'gb-protein-1-4-eel',\n",
       " 'gb-protein-eelect',\n",
       " 'gb-protein-egb',\n",
       " 'gb-protein-esurf',\n",
       " 'gb-ligand-1-4-eel',\n",
       " 'gb-ligand-eelec',\n",
       " 'gb-ligand-egb',\n",
       " 'gb-ligand-esurf',\n",
       " 'pb-complex-vdwaals',\n",
       " 'pb-protein-vdwaals',\n",
       " 'pb-ligand-vdwaals']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7551ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gb-overall-1-4-eel'] = df.apply(lambda row: row['gb-complex-1-4-eel'] - row['gb-protein-1-4-eel'] - row['gb-ligand-1-4-eel'], axis=1)\n",
    "df['gb-overall-eelec'] = df.apply(lambda row: row['gb-complex-eelec'] - row['gb-protein-eelect'] - row['gb-ligand-eelec'], axis=1)\n",
    "df['gb-overall-egb'] = df.apply(lambda row: row['gb-complex-egb'] - row['gb-protein-egb'] - row['gb-ligand-egb'], axis=1)\n",
    "df['gb-overall-esurf'] = df.apply(lambda row: row['gb-complex-esurf'] - row['gb-protein-esurf'] - row['gb-ligand-esurf'], axis=1)\n",
    "df['pb-overall-vdwaals'] = df.apply(lambda row: row['pb-complex-vdwaals'] - row['pb-protein-vdwaals'] - row['pb-ligand-vdwaals'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "245c4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [f for f in df.columns if f.__contains__('overall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0690f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb-overall-1-4-eel',\n",
       " 'gb-overall-eelec',\n",
       " 'gb-overall-egb',\n",
       " 'gb-overall-esurf',\n",
       " 'pb-overall-vdwaals']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de45873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[training_columns]),\n",
    "                   columns=training_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1e27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9fc3811",
   "metadata": {},
   "source": [
    "# Reading PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff6d3421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a1e\n",
      "1a4r\n",
      "1add\n",
      "1a99\n",
      "1a30\n",
      "1a4w\n",
      "1a4k\n",
      "1aaq\n",
      "1a9m\n",
      "1a94\n",
      "1a69\n",
      "PDB file reading runtime is 1.1369648178418477 minutes\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "start = time.time()\n",
    "# Dictionary with complex names as keys and molecule as values\n",
    "PDBs = {}\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# mypath = '../../../../../../Documents/GitHub/Binding-Free-Energy-Prediction-Host-Guest-System/pdbbind/raw-data/'\n",
    "mypath = '../dataset-small/'\n",
    "onlyfiles = [f for f in listdir(mypath) if f not in ('.DS_Store') and f in (df['complex-name'].tolist())]\n",
    "for f in onlyfiles:\n",
    "    print(f)\n",
    "    PDBs.update({f: rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + f + '/com_new.pqr')})\n",
    "\n",
    "for key, value in dict(PDBs).items():\n",
    "    if value is None:\n",
    "        del PDBs[key]\n",
    "time.sleep(1)\n",
    "# end time\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"PDB file reading runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a79b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the PDBs\n",
    "import random\n",
    "l = list(PDBs.items())\n",
    "random.shuffle(l)\n",
    "PDBs = dict(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cafe14",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f4dc72",
   "metadata": {},
   "source": [
    "<h3>PGNNA model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e47d6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "# batch_size = int(len(pdb_names_train)/4)\n",
    "# batch_size\n",
    "# batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7147688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "class PGNNA(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def __init__(self, batch_size):\n",
    "    super(PGNNA, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(64, activation=tf.nn.sigmoid)\n",
    "    self.dense3 = layers.Dense(1)\n",
    "    \n",
    "    ## Dense for overall\n",
    "    self.dense4 = layers.Dense(1, \n",
    "     kernel_initializer=initializers.Constant([.5, 1, 1, 1, 1, 1]),\n",
    "     bias_initializer=initializers.Zeros())\n",
    "#     self.dense4 = layers.Dense(1, \n",
    "#          kernel_initializer=initializers.Constant([.5, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1]),\n",
    "#          bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     x_feat, x_add = inputs[0], inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\n",
    "\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    model_var = self.dense3(model_var)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    ddg = self.dense4(binding_affinity)\n",
    "    tf.print(self.dense4.weights, output_stream=\"file://weights.txt\", summarize=30)\n",
    "    tf.print(binding_affinity[0], output_stream=\"file://binding_a.txt\", summarize=30)\n",
    "    tf.print(ddg[0], output_stream=\"file://ddg.txt\")\n",
    "    tf.print(model_var, output_stream=\"file://model_var.txt\", summarize=30)\n",
    "    tf.print(\"-------------------------\", output_stream=sys.stdout)\n",
    "    return ddg\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "# PGNNA_model = PGNNA(train_split_index)\n",
    "# PGNNA_model.compile(optimizer = \"adam\", loss = root_mean_squared_error)\n",
    "# K.set_value(PGNNA_model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428013ff",
   "metadata": {},
   "source": [
    "<h3> DDA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bd9ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "class DDA(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def __init__(self, batch_size):\n",
    "    super(DDA, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(64, activation=tf.nn.sigmoid)\n",
    "    self.dense3 = layers.Dense(1)\n",
    "    \n",
    "    ## Dense for overall\n",
    "    self.dense4 = layers.Dense(1) \n",
    "#      kernel_initializer=initializers.Constant([.5, 1, 1, 1, 1, 1]),\n",
    "#      bias_initializer=initializers.Zeros())\n",
    "#     self.dense4 = layers.Dense(1, \n",
    "#          kernel_initializer=initializers.Constant([.5, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1]),\n",
    "#          bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     x_feat, x_add = inputs[0], inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\n",
    "\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    model_var = self.dense3(model_var)\n",
    "#     binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "#     ddg = self.dense4(binding_affinity)\n",
    "#     tf.print(self.dense4.weights, output_stream=\"file://weights.txt\", summarize=30)\n",
    "#     tf.print(binding_affinity[0], output_stream=\"file://binding_a.txt\", summarize=30)\n",
    "#     tf.print(ddg[0], output_stream=\"file://ddg.txt\")\n",
    "#     tf.print(model_var, output_stream=\"file://model_var.txt\", summarize=30)\n",
    "#     tf.print(\"-------------------------\", output_stream=sys.stdout)\n",
    "    return model_var\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "# DDA_model = DDA(train_split_index)\n",
    "# DDA_model.compile(optimizer = \"adam\", loss = root_mean_squared_error)\n",
    "# K.set_value(DDA_model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d01702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ee156",
   "metadata": {},
   "source": [
    "# K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8367ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 22:17:58.068201: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGNNA Model Fold # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 22:17:58.765476: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "1/1 [==============================] - 14s 14s/step - loss: 83.2002\n",
      "-------------------------\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.3743\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 82.8952\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 35.4598\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 82.6375\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 35.6531\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 82.3601\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 35.7795\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 82.0961\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 35.9753\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 81.8749\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 36.1458\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 81.6580\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 36.3146\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 81.4152\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 36.4936\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 81.1792\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 36.6265\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 80.9534\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 36.7873\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 80.7420\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 36.9393\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 80.5269\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 37.0738\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 80.3195\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 37.2132\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 80.1344\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 37.3705\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 79.9431\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 37.4775\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 79.7508\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 37.5891\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 79.5725\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 37.6922\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 79.3891\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 37.8313\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 79.2058\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 37.9525\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 79.0335\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 38.0688\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 78.8571\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 38.1761\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 78.6878\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 38.3007\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.5182\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 38.4212\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 78.3531\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 38.5330\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 78.1904\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 38.6616\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 78.0186\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 38.7930\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 77.8567\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 38.8992\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 77.6852\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 39.0345\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 77.5130\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 39.1349\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 77.3519\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 39.2311\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 77.1857\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 39.3239\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 77.0237\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 39.4287\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 76.8548\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 39.5213\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 76.6878\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 39.6182\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 76.5118\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 39.6225\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 76.3442\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 39.6533\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 76.1748\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 39.6642\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 76.0026\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 39.7382\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 75.8355\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 39.7993\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 75.6671\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 39.8164\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 75.4958\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 39.8331\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 75.3268\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 39.8785\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 75.1583\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 39.9284\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step - loss: 74.9898\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 39.9111\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 74.8131\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 39.9960\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 74.6414\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 40.0894\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 74.4652\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 40.1352\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 74.2939\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 40.1404\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 74.1311\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 40.1797\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 73.9391\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 40.2039\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 73.7583\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 40.2694\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 73.5799\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 40.3037\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 73.4022\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 40.4547\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 73.2338\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 40.4683\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 73.0514\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 40.4716\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 72.8746\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 40.5025\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 72.7054\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 40.4614\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 72.5206\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 40.4912\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 72.3598\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 40.5410\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 72.1806\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 40.5715\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 72.0039\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 40.6503\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 71.8206\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 40.7905\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 71.6455\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 40.8314\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 71.4767\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 40.8574\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 71.3014\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 40.8330\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 71.1081\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 40.8583\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 70.9394\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 41.0379\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 70.7601\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 41.0163\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 70.5473\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 40.8360\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 70.3762\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 40.7794\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 70.2409\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 40.5779\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 70.0331\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 40.7416\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 69.8643\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 40.8589\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 69.6742\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 40.8904\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 69.5097\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 41.0654\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 69.3385\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 41.2325\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 69.1652\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 41.2605\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 68.9857\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 41.6660\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 68.8137\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 41.9179\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 68.6354\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 41.9766\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 68.4678\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 42.0234\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 68.2966\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 42.1505\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 68.1285\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 42.3836\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 67.9547\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 41.9720\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 67.7886\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 41.9252\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 67.6335\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 41.6282\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 404ms/step - loss: 67.4569\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 41.5251\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 67.2951\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 41.4614\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 67.1355\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 41.4885\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 66.9639\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 41.4027\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 66.7946\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 41.2539\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 66.6283\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 41.1491\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 66.4666\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 41.0949\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 66.2932\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 41.1285\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 66.1224\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 41.1519\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 65.9558\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 41.3041\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 65.7964\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 41.3343\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 65.6335\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 41.3314\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 65.4740\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 41.2675\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 65.3155\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 41.2838\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 41.2838\n",
      "[41.28376770019531]\n",
      "DDA Model Fold # 0\n",
      "1/1 [==============================] - 14s 14s/step - loss: 8.8124\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7611\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 8.4712\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.7532\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 8.1941\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 8.5405\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 7.8471\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 8.3285\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 7.5834\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 8.2123\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 7.3053\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 7.9721\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 7.0295\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 7.8087\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 6.7579\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 7.7102\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 6.4390\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 7.5479\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 6.1989\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 7.4400\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 5.9293\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 7.2950\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 5.7045\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 7.1099\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 5.5332\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 6.9594\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 5.3295\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 6.8443\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 5.1479\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 6.6841\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 4.9679\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 6.5395\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 4.8504\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 6.4265\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 4.6873\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 6.3054\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 4.5397\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 6.1681\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 4.4021\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 6.0681\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 4.2751\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 5.9440\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 4.1635\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 5.8050\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 4.0671\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 5.6665\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 3.9730\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 5.5715\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 3.8807\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 5.4743\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 3.7957\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 5.3827\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 3.7125\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 5.2422\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 3.6433\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 5.0838\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 3.5724\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 5.0010\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 3.5074\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 4.9203\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 3.4460\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 4.8553\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 3.3934\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 4.7795\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 3.3433\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 4.7063\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 3.2952\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 4.6351\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 3.2465\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 4.5659\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 3.2007\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 4.5220\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 3.1589\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 4.4090\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 3.1177\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 4.3723\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 3.0750\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 4.3138\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 3.0353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 222ms/step - loss: 4.2442\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 2.9965\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 4.1538\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 2.9585\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 4.1170\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 2.9214\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 4.0396\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 2.8854\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 3.9684\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 2.8495\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 3.9167\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 2.8144\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3.8904\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 2.7801\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 3.8404\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 2.7455\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 3.7913\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 2.7117\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 3.7427\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 2.6799\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 3.6948\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 2.6480\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 3.6479\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 2.6163\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 3.6019\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 2.5854\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.5523\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.5549\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.4982\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 2.5242\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 3.4549\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.4945\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 3.4123\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 2.4653\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 3.3328\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 2.4360\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.2923\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 2.4074\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3.2418\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 2.3796\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.2030\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.3521\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 3.1649\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 2.3251\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 3.1275\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 2.2984\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 3.1122\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 2.2723\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.0589\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 2.2466\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 3.0173\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 2.2213\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.9825\n",
      "1/1 [==============================] - 1s 500ms/step - loss: 2.1965\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 2.9289\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1722\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.8806\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 2.1483\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.8706\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 2.1248\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.8345\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.1017\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.8053\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.0791\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.8112\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 2.0570\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.7777\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 2.0352\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.7425\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 2.0140\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 2.7306\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 1.9934\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 2.6990\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 1.9732\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.6620\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 1.9536\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.6291\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.9345\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.5876\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 1.9159\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 2.5616\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 1.8978\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.5362\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.8804\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 2.5110\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.8637\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 2.4772\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.8475\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4541\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 1.8319\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.4178\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.8170\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.3962\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.8026\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.3731\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.7888\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.3529\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.7756\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.3241\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.7630\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.3053\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 1.7509\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.2825\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.7394\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 2.2762\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.7284\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.2591\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.7180\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.2392\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.7081\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.2314\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.6987\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.2159\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 1.6899\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.2014\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.6815\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.1925\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 1.6736\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 2.1786\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 1.6661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 377ms/step - loss: 2.1638\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.1638\n",
      "[2.163783073425293]\n",
      "PGNNA Model Fold # 1\n",
      "-------------------------\n",
      "1/1 [==============================] - 8s 8s/step - loss: 69.3381\n",
      "-------------------------\n",
      "1/1 [==============================] - 2s 2s/step - loss: 103.5636\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 69.1195\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 103.3834\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 68.9187\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 103.2200\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 68.7257\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 102.9966\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 68.5571\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 102.8087\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 68.3645\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 102.6424\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 68.1643\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 102.4485\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 67.9987\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 102.2624\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 67.8215\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 102.0834\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 67.6653\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 101.8975\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 67.5033\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 101.6972\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 67.3485\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 101.5403\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 67.2204\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 101.3886\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 67.0628\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 101.2319\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 66.9154\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 101.0561\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 66.7748\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 100.8918\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 66.6308\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 100.7637\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 66.5021\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 100.6061\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 66.3580\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 100.4658\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 66.2242\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 100.3188\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 66.0825\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 100.1862\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 65.9508\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 100.0548\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 65.8172\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 99.9136\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 65.6725\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 99.7579\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 65.5505\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 99.6017\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 65.3993\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 99.5063\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 65.2524\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 99.3794\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 65.1097\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 99.2468\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 64.9508\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 99.1355\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 64.8015\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 99.0501\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 64.6599\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 98.9261\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 64.5147\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 98.7757\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 64.3871\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 98.7233\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 64.2298\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 98.5712\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 64.0802\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 98.4572\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 63.9338\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 98.3007\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 63.7978\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 98.1819\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 63.6638\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 98.1280\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 63.5309\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 98.0703\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 63.4080\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 97.9584\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 63.2657\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 97.8666\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 63.1198\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 97.7457\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 691ms/step - loss: 62.9759\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 97.5692\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 62.8529\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 97.4339\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 62.6989\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 97.3157\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 62.5254\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 97.1924\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 62.3933\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 97.0761\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 62.2343\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 96.8970\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 62.0917\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 96.6757\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 61.9516\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 96.5621\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 61.8104\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 96.5511\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 61.6591\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 96.4381\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 61.5248\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 96.2465\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 61.3807\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 96.0868\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 61.2261\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 96.0086\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 61.0880\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 95.8999\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 60.9415\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 95.7559\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 60.8187\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 95.6642\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 60.6644\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 95.5125\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 60.5238\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 95.3220\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 60.3896\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 95.2135\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 60.2906\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 95.1038\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 60.1106\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 94.9946\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 59.9697\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 94.8852\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 59.8168\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 94.9248\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 59.6607\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 94.7777\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 59.5101\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 94.6195\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 59.3688\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 94.4341\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 59.2189\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 94.4561\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 59.0742\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 94.3774\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 58.9307\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 94.2480\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 58.7987\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 94.1303\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 58.6593\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 94.0275\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 58.5297\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 94.1151\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 58.3865\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 93.9601\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 58.2882\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 93.7787\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 58.1307\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 93.6731\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 57.9937\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 93.3013\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 57.8620\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 93.1513\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 57.7307\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 92.8633\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 57.5987\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 92.7913\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 57.4327\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 92.7974\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 57.2912\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 92.7275\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 57.1420\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 92.7182\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 57.0147\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 92.7237\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 56.9179\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step - loss: 92.6153\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 56.7773\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 92.4242\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 56.6447\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 92.3816\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 56.5047\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 92.3014\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 56.3668\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 92.2922\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 56.2318\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 92.2247\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 56.1053\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 92.1291\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 55.9791\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 92.0097\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 55.8620\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 91.6280\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 55.7259\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 91.5108\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 55.6033\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 91.3826\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 55.4806\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 91.3020\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 55.3568\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 91.1893\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 55.2324\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 91.0783\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 55.1092\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 90.9688\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 90.9688\n",
      "[41.28376770019531, 90.96882629394531]\n",
      "DDA Model Fold # 1\n",
      "1/1 [==============================] - 11s 11s/step - loss: 9.7774\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.0040\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 9.3901\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.8159\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.0177\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 7.7213\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.6730\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 7.5350\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 8.2855\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 7.3798\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 7.9441\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 7.2543\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 7.6546\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.1493\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 7.4083\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.8536\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 7.1441\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 6.7497\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 6.8743\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 6.6144\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 6.6341\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.4223\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.3865\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.2927\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 6.1647\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 6.1759\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 5.9579\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.0627\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 5.7658\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.9173\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 5.5817\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.7759\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 5.4206\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.6286\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 5.2674\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.5391\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 5.1302\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.4119\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 5.0066\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.2458\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 4.8978\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 5.1345\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 4.8026\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 5.0179\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 4.7029\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.9054\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 4.6216\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.7969\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 4.5415\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.6934\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 4.4674\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.5722\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 4.3960\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 4.4279\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 4.3294\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 4.2905\n",
      "1/1 [==============================] - 1s 730ms/step - loss: 4.2692\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1995\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 4.2121\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1114\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.1564\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 4.0339\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.1046\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.9256\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 4.0536\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.8504\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 4.0089\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.7764\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 3.9593\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.7014\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.9137\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.6410\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8683\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.5705\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 3.8261\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.4597\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 3.7857\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 3.3900\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 3.3270\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 3.7057\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.2779\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 3.6672\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.2186\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 3.6293\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.1609\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 3.5917\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1136\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 3.5550\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 3.0145\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 3.5183\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.9620\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 3.4816\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9108\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 3.4455\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.8609\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 3.4105\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.8119\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 3.3756\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.7643\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 3.3404\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.7121\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 3.3058\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.6600\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 3.2717\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6167\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 3.2373\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.5745\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 3.2032\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.5239\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 3.1695\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4838\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 3.1360\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.4309\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 3.1028\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3897\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 3.0700\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.3530\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 3.0375\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3172\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 3.0054\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.2923\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 2.9735\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.2581\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 2.9419\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.2347\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 2.9105\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2030\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 2.8794\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1710\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 2.8485\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1400\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 2.8179\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.1098\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7872\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 2.0826\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 2.7571\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0543\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 2.7273\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.0269\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 2.6977\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0004\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6683\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.9669\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 2.6392\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.9447\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 2.6103\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9313\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 2.5818\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.9255\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.5535\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.9239\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 2.5255\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.9174\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 2.4978\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.8949\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 2.4704\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.8762\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 2.4432\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.8637\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 2.4164\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.8435\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 2.3898\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.8243\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 2.3635\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8061\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 2.3375\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.7888\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 2.3119\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.7822\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 2.2865\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.7747\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 2.2615\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7672\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 2.2368\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7523\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 2.2124\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7382\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 2.1883\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7188\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 2.1646\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7072\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 2.1412\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6856\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 2.1181\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6765\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 2.0955\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6683\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 2.0731\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6610\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 2.0512\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6546\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 2.0297\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6432\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 2.0085\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.6385\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 1.9878\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6355\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 1.9674\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6335\n",
      "[2.163783073425293, 1.633509635925293]\n",
      "PGNNA Model Fold # 2\n",
      "-------------------------\n",
      "1/1 [==============================] - 16s 16s/step - loss: 82.7971\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 38.8937\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 82.5513\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 39.9125\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 82.3075\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 40.9301\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 82.0616\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 41.9553\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 81.8276\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 42.9721\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 81.5876\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 43.9457\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 81.3712\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 44.9521\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 81.1445\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 45.9438\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 80.9418\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 46.9234\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 80.7424\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 47.8990\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 80.5560\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 48.8699\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 80.3622\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 49.8144\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 80.1805\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 50.7588\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 80.0024\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 51.7044\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 79.8266\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 52.6179\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.6485\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 53.5316\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.4699\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 54.4341\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 79.3022\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 55.3243\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 79.1416\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 56.2011\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 78.9698\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 57.0650\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 78.8034\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 57.9051\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 78.6354\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 58.7343\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 78.4782\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 59.5205\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 78.3171\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 60.3114\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.1612\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 61.0864\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 78.0162\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 61.8436\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 77.8648\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 62.5744\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 77.7151\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 63.2857\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 77.5655\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 63.9740\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 77.4052\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 64.6373\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 77.2503\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 65.2738\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 77.1051\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 65.8884\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 76.9627\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 66.4775\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 76.8201\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 67.0405\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 76.6670\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 67.5793\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 76.5221\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 68.1082\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 76.3796\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 68.6026\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 76.2340\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 69.0599\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 76.0836\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 69.4876\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 769ms/step - loss: 75.9352\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 69.8889\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 75.7965\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 70.2217\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 75.6481\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 70.6591\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 75.5047\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step - loss: 70.9838\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 75.3650\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 71.2822\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 75.2157\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 71.5536\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 75.0729\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 71.7300\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 74.9334\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 71.9223\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 74.7910\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 72.1051\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 74.6280\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 72.2705\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 74.4744\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 72.3937\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 74.3320\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 72.5164\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 74.1920\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 72.6925\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 74.0622\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 72.8632\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 73.9031\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 73.0642\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 73.7502\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 73.1354\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 73.6001\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 73.1800\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 73.4615\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 73.2758\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 73.3101\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 73.2334\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 73.1683\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 73.1499\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 73.0347\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 73.1331\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 72.8797\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 73.0965\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 72.7418\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 73.0964\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 72.6023\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 73.0022\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 72.4547\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 72.9447\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 72.3124\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 72.8688\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 72.1687\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 72.7858\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 72.0320\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 72.7507\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 71.8906\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 72.6234\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 71.7413\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 72.6102\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 71.6053\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 72.5029\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 71.4625\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 72.3870\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 71.3287\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 72.2645\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 71.1873\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 72.2751\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 71.0424\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 72.1413\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 70.9105\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 72.0006\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 70.7696\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 71.8537\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 70.6375\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 71.7961\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 70.4971\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 71.6178\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 70.3583\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 71.3440\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70.2189\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 71.2791\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 70.0810\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 71.0846\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 69.9427\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 70.9048\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 69.8053\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 70.7214\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 69.6715\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 70.5346\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 69.5369\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 70.1808\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 69.4044\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step - loss: 69.8878\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 69.2723\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 69.6613\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 69.1427\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 69.5780\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 69.0135\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 69.4015\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 68.8808\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 69.1539\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 68.7471\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 69.1712\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 68.6160\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 68.9778\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 68.4893\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 68.7525\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 68.3583\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 68.5144\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 68.2279\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 67.9306\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 68.0961\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 67.7128\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 67.9642\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 67.4932\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 67.8335\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 67.1973\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 67.7007\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 66.9718\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 67.5699\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 66.7292\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 66.7292\n",
      "[41.28376770019531, 90.96882629394531, 66.72924041748047]\n",
      "DDA Model Fold # 2\n",
      "1/1 [==============================] - 15s 15s/step - loss: 8.6013\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.7640\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 8.2265\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 7.5539\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 7.8547\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.4175\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 7.4790\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 7.3613\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 7.1951\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 7.2847\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 6.8534\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 7.1255\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 6.5172\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.9597\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 6.2446\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.7931\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 5.9819\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 6.5533\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 5.7374\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 6.4167\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 5.4783\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.3603\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 5.2733\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.0441\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 5.0790\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.8854\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 4.8858\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.7260\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 4.7452\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.5299\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 4.5797\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.3603\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 4.4454\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.2273\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 4.3172\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.1591\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 4.1969\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.0827\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 4.0852\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 4.9565\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 4.0132\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.7995\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 3.9140\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4.6935\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 3.8251\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.6656\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 3.7515\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 4.6318\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.6786\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 4.4810\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 3.6225\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 4.3663\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 3.5554\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 4.2597\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 3.5023\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 4.2686\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 3.4396\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.1621\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 3.3751\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 4.0861\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 3.3208\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 4.0129\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 3.2634\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.9132\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 3.2132\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 3.8157\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 3.1647\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.7456\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 3.1177\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.6530\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 3.0724\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 3.5616\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 3.0276\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.4717\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 2.9862\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.4325\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 2.9455\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.3485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 534ms/step - loss: 2.9045\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2669\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 2.8664\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.1528\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 2.8288\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 3.0752\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 2.7915\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.0007\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 2.7557\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.9188\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 2.7201\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.8459\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 2.6863\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.7744\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 2.6531\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.6900\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 2.6203\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.6169\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 2.5887\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.6117\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 2.5578\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.5315\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 2.5277\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4523\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 2.4984\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.3612\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 2.4693\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.3351\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 2.4406\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.2698\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 2.4128\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.2077\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 2.3860\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.1478\n",
      "1/1 [==============================] - 1s 755ms/step - loss: 2.3600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.0963\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 2.3346\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0401\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 2.3099\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.9834\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2857\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.9273\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2620\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.8723\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 2.2391\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.8181\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 2.2168\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.7793\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 2.1951\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.7315\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 2.1740\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.6799\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 2.1535\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.6293\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 2.1337\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.5795\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 2.1145\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.5307\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 2.0959\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.4883\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 2.0779\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.4931\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 2.0604\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5382\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 2.0435\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.4914\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 2.0272\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.4089\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 2.0115\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3128\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 1.9963\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2659\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 1.9818\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.2500\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 1.9678\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2076\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 1.9543\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.1722\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 1.9414\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2019\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 1.9290\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1703\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 1.9172\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1304\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 1.9059\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0909\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 1.8951\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0520\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 1.8849\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0137\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 1.8751\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9761\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 1.8658\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9393\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 1.8570\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9033\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 1.8486\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8247\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 1.8407\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7287\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 1.8333\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6962\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 1.8262\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7190\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 1.8196\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7587\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 1.8133\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7273\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1.8074\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6968\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8019\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6672\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 1.7968\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6384\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 1.7920\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6104\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1.7876\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5832\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 1.7834\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5570\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 1.7796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5318\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5318\n",
      "[2.163783073425293, 1.633509635925293, 0.5317752361297607]\n",
      "PGNNA Model Fold # 3\n",
      "-------------------------\n",
      "1/1 [==============================] - 8s 8s/step - loss: 77.3681\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 74.7282\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 77.1607\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 74.4761\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 76.9616\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 74.2063\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 76.7965\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 73.9913\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 76.6055\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 73.7764\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 76.4359\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 73.5434\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 76.2778\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 73.3526\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 76.1140\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 73.1292\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 75.9467\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 72.9208\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 75.8022\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 72.6753\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 75.6458\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 72.4332\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 75.4900\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 72.2211\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 75.3333\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 72.0115\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 991ms/step - loss: 75.1964\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 71.7929\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 75.0520\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 71.5868\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 74.9071\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 71.3545\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 74.7808\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 71.1057\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 74.6418\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 70.9147\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 74.5048\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 70.7475\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 74.3629\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 70.5207\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 74.2315\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 70.3221\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 74.1083\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 70.1697\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 73.9804\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 70.0101\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 73.8405\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 69.8252\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 73.7135\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 69.6327\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 73.5777\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 69.4318\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 73.4525\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 69.2428\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 73.3211\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 68.9965\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 73.1876\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 68.8159\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 73.0455\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 68.6217\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 72.9192\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 68.4564\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 72.7764\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 68.2794\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 72.6372\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 68.1012\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 72.4841\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 67.9222\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 72.3476\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 67.7570\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 72.2150\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 67.5844\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 72.0771\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 67.3923\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 71.9400\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 67.1723\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 71.8142\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 67.0271\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 71.6593\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 66.8334\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 71.5366\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 66.5443\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 71.4014\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 66.3978\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 719ms/step - loss: 71.2668\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 66.2353\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 71.1264\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 66.1277\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 70.9774\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 66.0221\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70.8483\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 65.8276\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70.7079\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 65.5834\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 70.5704\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 65.3771\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70.4302\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 65.2426\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 70.3009\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 65.1483\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 70.1670\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 64.9034\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 70.0429\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 64.8041\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 69.9133\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 64.5315\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 69.7779\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 64.3461\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 69.6325\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 64.1647\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 69.5016\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 63.9926\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 69.3546\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 63.9366\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 69.2099\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 63.7990\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 69.0645\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 63.6789\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 68.9319\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 63.5115\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 68.7816\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 63.3144\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 68.6302\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 63.3125\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 68.4804\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 63.2676\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 68.3403\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 63.0750\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 68.2054\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 62.7050\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 68.0543\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 62.5986\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 67.9065\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 62.4435\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 67.7861\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 62.2756\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 755ms/step - loss: 67.6406\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 62.1846\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 67.5094\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 61.8529\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 67.3730\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 61.7644\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 67.2434\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 61.6961\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 774ms/step - loss: 67.1014\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 61.6860\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 66.9704\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 61.3963\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 66.8334\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 61.4168\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 994ms/step - loss: 66.6843\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 61.2747\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 66.5447\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 61.1329\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 66.4132\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 60.9351\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 66.2723\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 60.7941\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 66.1357\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 60.6596\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 994ms/step - loss: 66.0038\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 60.6234\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 65.8702\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 60.4858\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 65.7387\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 60.3483\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 65.6038\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 60.2488\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 65.4712\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 60.1122\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 65.3401\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 59.9041\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 65.2039\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 59.6996\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 65.0723\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 59.5626\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 64.9429\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 59.2020\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 64.8168\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 59.0541\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 64.6915\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 58.7285\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 64.5611\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 58.5404\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 64.4329\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 58.5322\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 64.3050\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 58.4007\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 64.1780\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 58.1172\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 64.0473\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 58.0501\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 63.9210\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 57.9154\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 63.7955\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 57.7594\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 63.6700\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 57.5775\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 63.5438\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 57.5213\n",
      "-------------------------\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 57.5213\n",
      "[41.28376770019531, 90.96882629394531, 66.72924041748047, 57.521331787109375]\n",
      "DDA Model Fold # 3\n",
      "1/1 [==============================] - 14s 14s/step - loss: 8.9623\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2019\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 8.5958\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 9.0743\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 8.2005\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.9067\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 7.8586\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.8149\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 7.5062\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6310\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 7.1869\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.5217\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 6.9370\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.3914\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 6.6237\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.2206\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 6.3681\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0069\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 6.0756\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7822\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 5.8292\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.5738\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 5.5795\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.3847\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 5.3671\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.2319\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 5.1607\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.1183\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 4.9869\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9778\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 4.8275\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.8712\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 4.6589\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.7253\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 4.5396\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6282\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 4.4215\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4554\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 4.2936\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.3132\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 4.1815\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.1999\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 4.0765\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1078\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 3.9827\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9873\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 3.8921\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.8900\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8132\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 5.7474\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7405\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6388\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 3.6708\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.4860\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 3.6066\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.3933\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 3.5484\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.3046\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.4903\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.2159\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 3.4335\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1407\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 3.3796\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 5.0462\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 3.3320\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.9416\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 3.2860\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.8590\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 3.2421\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.7789\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 3.2018\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.7011\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 3.1606\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.6077\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 3.1196\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.4845\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 3.0800\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.4216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 691ms/step - loss: 3.0426\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.3525\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 3.0057\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.2859\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9705\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.2050\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 2.9361\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1421\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 2.9027\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.0458\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 2.8700\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.9858\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 2.8379\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.9279\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 2.8064\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.8845\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 2.7755\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.8205\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 2.7451\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.7667\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 2.7151\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.6852\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 2.6857\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.6417\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 2.6567\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.6049\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 2.6283\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.5680\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 2.6002\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.5193\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 2.5726\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.4605\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 2.5451\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.4493\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 2.5184\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.4029\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 2.4921\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.3533\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 2.4662\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2948\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4406\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 3.2711\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4155\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.2276\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 2.3909\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1749\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 2.3664\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 3.1071\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 2.3427\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0861\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3194\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.0459\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2965\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 3.0065\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 2.2737\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.9860\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2518\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.9477\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2302\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.9100\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 2.2091\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.8729\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1884\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.8334\n",
      "1/1 [==============================] - 1s 760ms/step - loss: 2.1681\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.7929\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 2.1483\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.7579\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 2.1289\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.7235\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 2.1100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.6897\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 2.0916\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.6566\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 2.0737\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6241\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 2.0562\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.5922\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 2.0391\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5643\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 2.0226\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.5406\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0065\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 2.5110\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 1.9908\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.4818\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 1.9757\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.4703\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 1.9610\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.4315\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 1.9467\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.4035\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 1.9330\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.3761\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 1.9197\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3369\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 1.9068\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3049\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 1.8944\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.2796\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 1.8825\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2468\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 1.8710\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.2223\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 1.8600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.1986\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 1.8494\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1717\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 1.8393\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1492\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 1.8295\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.1274\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 1.8202\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.1199\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8114\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1086\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8029\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 2.0945\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 1.7948\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0744\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 1.7871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0686\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0686\n",
      "[2.163783073425293, 1.633509635925293, 0.5317752361297607, 2.068578004837036]\n",
      "Model training and testing runtime is 18.266829534371695 minutes\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRAIN_SET_PERCENTAGE = 1-(1/k)\n",
    "VAL_SET_PERCENTAGE = 1/k\n",
    "PDBs.pop('',None)\n",
    "\n",
    "# PGNNA model variables\n",
    "PGNNA_train_losses = [[] for _ in range(k_fold)]\n",
    "PGNNA_val_losses = [[] for _ in range(k_fold)]\n",
    "PGNNA_rmse_train, PGNNA_rmse_test = [], []\n",
    "\n",
    "# DDA model variables\n",
    "DDA_train_losses = [[] for _ in range(k_fold)]\n",
    "DDA_val_losses = [[] for _ in range(k_fold)]\n",
    "DDA_rmse_train, DDA_rmse_test = [], []\n",
    "\n",
    "# Defining Featurizer\n",
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "\n",
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# k-fold loop\n",
    "for fold in range(k_fold):\n",
    "    # fold=0 -> 0 * (0.25 * 72) = 0\n",
    "    # fold=1 -> 1 * (0.25 * 72) = 18\n",
    "    # fold=2 -> 2 * (0.25 * 72) = 36\n",
    "    # fold=3 -> 3 * (0.25 *72) = 54\n",
    "    X, X_ids, pdb_names_val, pdb_names_test = [], [], [], []\n",
    "    pdb_names_train, X_val_featurized, X_test_featurized, X_train_featurized  = [], [], [], []\n",
    "    \n",
    "\n",
    "    # Featurize PDB's\n",
    "    for i in PDBs.keys():\n",
    "        X_ids.append(i)\n",
    "        X.append(featurizer.featurize(PDBs[i]))\n",
    "\n",
    "    pdb_names = [i.split('-')[0] for i in X_ids]  \n",
    "    TEST_SIZE = int(len(X) * VAL_SET_PERCENTAGE)\n",
    "    val_split_index_begin = int(fold * TEST_SIZE)\n",
    "#     print(f\"begin {val_split_index_begin}\")\n",
    "    val_split_index_end = int(val_split_index_begin) + int(TEST_SIZE)\n",
    "#     print(f\"end {val_split_index_end}\")\n",
    "\n",
    "    # validation\n",
    "    pdb_names_val = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "\n",
    "    # Test set\n",
    "    pdb_names_test = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "    \n",
    "    # Train set\n",
    "    pdb_names_train = [pdb_names[i] for i in range(len(pdb_names)) if i not in range(val_split_index_begin,val_split_index_end)]\n",
    "\n",
    "\n",
    "    X = [x[0] for x in X]\n",
    "    \n",
    "    X_val_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_test_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_train_featurized = [X[i] for i in range(len(X)) if i not in range(val_split_index_begin, val_split_index_end)]\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    x_add_train,x_add_val, x_add_test, y_train,y_val, y_test = [], [], [], [], [], []\n",
    "    # Train\n",
    "    for i in range(len(pdb_names_train)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "        y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_train.append(-new_df[training_columns].to_numpy()[0])\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    # Val\n",
    "    for i in range(len(pdb_names_val)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_val[i])]\n",
    "        y_val.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_val.append(-new_df[training_columns].to_numpy()[0])\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "\n",
    "    # Test\n",
    "    for i in range(len(pdb_names_test)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "    #     print(pdb_names_test[i])\n",
    "    #     print(new_df['ddg'].to_numpy())\n",
    "        y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_test.append(-new_df[training_columns].to_numpy()[0])\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    \n",
    "    x_preprocessed_train, x_preprocessed_test = [], []\n",
    "\n",
    "    ## for X train\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "    x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "    ## for X val\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "    x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "    ## for X test\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "    x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_test.append(np.array(x_add_test))\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    # Training\n",
    "    x_train = np.full([14, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_train):\n",
    "        if len(j.shape) > 1:\n",
    "            x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "    # Validation\n",
    "    x_val = np.full([14, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_val):\n",
    "        if len(j.shape) > 1:\n",
    "            x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "    # Testing\n",
    "\n",
    "    x_test = np.full([14, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_test):\n",
    "        if len(j.shape) > 1:\n",
    "            x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_test = x_test.reshape([1] + list(x_test.shape))\n",
    "    \n",
    "    # Variable initializations for models\n",
    "    \n",
    "    val_size = len(y_val)\n",
    "    train_size = len(y_train)\n",
    "    \n",
    "    # PGNNA Model\n",
    "    batch_size = len(pdb_names_train)\n",
    "    PGNNA_model = PGNNA(len(y_train))\n",
    "    PGNNA_model.compile(optimizer = \"adam\", loss = root_mean_squared_error)\n",
    "    K.set_value(PGNNA_model.optimizer.learning_rate, 0.001)\n",
    "    print(f'PGNNA Model Fold # {fold}')\n",
    "    for epoch in range(max_epoch):\n",
    "        PGNNA_model.modify_graphgather(train_size)\n",
    "        PGNNA_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        PGNNloss = PGNNA_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "        PGNNA_train_losses[fold].append(PGNNloss.history['loss'][0])\n",
    "        PGNNA_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        PGNNA_model.modify_graphgather(val_size)\n",
    "        PGNNA_val_losses[fold].append(PGNNA_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "        \n",
    "    PGNNA_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    PGNNA_model.modify_graphgather(len(y_test))\n",
    "    evalu = PGNNA_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # PGNNA Testing RMSE calculation\n",
    "    PGNNA_rmse_test.append(evalu)\n",
    "    print(PGNNA_rmse_test)\n",
    "    # PGNNA Training RMSE calculation\n",
    "    PGNNA_train_loss = PGNNA_train_losses[fold][-1]\n",
    "    PGNNA_rmse_train.append(PGNNA_train_loss)\n",
    "    \n",
    "    # Data Driven model\n",
    "    DDA_model = DDA(len(y_train))\n",
    "    DDA_model.compile(optimizer = \"adam\", loss = root_mean_squared_error)\n",
    "    K.set_value(DDA_model.optimizer.learning_rate, 0.001)\n",
    "    print(f'DDA Model Fold # {fold}')\n",
    "    for epoch in range(max_epoch):\n",
    "        DDA_model.modify_graphgather(train_size)\n",
    "        DDA_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        DDAloss = DDA_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "        DDA_train_losses[fold].append(DDAloss.history['loss'][0])\n",
    "        DDA_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        DDA_model.modify_graphgather(val_size)\n",
    "        DDA_val_losses[fold].append(DDA_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "    \n",
    "    DDA_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    DDA_model.modify_graphgather(len(y_test))\n",
    "    DDA_evaluate = DDA_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # DDA Testing RMSE calculation\n",
    "    DDA_rmse_test.append(DDA_evaluate)\n",
    "    print(DDA_rmse_test)\n",
    "    # DDA training RMSE calculation\n",
    "    DDA_train_loss = DDA_train_losses[fold][-1]\n",
    "    DDA_rmse_train.append(DDA_train_loss)\n",
    "    \n",
    "time.sleep(1)\n",
    "# end time\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Model training and testing runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2929d32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6219718 ],\n",
       "        [1.1000078 ],\n",
       "        [0.89701515],\n",
       "        [0.9082297 ],\n",
       "        [1.08972   ],\n",
       "        [1.0899081 ]], dtype=float32),\n",
       " array([0.09051859], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the wights after training PGNNA MODEL\n",
    "PGNNA_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be1ddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6661344766616821, 1.967393159866333, 1.7795567512512207, 1.7871183156967163]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDA_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3feac06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average RMSE on Training set\n",
    "average_DDA_rmse_train = sum(DDA_rmse_train) / len(DDA_rmse_train)\n",
    "average_PGNNA_rmse_train = sum(PGNNA_rmse_train) / len(PGNNA_rmse_train)\n",
    "# calculating the average RMSE on Testing set\n",
    "average_DDA_rmse_test = sum(DDA_rmse_test) / len(DDA_rmse_test)\n",
    "average_PGNNA_rmse_test = sum(PGNNA_rmse_test) / len(PGNNA_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86ec60",
   "metadata": {},
   "source": [
    "# Model Performance Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2bf50",
   "metadata": {},
   "source": [
    "<h3>PGNNA Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d218fed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the average of k-fold losses\n",
    "average_PGNNA_train_losses = [sum(x)/len(x) for x in zip(*PGNNA_train_losses)]\n",
    "average_PGNNA_val_losses = [sum(x)/len(x) for x in zip(*PGNNA_val_losses)]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_PGNNA_train_losses)), average_PGNNA_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_PGNNA_val_losses)), average_PGNNA_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.title(\"PGNNA Model\")\n",
    "# Time stamp with date and time\n",
    "time.strftime(\"%Y-%m-%d %H%M%S\")\n",
    "\n",
    "# save plot\n",
    "plt.savefig(\"PGNNA_loss\" + time.strftime(\"%Y-%m-%d %H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4d41d",
   "metadata": {},
   "source": [
    "<h3>DDA Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72d1cedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the average of k-fold losses\n",
    "average_DDA_train_losses = [sum(x)/len(x) for x in zip(*DDA_train_losses)]\n",
    "average_DDA_val_losses = [sum(x)/len(x) for x in zip(*DDA_val_losses)]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_DDA_train_losses)), average_DDA_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_DDA_val_losses)), average_DDA_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.title('DDA Model')\n",
    "# Time stamp with date and time\n",
    "time.strftime(\"%Y-%m-%d %H%M%S\")\n",
    "\n",
    "# save plot\n",
    "plt.savefig(\"DDA_loss\" + time.strftime(\"%Y-%m-%d %H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cefc3ef",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3974a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+\n",
      "|                    Models Comparison                    |\n",
      "+-------------+---------------+------------+--------------+\n",
      "| DDA (TRAIN) | PGNNA (TRAIN) | DDA (TEST) | PGNNA (TEST) |\n",
      "+-------------+---------------+------------+--------------+\n",
      "|     1.80    |     62.88     |    1.60    |    64.13     |\n",
      "+-------------+---------------+------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Models Comparison\"\n",
    "rmse_table.field_names = [\"DDA (TRAIN)\", \"PGNNA (TRAIN)\", \"DDA (TEST)\", \"PGNNA (TEST)\"]\n",
    "rmse_table.add_row([ \"{:.2f}\".format(average_DDA_rmse_train),\"{:.2f}\".format(average_PGNNA_rmse_train),\n",
    "                   \"{:.2f}\".format(average_DDA_rmse_test),\"{:.2f}\".format(average_PGNNA_rmse_test)])\n",
    "\n",
    "print(rmse_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9949ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-deepchem-jupyter",
   "language": "python",
   "name": "rdkit-deepchem-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
