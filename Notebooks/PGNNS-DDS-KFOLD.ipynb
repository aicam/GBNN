{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2418aa36-305a-4890-8db5-efa2ddbfa398",
   "metadata": {},
   "source": [
    "<h1>test on 209 datapoints without any noise </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9245b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import time\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "#K-fold\n",
    "k_fold = 4\n",
    "k = k_fold\n",
    "max_epoch = 100\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7cb7db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021.09.3'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55e66389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5dcd3310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.4'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23b2d7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5c79403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading molecular data\n",
    "df = pd.read_csv('molecule_parameters.csv')\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1de144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.697637870606162"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DDG Standard deviation\n",
    "np.std(df.ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b293820-dbc0-46dc-a50f-476c71ab9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-34.07407324'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entropy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06c51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing entropy and add some noise\n",
    "# df['entropy'] = df['entropy'].astype(float) + np.random.normal(np.sqrt(df['entropy'].astype(float).mean()), 1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "464c758b-2918-4ee7-8154-107187787a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['entropy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1112109",
   "metadata": {},
   "source": [
    "# Reading PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66dad05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1bcd\n",
      "1gnm\n",
      "1ajp\n",
      "1amw\n",
      "1j4r\n",
      "1ajn\n",
      "1dgm\n",
      "1hi5\n",
      "1hwr\n",
      "1c5x\n",
      "1jak\n",
      "1cgl\n",
      "1bnv\n",
      "1b8y\n",
      "1hmt\n",
      "1b4h\n",
      "1gfy\n",
      "1ghw\n",
      "1apv\n",
      "1a4k\n",
      "1b51\n",
      "1bhf\n",
      "1d4p\n",
      "1bhx\n",
      "1hk4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:49:43] Explicit valence for atom # 4629 O, 3, is greater than permitted\n",
      "RDKit ERROR: [15:49:43] Explicit valence for atom # 4629 O, 3, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1gpn\n",
      "1a9m\n",
      "1iih\n",
      "1afk\n",
      "1hih\n",
      "1ik4\n",
      "1d3d\n",
      "1afl\n",
      "1gi7\n",
      "1d3p\n",
      "1bzy\n",
      "1j36\n",
      "1bm7\n",
      "1iiq\n",
      "1bwa\n",
      "1cet\n",
      "1ghz\n",
      "1if8\n",
      "1c87\n",
      "1hms\n",
      "1hvh\n",
      "1b3h\n",
      "1a4r\n",
      "1bnq\n",
      "1b32\n",
      "1ii5\n",
      "1hpx\n",
      "1j17\n",
      "1c70\n",
      "1hyo\n",
      "1d6v\n",
      "1bxr\n",
      "1hpv\n",
      "1a94\n",
      "1c5q\n",
      "1b5h\n",
      "1gnn\n",
      "1c5o\n",
      "1ikt\n",
      "1cnx\n",
      "1bnu\n",
      "1b6j\n",
      "1b8n\n",
      "1dhi\n",
      "1ai5\n",
      "1hvr\n",
      "1a69\n",
      "1bn1\n",
      "1b3f\n",
      "1gai\n",
      "1b3l\n",
      "1hvl\n",
      "1hxb\n",
      "1c83\n",
      "1alw\n",
      "1bzc\n",
      "1aj7\n",
      "1b58\n",
      "1d4y\n",
      "1aaq\n",
      "1bty\n",
      "1ctt\n",
      "1b52\n",
      "1b9j\n",
      "1b55\n",
      "1gi4\n",
      "1hp5\n",
      "1igb\n",
      "1ie9\n",
      "1hvk\n",
      "1gj6\n",
      "1c84\n",
      "1ghy\n",
      "1c4u\n",
      "1bwb\n",
      "1c3x\n",
      "1b46\n",
      "1izi\n",
      "1bgq\n",
      "1b2h\n",
      "1hpo\n",
      "1j14\n",
      "1add\n",
      "1a99\n",
      "1cnw\n",
      "1df8\n",
      "1a30\n",
      "1ciz\n",
      "1b1h\n",
      "1hos\n",
      "1bnn\n",
      "1hn4\n",
      "1hps\n",
      "1bdq\n",
      "1adl\n",
      "1bju\n",
      "1ajv\n",
      "1d6w\n",
      "1j16\n",
      "1bq4\n",
      "1i1e\n",
      "1igj\n",
      "1hii\n",
      "1bv9\n",
      "1bai\n",
      "1b57\n",
      "1det\n",
      "1b4z\n",
      "1ivp\n",
      "1gar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:51:50] Explicit valence for atom # 940 O, 3, is greater than permitted\n",
      "RDKit ERROR: [15:51:50] Explicit valence for atom # 940 O, 3, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1br6\n",
      "1d7j\n",
      "1cbx\n",
      "1bn4\n",
      "1hmr\n",
      "1c86\n",
      "1gaf\n",
      "1hvi\n",
      "1bn3\n",
      "1cps\n",
      "1d9i\n",
      "1ai7\n",
      "1ghv\n",
      "1atl\n",
      "1gi1\n",
      "1ajq\n",
      "1bma\n",
      "1grp\n",
      "1b5j\n",
      "1hi4\n",
      "1c5y\n",
      "1c5s\n",
      "1b6h\n",
      "1hsh\n",
      "1gjc\n",
      "1bp0\n",
      "1bnw\n",
      "1hsl\n",
      "1b6l\n",
      "1izh\n",
      "1d2e\n",
      "1c1r\n",
      "1c5c\n",
      "1bjv\n",
      "1ado\n",
      "1bcu\n",
      "1b0h\n",
      "1d4k\n",
      "1i37\n",
      "1gpk\n",
      "1ceb\n",
      "1hvj\n",
      "1d7i\n",
      "1if7\n",
      "1hvs\n",
      "1ai4\n",
      "1hxw\n",
      "1b3g\n",
      "1c88\n",
      "1a4w\n",
      "1j01\n",
      "1d4l\n",
      "1bv7\n",
      "1iy7\n",
      "1b7h\n",
      "1ctu\n",
      "1ax0\n",
      "1c5p\n",
      "1hlk\n",
      "1ajx\n",
      "1c5n\n",
      "1gno\n",
      "1b5i\n",
      "1b05\n",
      "1avn\n",
      "1aid\n",
      "1cny\n",
      "1bnt\n",
      "1d09\n",
      "1c1u\n",
      "1a1e\n",
      "1b8o\n",
      "1b40\n",
      "1b6k\n",
      "PDB file reading runtime is 4.693575191497803 minutes\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "start = time.time()\n",
    "# Dictionary with complex names as keys and molecule as values\n",
    "PDBs = {}\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# mypath = '../../../../../../Documents/GitHub/Binding-Free-Energy-Prediction-Host-Guest-System/pdbbind/raw-data/'\n",
    "mypath = 'dataset234/'\n",
    "onlyfiles = [f for f in listdir(mypath) if f not in ('.DS_Store') and f in (df['complex-name'].tolist())]\n",
    "for f in onlyfiles:\n",
    "    print(f)\n",
    "    PDBs.update({f: rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + f + '/com_new.pqr')})\n",
    "\n",
    "for key, value in dict(PDBs).items():\n",
    "    if value is None:\n",
    "        del PDBs[key]\n",
    "time.sleep(1)\n",
    "# end time\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"PDB file reading runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50c4732a-e78e-4dfe-9aa5-f9fe582b5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save PDB\n",
    "import pickle\n",
    "with open('PDBs-234.pkl', 'wb') as file:\n",
    "    pickle.dump(PDBs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fedd496a-bcd2-4d0f-a36b-927c450274d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load PDB\n",
    "# import pickle\n",
    "# PDBs = {}\n",
    "# with open('PDBs-200.pkl', 'rb') as file:\n",
    "#     PDBs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c287b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the PDBs\n",
    "import random\n",
    "l = list(PDBs.items())\n",
    "random.shuffle(l)\n",
    "PDBs = dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bec9a04d-7ef6-4bcb-855b-8f88003a3210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4773b4b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2808df",
   "metadata": {},
   "source": [
    "<h3>PGNNS model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b458c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "# batch_size = int(len(pdb_names_train)/4)\n",
    "# batch_size\n",
    "# batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e277cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class PGNNS(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(PGNNS, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([0.5, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 16])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    return self.dense3(binding_affinity)\n",
    "# PGNNS = PGNNS(train_split_index)\n",
    "# PGNNS.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79090058",
   "metadata": {},
   "source": [
    "<h3> DDS</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b4ce35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# batch_size = int(len(df) / 2)\n",
    "\n",
    "class DDS(tf.keras.Model):\n",
    "   \n",
    "    def modify_graphgather(self, batch_size):\n",
    "        self.readout.batch_size = batch_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        super(DDS, self).__init__()\n",
    "        self.input_shapes = None\n",
    "        self.batch_size = batch_size\n",
    "        self.gc1 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.gp1 = GraphPool()\n",
    "\n",
    "        self.gc2 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.gp2 = GraphPool()\n",
    "\n",
    "        self.dense1 = layers.Dense(64, activation=tf.nn.tanh)\n",
    "        self.batch_norm3 = layers.BatchNormalization()\n",
    "        self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "        self.dense2 = layers.Dense(1)\n",
    "    #     self.dense3 = layers.Dense(1, \n",
    "    #          kernel_initializer=initializers.Constant([.5, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
    "    #          bias_initializer=initializers.Zeros())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = inputs[0]\n",
    "        x = []\n",
    "    #     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "    #                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "        for i in range(len(self.input_shapes)):\n",
    "            x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "        for i in range(1, len(self.input_shapes)):\n",
    "            x[i] = tf.cast(x[i], tf.int32)\n",
    "        x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 16])\n",
    "        gc1_output = self.gc1(x)\n",
    "        batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "        gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "        gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "        batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "        gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "        dense1_output = self.dense1(gp2_output)\n",
    "        batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "        readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "\n",
    "        model_var = self.dense2(readout_output)\n",
    "    #     binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "        return model_var #self.dense3(binding_affinity)\n",
    "# DDS_model = DDS(train_split_index)\n",
    "# DDS_model.compile(loss='mse', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "32c45a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df587495-c087-43fd-8488-7ce14d61b64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a06ba8",
   "metadata": {},
   "source": [
    "# K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2bdbf0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGNNS Model Fold # 0\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.6671\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16455.1758\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16573.6562\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1077.4589\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1085.7816\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 3575.3525\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3564.9988\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 9595.3857\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9541.8682\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 7270.6372\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7228.2310\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 2125.6372\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2092.8538\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 23.7577\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.5947\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1968.3721\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2009.8713\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4434.9741\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4502.0591\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 4361.7651\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4419.3467\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2226.5972\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2261.5493\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 326.1553\n",
      "1/1 [==============================] - 2s 2s/step - loss: 333.7322\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 206.4428\n",
      "1/1 [==============================] - 2s 2s/step - loss: 200.2715\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1482.7289\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1471.8212\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2517.8074\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2498.6489\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 2239.2913\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2215.8542\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1062.6980\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1040.6927\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 129.3251\n",
      "1/1 [==============================] - 2s 2s/step - loss: 120.1311\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 159.8141\n",
      "1/1 [==============================] - 2s 2s/step - loss: 166.7987\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 865.6116\n",
      "1/1 [==============================] - 2s 2s/step - loss: 880.8019\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1371.5287\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1383.6555\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1154.8296\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1161.8237\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 494.0817\n",
      "1/1 [==============================] - 2s 2s/step - loss: 496.7805\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 43.6876\n",
      "1/1 [==============================] - 2s 2s/step - loss: 42.5830\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 151.9222\n",
      "1/1 [==============================] - 2s 2s/step - loss: 147.8692\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 574.3297\n",
      "1/1 [==============================] - 2s 2s/step - loss: 567.1989\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 797.6461\n",
      "1/1 [==============================] - 2s 2s/step - loss: 786.4963\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 595.0947\n",
      "1/1 [==============================] - 2s 2s/step - loss: 583.1486\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 207.3153\n",
      "1/1 [==============================] - 2s 2s/step - loss: 197.8632\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 17.9112\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.5302\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 150.0252\n",
      "1/1 [==============================] - 2s 2s/step - loss: 157.1523\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 379.0319\n",
      "1/1 [==============================] - 2s 2s/step - loss: 394.0004\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 422.8242\n",
      "1/1 [==============================] - 2s 2s/step - loss: 437.7526\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 242.8467\n",
      "1/1 [==============================] - 2s 2s/step - loss: 252.4365\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 50.2055\n",
      "1/1 [==============================] - 2s 2s/step - loss: 52.0391\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 38.9262\n",
      "1/1 [==============================] - 2s 2s/step - loss: 33.6357\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 178.6685\n",
      "1/1 [==============================] - 2s 2s/step - loss: 168.3436\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 280.4923\n",
      "1/1 [==============================] - 2s 2s/step - loss: 266.6983\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 225.2922\n",
      "1/1 [==============================] - 2s 2s/step - loss: 211.9335\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 86.4105\n",
      "1/1 [==============================] - 2s 2s/step - loss: 77.5062\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 17.6826\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.2738\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 68.6001\n",
      "1/1 [==============================] - 2s 2s/step - loss: 72.0689\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 145.3470\n",
      "1/1 [==============================] - 2s 2s/step - loss: 151.8870\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 143.2496\n",
      "1/1 [==============================] - 2s 2s/step - loss: 149.3706\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 70.1193\n",
      "1/1 [==============================] - 2s 2s/step - loss: 73.0349\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 18.6689\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.1776\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 42.9578\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.1557\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 97.9255\n",
      "1/1 [==============================] - 2s 2s/step - loss: 89.1642\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 108.5145\n",
      "1/1 [==============================] - 2s 2s/step - loss: 99.2100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 63.8553\n",
      "1/1 [==============================] - 2s 2s/step - loss: 56.7445\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 21.7784\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.0135\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 26.0290\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.4535\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 56.5758\n",
      "1/1 [==============================] - 2s 2s/step - loss: 57.6334\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 64.5684\n",
      "1/1 [==============================] - 2s 2s/step - loss: 66.1030\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 40.3116\n",
      "1/1 [==============================] - 2s 2s/step - loss: 40.7816\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 18.5871\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.7611\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 25.8556\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.6647\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 46.9786\n",
      "1/1 [==============================] - 2s 2s/step - loss: 41.5300\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 50.9083\n",
      "1/1 [==============================] - 2s 2s/step - loss: 45.3560\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 33.4255\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.7695\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 18.3881\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.2818\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 22.0911\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.4952\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 33.1306\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.4657\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 33.0897\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.2927\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 22.6535\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.9623\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 17.6597\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.7456\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 24.1846\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.1555\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 31.1235\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.5619\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 28.3072\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.8411\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 20.3285\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.6241\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 17.8039\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.1040\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 21.3690\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.6955\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 23.3746\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.0405\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 20.3551\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.5233\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 17.5746\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.7582\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 19.6526\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.7594\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 23.2894\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.7404\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 23.1723\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.5234\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 19.6320\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.6205\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 17.5084\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.4948\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 18.4051\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.1952\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 19.1330\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.3425\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 18.1930\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.0302\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 17.5163\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.4584\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 18.8961\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.8741\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 20.6000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.0645\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 20.4653\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.8565\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 18.6122\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.6366\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 17.5064\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.3429\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 17.6373\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.1206\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 17.8197\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.4052\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 17.6152\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.7088\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 17.7294\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.2067\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 18.5358\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.5750\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 19.1716\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.9540\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 18.6490\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.6380\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 17.6966\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.1850\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 17.3076\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.2794\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 17.3254\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.5998\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 17.3108\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 17.3108\n",
      "[4.16062754079275]\n",
      "DDS Model Fold # 0\n",
      "1/1 [==============================] - 5s 5s/step - loss: 88.6619\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 90.0748\n",
      "1/1 [==============================] - 2s 2s/step - loss: 84.1529\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 86.7417\n",
      "1/1 [==============================] - 1s 1s/step - loss: 77.8271\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 83.4107\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70.9209\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 82.1191\n",
      "1/1 [==============================] - 1s 1s/step - loss: 65.5806\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 82.5735\n",
      "1/1 [==============================] - 1s 1s/step - loss: 61.6780\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 84.6819\n",
      "1/1 [==============================] - 1s 1s/step - loss: 57.9931\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 85.0932\n",
      "1/1 [==============================] - 1s 1s/step - loss: 53.9674\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 84.9533\n",
      "1/1 [==============================] - 2s 2s/step - loss: 49.6924\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 85.3355\n",
      "1/1 [==============================] - 2s 2s/step - loss: 45.0603\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 84.8110\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.8968\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 84.2396\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.3167\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 83.3002\n",
      "1/1 [==============================] - 2s 2s/step - loss: 34.2517\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 81.3065\n",
      "1/1 [==============================] - 1s 1s/step - loss: 30.9448\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 79.0981\n",
      "1/1 [==============================] - 1s 1s/step - loss: 28.5157\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 76.1182\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.9713\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 74.3863\n",
      "1/1 [==============================] - 1s 1s/step - loss: 23.2921\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 74.2487\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.6610\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 76.8102\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.2391\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 76.7398\n",
      "1/1 [==============================] - 1s 1s/step - loss: 15.9575\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 76.9133\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.1801\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 74.2659\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.7765\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 73.1960\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.7529\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 73.4118\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.9378\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 72.0434\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.4355\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 70.4636\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.0977\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 68.9274\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.9197\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 67.6967\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7106\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 66.7943\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6024\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 65.2363\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5710\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 64.5398\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5658\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 63.8924\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5720\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 63.2828\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6130\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 62.6374\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6473\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 62.1083\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6948\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 61.6298\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7260\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 61.3636\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7205\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 61.1824\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7348\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 60.7416\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7197\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 60.0062\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7044\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 59.4739\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6829\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 58.9873\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6630\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 58.7428\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6275\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 58.2245\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5850\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 57.4872\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5469\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 56.6037\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5046\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 56.2859\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4617\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 55.1280\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4103\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 53.0387\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3662\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 51.7066\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.3240\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 51.4913\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2787\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 50.6513\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2413\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 50.1555\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2037\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 49.5442\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1748\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 49.2327\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.1504\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 48.8562\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1295\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 48.6296\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.1135\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 48.4723\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0959\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 48.2997\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0801\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 48.0179\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.0655\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 47.9812\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0543\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 47.4897\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0446\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 47.2203\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0358\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 47.0472\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0266\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 46.7023\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0194\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 46.5375\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0132\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 46.6950\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0092\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 46.1392\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.0047\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 45.7780\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0002\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 45.4454\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9969\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 45.1606\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9908\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 45.1807\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9887\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 45.4094\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9864\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 45.1351\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9844\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 44.9462\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9817\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 45.1624\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9782\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 45.2822\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9766\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 45.3566\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9755\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 45.5564\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9738\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 45.7261\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9718\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 45.9692\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9693\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 45.8834\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9637\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 45.9492\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9587\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 46.1295\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9552\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 46.3667\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9530\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 46.5281\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9510\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 46.6085\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9493\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 46.6188\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9476\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 46.6331\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9459\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 46.7969\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9440\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 46.8668\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9420\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 47.1748\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9403\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 47.4958\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9379\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 47.5137\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9332\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 47.4937\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9278\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 47.4711\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9260\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 47.3085\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9245\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 46.9093\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9226\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 46.4426\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9195\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 46.6030\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9173\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 46.6329\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 46.6329\n",
      "[6.8288316862921015]\n",
      "PGNNS Model Fold # 1\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.8638\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41563.5195\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26661.9902\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 19.5475\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.5778\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 34092.1914\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21916.4746\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 28605.0781\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18369.1914\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 2399.1589\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1544.1842\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 7989.2544\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5131.7534\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 23964.6797\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15336.4443\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 14910.3281\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9529.3418\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 869.0916\n",
      "1/1 [==============================] - 2s 2s/step - loss: 552.9321\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4908.9609\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3167.9553\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 14715.7207\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9427.5859\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 10927.6025\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6973.9722\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 1497.4249\n",
      "1/1 [==============================] - 2s 2s/step - loss: 950.1371\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1581.2111\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1031.3931\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 8139.7612\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5247.4346\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 8368.0049\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5393.2344\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 2461.6807\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1590.4404\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 151.1545\n",
      "1/1 [==============================] - 2s 2s/step - loss: 98.0307\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 3740.1528\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2393.3103\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 5910.7134\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3784.2581\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 3090.1919\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1978.6200\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 137.9234\n",
      "1/1 [==============================] - 2s 2s/step - loss: 89.1414\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 1190.8363\n",
      "1/1 [==============================] - 2s 2s/step - loss: 773.3109\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 3492.0527\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2255.6404\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2938.4001\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1895.2524\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 639.4226\n",
      "1/1 [==============================] - 2s 2s/step - loss: 413.9274\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 181.2943\n",
      "1/1 [==============================] - 2s 2s/step - loss: 118.8018\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1681.3894\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1084.0643\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 2255.7666\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1456.0793\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1015.5312\n",
      "1/1 [==============================] - 2s 2s/step - loss: 658.8312\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 27.8175\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.0555\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 606.1860\n",
      "1/1 [==============================] - 2s 2s/step - loss: 387.4121\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1443.9585\n",
      "1/1 [==============================] - 2s 2s/step - loss: 917.8175\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1089.1877\n",
      "1/1 [==============================] - 2s 2s/step - loss: 690.5892\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 196.6571\n",
      "1/1 [==============================] - 2s 2s/step - loss: 124.0856\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 121.0322\n",
      "1/1 [==============================] - 2s 2s/step - loss: 84.6283\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 720.9885\n",
      "1/1 [==============================] - 2s 2s/step - loss: 474.9595\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 851.5080\n",
      "1/1 [==============================] - 2s 2s/step - loss: 561.4156\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 327.6290\n",
      "1/1 [==============================] - 2s 2s/step - loss: 220.7434\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 19.0118\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.9833\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 314.5454\n",
      "1/1 [==============================] - 2s 2s/step - loss: 197.4714\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 602.2999\n",
      "1/1 [==============================] - 2s 2s/step - loss: 377.8855\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 394.8782\n",
      "1/1 [==============================] - 2s 2s/step - loss: 246.6654\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 57.9151\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.0027\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 86.9033\n",
      "1/1 [==============================] - 2s 2s/step - loss: 63.0867\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 320.5213\n",
      "1/1 [==============================] - 2s 2s/step - loss: 217.0695\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 317.4772\n",
      "1/1 [==============================] - 2s 2s/step - loss: 214.8043\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 98.3329\n",
      "1/1 [==============================] - 2s 2s/step - loss: 70.2459\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 27.0972\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.9994\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 173.5611\n",
      "1/1 [==============================] - 2s 2s/step - loss: 108.5082\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 253.9114\n",
      "1/1 [==============================] - 2s 2s/step - loss: 158.3062\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 137.1249\n",
      "1/1 [==============================] - 2s 2s/step - loss: 85.3845\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 22.0684\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.1638\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 65.6612\n",
      "1/1 [==============================] - 2s 2s/step - loss: 48.7773\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 147.3936\n",
      "1/1 [==============================] - 2s 2s/step - loss: 103.4611\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 114.7122\n",
      "1/1 [==============================] - 2s 2s/step - loss: 81.6460\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 30.9729\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.7093\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 34.0481\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.8088\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 100.3471\n",
      "1/1 [==============================] - 2s 2s/step - loss: 62.6703\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 108.4409\n",
      "1/1 [==============================] - 2s 2s/step - loss: 67.4893\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 48.7933\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.3994\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 18.5007\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.1089\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 48.6408\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.0637\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 69.5703\n",
      "1/1 [==============================] - 3s 3s/step - loss: 51.1928\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 43.1049\n",
      "1/1 [==============================] - 2s 2s/step - loss: 33.0783\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 18.4500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.9328\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 35.1390\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.3054\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 58.8925\n",
      "1/1 [==============================] - 2s 2s/step - loss: 37.2756\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 48.6016\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.0625\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 23.2325\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.5088\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 20.7958\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.0661\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 34.7447\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.3949\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 34.7597\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.3425\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 21.6832\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.6179\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 19.9428\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.7942\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 31.7268\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.0915\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 35.9470\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.4517\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.1771\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.8751\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 18.4455\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.2413\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 21.5783\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.4649\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 25.2261\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.2761\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 21.6320\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.5002\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 18.2990\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.2479\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 22.0706\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.4920\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 26.7748\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.9011\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 24.8302\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.8413\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 19.6898\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.3882\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 18.4936\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.5684\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 20.2776\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.2954\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 20.0941\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.1064\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 18.4313\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.4281\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 19.2499\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.1474\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 21.9190\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.2704\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 22.3460\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.4713\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 20.0750\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.4117\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 18.3955\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.9809\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 18.6533\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.6377\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 18.9294\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.9318\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 18.4132\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.2971\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 18.6159\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 18.6159\n",
      "[4.16062754079275, 4.314613819367652]\n",
      "DDS Model Fold # 1\n",
      "1/1 [==============================] - 5s 5s/step - loss: 106.9287\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 100.7012\n",
      "1/1 [==============================] - 2s 2s/step - loss: 96.0710\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 92.3094\n",
      "1/1 [==============================] - 1s 1s/step - loss: 87.6192\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 82.5804\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.1105\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 74.0969\n",
      "1/1 [==============================] - 2s 2s/step - loss: 73.7934\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 69.8291\n",
      "1/1 [==============================] - 2s 2s/step - loss: 64.5801\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 64.9351\n",
      "1/1 [==============================] - 1s 1s/step - loss: 54.9674\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 60.2102\n",
      "1/1 [==============================] - 1s 1s/step - loss: 47.3967\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 58.2232\n",
      "1/1 [==============================] - 1s 1s/step - loss: 39.6227\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 54.5064\n",
      "1/1 [==============================] - 2s 2s/step - loss: 33.8216\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 50.4979\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.8711\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 49.7778\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.7684\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 46.3549\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.9671\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 44.5200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.6952\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 43.9683\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.3521\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 42.9677\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.3757\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 40.2775\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.2630\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 37.4106\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.3695\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 35.5678\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.0706\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 36.5890\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.8146\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 36.7120\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.7218\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 36.8365\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.7823\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 36.1997\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.7920\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 35.7141\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.7776\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 35.2821\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.8554\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 34.5953\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.8509\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 34.4242\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.7716\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 34.6686\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.6070\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 34.9539\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.4736\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 34.8560\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.3185\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 34.8332\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.1525\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 34.7108\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.9722\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 34.8061\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.8049\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 35.3742\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.6425\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 35.6327\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.5172\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 35.7600\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3864\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 36.2435\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2875\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 36.5272\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2040\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 36.9127\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1166\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 37.1383\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0611\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 37.2035\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0054\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 37.1410\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9764\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 37.1620\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9492\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 37.2855\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9246\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 37.8170\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9089\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 37.9410\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8961\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 38.2616\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8864\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 38.4223\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8894\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 38.6223\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8871\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 38.7065\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8828\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 38.7610\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8801\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 38.8848\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8742\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 38.8084\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.8605\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 38.8954\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8460\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 39.0512\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8328\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 39.2920\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.8157\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 39.5557\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7943\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 39.6501\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7780\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 39.4992\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7653\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 39.4912\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7579\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 39.5417\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7489\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 39.5049\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7339\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 39.2919\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7243\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 39.1237\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7028\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 38.8625\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6830\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 38.7608\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6749\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 38.4265\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6688\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 38.1868\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6576\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 37.9885\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6490\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 37.8878\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6407\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 37.7424\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6391\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 37.5176\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6258\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 37.5089\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6185\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 37.1914\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5986\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 37.0568\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5940\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 36.8060\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5929\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 36.4576\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5802\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 36.0572\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5833\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 35.8832\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5445\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 36.1505\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4853\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 36.2166\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4746\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 36.1863\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.4777\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 36.0033\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4689\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 35.9072\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4716\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 35.8251\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4640\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 35.9398\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.4567\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 35.9965\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.4518\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 35.9106\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4489\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 35.8107\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4458\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 35.6788\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4424\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 35.7896\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4412\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 35.7696\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4394\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 35.6537\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4362\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 35.5302\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4349\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 35.7262\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4336\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 35.4569\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4324\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 35.3651\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.4311\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 35.2006\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4294\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 34.7400\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4280\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 34.7394\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4259\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 34.7171\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 34.7171\n",
      "[6.8288316862921015, 5.8921259174552985]\n",
      "PGNNS Model Fold # 2\n",
      "1/1 [==============================] - 10s 10s/step - loss: 18.0334\n",
      "1/1 [==============================] - 1s 1s/step - loss: 49008.0352\n",
      "1/1 [==============================] - 2s 2s/step - loss: 57156.1289\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 15.9056\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.3758\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 39692.2109\n",
      "1/1 [==============================] - 2s 2s/step - loss: 46613.1133\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 33618.5938\n",
      "1/1 [==============================] - 2s 2s/step - loss: 39416.4180\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2958.6970\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3469.1226\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 9068.8145\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10564.8154\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 27960.5078\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32620.8691\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 17834.3145\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20823.7637\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 1198.5070\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1384.2736\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 5302.7012\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6235.9575\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 16897.4238\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19809.1602\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 13133.4180\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15365.2471\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 2121.4353\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2440.4421\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1449.5612\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1731.7977\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 8987.0098\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10596.5049\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 10028.6523\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11808.6670\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 3419.8232\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4025.6770\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 51.1925\n",
      "1/1 [==============================] - 2s 2s/step - loss: 56.2141\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 3763.9570\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4381.7759\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 6863.3540\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7982.6665\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 4193.9775\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4846.3369\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 395.9955\n",
      "1/1 [==============================] - 2s 2s/step - loss: 443.2192\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 901.8591\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1079.8810\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 3672.7871\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4354.1494\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 3711.3472\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4396.6279\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1168.0349\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1389.7513\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 45.0900\n",
      "1/1 [==============================] - 2s 2s/step - loss: 46.8990\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1508.5190\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1734.5750\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 2665.8535\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3078.6943\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1645.8571\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1892.7466\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 177.0352\n",
      "1/1 [==============================] - 2s 2s/step - loss: 195.6897\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 329.4431\n",
      "1/1 [==============================] - 2s 2s/step - loss: 395.6429\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1395.4423\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1653.7206\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1461.3231\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1733.5966\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 496.2103\n",
      "1/1 [==============================] - 2s 2s/step - loss: 592.9402\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 21.2687\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.0066\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 559.2088\n",
      "1/1 [==============================] - 2s 2s/step - loss: 637.7903\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1038.6176\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1193.9434\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 679.2831\n",
      "1/1 [==============================] - 2s 2s/step - loss: 776.5237\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 94.6952\n",
      "1/1 [==============================] - 2s 2s/step - loss: 102.9204\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 117.7819\n",
      "1/1 [==============================] - 2s 2s/step - loss: 142.5116\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 526.7277\n",
      "1/1 [==============================] - 2s 2s/step - loss: 631.3458\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 578.4534\n",
      "1/1 [==============================] - 2s 2s/step - loss: 691.8325\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 213.0118\n",
      "1/1 [==============================] - 2s 2s/step - loss: 257.0775\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 16.7574\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.5019\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 220.3395\n",
      "1/1 [==============================] - 2s 2s/step - loss: 245.2023\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 416.5682\n",
      "1/1 [==============================] - 2s 2s/step - loss: 470.7233\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 284.6717\n",
      "1/1 [==============================] - 2s 2s/step - loss: 318.6609\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 51.1136\n",
      "1/1 [==============================] - 2s 2s/step - loss: 53.0340\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 51.2542\n",
      "1/1 [==============================] - 2s 2s/step - loss: 62.0223\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 209.3067\n",
      "1/1 [==============================] - 2s 2s/step - loss: 252.5447\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 232.1385\n",
      "1/1 [==============================] - 2s 2s/step - loss: 279.2158\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 91.2322\n",
      "1/1 [==============================] - 2s 2s/step - loss: 110.2627\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 16.2877\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.9428\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 98.3144\n",
      "1/1 [==============================] - 2s 2s/step - loss: 105.7303\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 175.0979\n",
      "1/1 [==============================] - 2s 2s/step - loss: 193.0643\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 121.0265\n",
      "1/1 [==============================] - 2s 2s/step - loss: 131.7106\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 29.0820\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.8013\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 30.3597\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.4445\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 91.5159\n",
      "1/1 [==============================] - 2s 2s/step - loss: 110.0643\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 97.4009\n",
      "1/1 [==============================] - 2s 2s/step - loss: 116.9116\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 41.9445\n",
      "1/1 [==============================] - 2s 2s/step - loss: 49.4269\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 16.4606\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.9542\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 51.2443\n",
      "1/1 [==============================] - 2s 2s/step - loss: 53.7165\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 79.2175\n",
      "1/1 [==============================] - 2s 2s/step - loss: 85.3318\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 54.8593\n",
      "1/1 [==============================] - 2s 2s/step - loss: 57.8090\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 19.6218\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.9537\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 22.8658\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.3782\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 46.3948\n",
      "1/1 [==============================] - 2s 2s/step - loss: 54.4158\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 45.6648\n",
      "1/1 [==============================] - 2s 2s/step - loss: 53.4385\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 23.5224\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.1070\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 16.5981\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.0804\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 31.9894\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.6212\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 41.0625\n",
      "1/1 [==============================] - 2s 2s/step - loss: 42.7792\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 29.3909\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.7842\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 16.3626\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.9149\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 19.4195\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.8510\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 28.0905\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.6922\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 25.9475\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.9962\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 17.4090\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.1004\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 16.6100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.1440\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 23.4002\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.3640\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 25.6338\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.7734\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 20.0124\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.6399\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 15.6016\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.2613\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 17.6526\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.3746\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 20.5261\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.0318\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 18.7400\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.7992\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 15.7172\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.7118\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 16.5425\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.0020\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 19.4435\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.9323\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 19.5318\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.9970\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 16.8533\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.2694\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 15.4833\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.2269\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 16.5129\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.9088\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 17.1929\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.8631\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 16.1944\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.4960\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 15.4249\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.1663\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 16.3505\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.7641\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 17.4960\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 17.4960\n",
      "[4.16062754079275, 4.314613819367652, 4.182818856588955]\n",
      "DDS Model Fold # 2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 87.2888\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 105.1554\n",
      "1/1 [==============================] - 1s 1s/step - loss: 74.7981\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 99.9918\n",
      "1/1 [==============================] - 1s 1s/step - loss: 66.4851\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 94.3457\n",
      "1/1 [==============================] - 1s 1s/step - loss: 60.8056\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 91.7519\n",
      "1/1 [==============================] - 1s 1s/step - loss: 50.9773\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 80.9191\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.5366\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 75.1879\n",
      "1/1 [==============================] - 1s 1s/step - loss: 38.1425\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 75.2792\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.0164\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 78.0766\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.8458\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 81.0470\n",
      "1/1 [==============================] - 1s 1s/step - loss: 22.3018\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 80.2859\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.2263\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 78.6645\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.0741\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 74.6786\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.6636\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 73.4897\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1477\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 69.7878\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.3110\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 67.6620\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.4972\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 67.1730\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.6792\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 66.3205\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.0047\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 65.3532\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.0953\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 64.7187\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.2586\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 65.4287\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.3642\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 65.9534\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.2443\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 66.7235\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1962\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 67.1001\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.9870\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 68.4625\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.8257\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 68.1669\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.6081\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 68.4601\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.4244\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 67.5472\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.2017\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 66.6143\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.0394\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 64.8691\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.8630\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 63.7193\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6681\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 63.1311\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5364\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 62.4726\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4466\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 61.7193\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3878\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 60.3209\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3471\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 59.4820\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3190\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 58.9418\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.3033\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 58.3371\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2960\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 58.0377\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2818\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 57.8096\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2506\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 57.3783\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2222\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 57.1603\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.2261\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 56.8447\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1927\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 56.5460\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1924\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 56.1940\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1782\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 55.3378\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1595\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 54.9406\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1498\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 54.2351\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1349\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 53.6613\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1193\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 53.4084\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1021\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 53.3954\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0918\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 53.3980\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0831\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 53.1633\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0715\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 52.4866\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0638\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 51.6442\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0526\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 51.7066\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0449\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 51.7430\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0395\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 51.7518\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0360\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 52.0926\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0322\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 52.0478\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0273\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 51.8646\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0235\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 51.9414\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0223\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 51.8446\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0188\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 51.9504\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0150\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 52.1715\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.0000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 52.7837\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9920\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 53.6031\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9923\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 53.8530\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9896\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 53.7800\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9891\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 54.1094\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9881\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 54.4382\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9874\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 54.3248\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9856\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 53.9033\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9841\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 53.6512\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9835\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 53.4528\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9813\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 53.2781\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9799\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 52.5473\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9786\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 51.8527\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9760\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 51.6926\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9724\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 51.1846\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9699\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 50.9506\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9685\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 50.8946\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9669\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 50.8474\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9662\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 50.8579\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9655\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 51.1375\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9647\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 51.1301\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9642\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 50.6639\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9638\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 50.2227\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9633\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 50.0488\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9627\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 49.8485\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9624\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 49.6792\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9619\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 49.5165\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.9614\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 49.3636\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9611\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 49.2380\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9604\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 49.0950\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9598\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 48.9410\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9587\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 48.7530\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9528\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 48.5531\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9517\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 48.4047\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9512\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 48.2445\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9506\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 48.0429\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 48.0429\n",
      "[6.8288316862921015, 5.8921259174552985, 6.931295008465933]\n",
      "PGNNS Model Fold # 3\n",
      "1/1 [==============================] - 6s 6s/step - loss: 19.3689\n",
      "1/1 [==============================] - 1s 993ms/step - loss: 57030.3125\n",
      "1/1 [==============================] - 2s 2s/step - loss: 81065.8281\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 13.2280\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.6137\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 46122.2891\n",
      "1/1 [==============================] - 2s 2s/step - loss: 65951.0781\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 39062.8672\n",
      "1/1 [==============================] - 2s 2s/step - loss: 55833.8789\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 3408.3665\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4909.7383\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 10542.1768\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14927.3018\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 32486.8828\n",
      "1/1 [==============================] - 2s 2s/step - loss: 46144.0039\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 20770.7305\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29448.6914\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1390.9867\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1968.3588\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 6139.8828\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8752.8428\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 19603.4219\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27946.7109\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 15279.4004\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21770.8965\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 2445.2566\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3519.2512\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1690.9303\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2361.2959\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 10521.9902\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14857.1221\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 11846.4482\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16727.3457\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 4154.6006\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5829.6431\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 34.8728\n",
      "1/1 [==============================] - 2s 2s/step - loss: 54.6173\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 4172.8472\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6021.3271\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 7823.8408\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11246.6729\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 4852.0503\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7005.2212\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 470.5644\n",
      "1/1 [==============================] - 2s 2s/step - loss: 708.4684\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 1019.3843\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1389.9379\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 4319.1392\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6017.6548\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 4517.8867\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6296.4951\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1544.5919\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2122.5146\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 21.7220\n",
      "1/1 [==============================] - 2s 2s/step - loss: 35.7878\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1552.4629\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2287.0027\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 2961.2454\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4318.1543\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 1925.3385\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2811.9070\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 232.4808\n",
      "1/1 [==============================] - 2s 2s/step - loss: 352.6671\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 336.5391\n",
      "1/1 [==============================] - 3s 3s/step - loss: 449.9069\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1603.8365\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2217.2800\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1806.1244\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2501.1665\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 702.5110\n",
      "1/1 [==============================] - 2s 2s/step - loss: 960.1013\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 13.3075\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.9070\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 527.2405\n",
      "1/1 [==============================] - 3s 3s/step - loss: 776.7625\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1129.7512\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1646.0200\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 815.0268\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1188.8451\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 139.2738\n",
      "1/1 [==============================] - 2s 2s/step - loss: 206.3860\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 98.1768\n",
      "1/1 [==============================] - 3s 3s/step - loss: 130.8839\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 577.9874\n",
      "1/1 [==============================] - 2s 2s/step - loss: 802.3138\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 721.3062\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1000.4372\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 322.7737\n",
      "1/1 [==============================] - 2s 2s/step - loss: 442.6879\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 16.6361\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.5324\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 178.2015\n",
      "1/1 [==============================] - 2s 2s/step - loss: 264.6139\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 430.1464\n",
      "1/1 [==============================] - 2s 2s/step - loss: 630.5768\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 341.1108\n",
      "1/1 [==============================] - 3s 3s/step - loss: 501.2953\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 76.0888\n",
      "1/1 [==============================] - 3s 3s/step - loss: 113.9724\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 36.0838\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.9406\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 218.9268\n",
      "1/1 [==============================] - 2s 2s/step - loss: 298.3455\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 293.5108\n",
      "1/1 [==============================] - 2s 2s/step - loss: 402.1078\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 148.3187\n",
      "1/1 [==============================] - 3s 3s/step - loss: 200.2155\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 16.8899\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.9467\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 67.4297\n",
      "1/1 [==============================] - 2s 2s/step - loss: 100.2875\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 169.1357\n",
      "1/1 [==============================] - 2s 2s/step - loss: 248.4976\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 144.4191\n",
      "1/1 [==============================] - 3s 3s/step - loss: 211.7130\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 41.4451\n",
      "1/1 [==============================] - 3s 3s/step - loss: 60.7012\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 19.7559\n",
      "1/1 [==============================] - 3s 3s/step - loss: 24.7917\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 89.4770\n",
      "1/1 [==============================] - 2s 2s/step - loss: 120.3465\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 122.7430\n",
      "1/1 [==============================] - 2s 2s/step - loss: 166.5136\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 68.5400\n",
      "1/1 [==============================] - 3s 3s/step - loss: 91.3968\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 15.0606\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.8373\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 32.1644\n",
      "1/1 [==============================] - 2s 2s/step - loss: 46.7098\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 72.4256\n",
      "1/1 [==============================] - 2s 2s/step - loss: 105.3900\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 64.0438\n",
      "1/1 [==============================] - 3s 3s/step - loss: 93.1115\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 24.0258\n",
      "1/1 [==============================] - 3s 3s/step - loss: 34.3262\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 15.5323\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.3035\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 43.5766\n",
      "1/1 [==============================] - 2s 2s/step - loss: 56.3717\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 56.6864\n",
      "1/1 [==============================] - 3s 3s/step - loss: 74.6093\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 35.1784\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.3786\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 13.7731\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.1743\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 19.8014\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.2951\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 34.6670\n",
      "1/1 [==============================] - 2s 2s/step - loss: 51.0379\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 31.1618\n",
      "1/1 [==============================] - 2s 2s/step - loss: 45.6960\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 16.3596\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.7634\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 14.2188\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.5503\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 25.5721\n",
      "1/1 [==============================] - 2s 2s/step - loss: 32.2547\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 30.3146\n",
      "1/1 [==============================] - 2s 2s/step - loss: 38.8003\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 21.4114\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.8862\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 13.0548\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.3470\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 15.5893\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.3424\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 21.2044\n",
      "1/1 [==============================] - 2s 2s/step - loss: 29.9659\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 19.4194\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.1818\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 13.7757\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.2290\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 13.4963\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.8709\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 18.1634\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.8240\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 19.6571\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.8211\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 15.8413\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.7986\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 12.7859\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.0757\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 14.0597\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.4861\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 16.0587\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.6283\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 15.0579\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.0527\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 12.9394\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.6107\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 13.2545\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.5195\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 15.2392\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.9301\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 15.5729\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.3401\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 13.8483\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.1947\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 12.7274\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.0040\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 13.2535\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 13.2535\n",
      "[4.16062754079275, 4.314613819367652, 4.182818856588955, 3.640538554331786]\n",
      "DDS Model Fold # 3\n",
      "1/1 [==============================] - 8s 8s/step - loss: 98.6407\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 94.5250\n",
      "1/1 [==============================] - 1s 1s/step - loss: 92.4736\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 87.2784\n",
      "1/1 [==============================] - 1s 1s/step - loss: 82.8326\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 87.6303\n",
      "1/1 [==============================] - 1s 1s/step - loss: 70.3755\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 82.5717\n",
      "1/1 [==============================] - 2s 2s/step - loss: 58.6124\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 78.9090\n",
      "1/1 [==============================] - 1s 1s/step - loss: 48.0166\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 78.6626\n",
      "1/1 [==============================] - 1s 1s/step - loss: 37.6616\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 75.8533\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.3778\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 77.9417\n",
      "1/1 [==============================] - 1s 1s/step - loss: 24.3834\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 75.3140\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.9867\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 65.9382\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.4234\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 62.2680\n",
      "1/1 [==============================] - 2s 2s/step - loss: 12.8927\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 62.2619\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.4832\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 58.5785\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.0423\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 56.2358\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.3704\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 54.8621\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.9674\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 53.9088\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.6281\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 53.0505\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.0865\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 52.6693\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.4448\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 51.4278\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.5802\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 48.8642\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.3911\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 47.0088\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.9864\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 46.5037\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.5423\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 45.7199\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.1545\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 44.9706\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.7811\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 45.4166\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.4612\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 49.6768\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1729\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 51.8352\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.9119\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 52.8202\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.7378\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 53.0739\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.6070\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 53.1622\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.4958\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 53.3277\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.3910\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 53.6173\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.2752\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 53.8835\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.1891\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 54.3763\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.1222\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 54.9743\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.0858\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 56.1001\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.0723\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 56.2714\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.0489\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 56.5745\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.0102\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 56.6835\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.9437\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 56.2926\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.9028\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 55.8923\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.8875\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 55.4369\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.8581\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 54.0992\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.8251\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 52.7549\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.8091\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 51.9248\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.7935\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 50.3204\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7730\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 49.3357\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7486\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 48.2806\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7202\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 47.1152\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6890\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 46.1840\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6595\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 45.5218\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6400\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 44.8000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6314\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 44.3811\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6227\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 43.9407\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.6096\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 43.5447\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.5982\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 43.1525\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5909\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 42.7739\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5839\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 42.4181\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5803\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 42.0769\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5791\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 41.7469\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5772\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 41.4555\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5720\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 41.1838\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5697\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 40.9303\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5675\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 40.6667\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5638\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 40.4351\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5610\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 40.2270\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.5585\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 40.0324\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5563\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 39.8435\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5526\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 39.6650\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5482\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 39.5105\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5450\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 39.4091\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5413\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 39.2380\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5383\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 39.0762\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5357\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 38.8769\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5331\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 38.7269\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5304\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 38.5844\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5242\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 38.4434\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5217\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 38.3099\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5201\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 38.2392\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5183\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 38.1164\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5168\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 38.1130\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5156\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 38.0298\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5145\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 37.9459\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5129\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 37.8116\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5114\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 37.7509\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5087\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 37.7092\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5065\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 37.7361\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5051\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 37.7110\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5037\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 37.5750\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5023\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 37.4302\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.5008\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 37.2852\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4998\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 37.1391\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4971\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 37.5551\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4951\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 37.7206\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4939\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 37.6464\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4929\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 37.5506\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9.4917\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 37.4359\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4907\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 37.2951\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4899\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 37.1564\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.4889\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 37.0222\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 37.0222\n",
      "[6.8288316862921015, 5.8921259174552985, 6.931295008465933, 6.0845887791676]\n",
      "Model training and testing runtime is 47.27158963680267 minutes\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRAIN_SET_PERCENTAGE = 1-(1/k)\n",
    "VAL_SET_PERCENTAGE = 1/k\n",
    "PDBs.pop('',None)\n",
    "\n",
    "# PGNNS model variables\n",
    "PGNNS_train_losses = [[] for _ in range(k_fold)]\n",
    "PGNNS_val_losses = [[] for _ in range(k_fold)]\n",
    "PGNNS_rmse_train, PGNNS_rmse_test = [], []\n",
    "\n",
    "# DDS model variables\n",
    "DDS_train_losses = [[] for _ in range(k_fold)]\n",
    "DDS_val_losses = [[] for _ in range(k_fold)]\n",
    "DDS_rmse_train, DDS_rmse_test = [], []\n",
    "\n",
    "# Defining Featurizer\n",
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "\n",
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "X, X_ids = [], []\n",
    "\n",
    "# Featurize PDB's\n",
    "for i in PDBs.keys():\n",
    "    X_ids.append(i)\n",
    "    X.append(featurizer.featurize(PDBs[i]))\n",
    "pdb_names = [i.split('-')[0] for i in X_ids] \n",
    "X = [x[0] for x in X]\n",
    "# k-fold loop\n",
    "for fold in range(k_fold):\n",
    "    # fold=0 -> 0 * (0.25 * 72) = 0\n",
    "    # fold=1 -> 1 * (0.25 * 72) = 18\n",
    "    # fold=2 -> 2 * (0.25 * 72) = 36\n",
    "    # fold=3 -> 3 * (0.25 *72) = 54\n",
    "    pdb_names_val, pdb_names_test = [], []\n",
    "    pdb_names_train, X_val_featurized, X_test_featurized, X_train_featurized  = [], [], [], []\n",
    "    \n",
    "\n",
    "     \n",
    "    TEST_SIZE = int(len(X) * VAL_SET_PERCENTAGE)\n",
    "    val_split_index_begin = int(fold * TEST_SIZE)\n",
    "#     print(f\"begin {val_split_index_begin}\")\n",
    "    val_split_index_end = int(val_split_index_begin) + int(TEST_SIZE)\n",
    "#     print(f\"end {val_split_index_end}\")\n",
    "\n",
    "    # validation\n",
    "    pdb_names_val = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "\n",
    "    # Test set\n",
    "    pdb_names_test = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "    \n",
    "    # Train set\n",
    "    pdb_names_train = [pdb_names[i] for i in range(len(pdb_names)) if i not in range(val_split_index_begin,val_split_index_end)]\n",
    "\n",
    "    \n",
    "    X_val_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_test_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_train_featurized = [X[i] for i in range(len(X)) if i not in range(val_split_index_begin, val_split_index_end)]\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    x_add_train, x_add_val, x_add_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "    # Train\n",
    "    for i in range(len(pdb_names_train)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "        y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_train.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_train = np.array(y_train)\n",
    "    # Val\n",
    "    for i in range(len(pdb_names_val)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_val[i])]\n",
    "        y_val.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_val.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    # Test\n",
    "    for i in range(len(pdb_names_test)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "        y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_test.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_preprocessed_train, x_preprocessed_val, x_preprocessed_test = [], [], []\n",
    "    \n",
    "    ## Step\n",
    "    \n",
    "    # X train\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "    x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "    ## X val\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "    x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "\n",
    "    ## X test\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "    x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_test.append(np.array(x_add_test))\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    # Train\n",
    "    x_train = np.full([15, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_train):\n",
    "        if len(j.shape) > 1:\n",
    "            x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "    # Validation\n",
    "    x_val = np.full([15, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_val):\n",
    "        if len(j.shape) > 1:\n",
    "            x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "    # Test\n",
    "    x_test = np.full([15, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_test):\n",
    "        if len(j.shape) > 1:\n",
    "            x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_test = x_test.reshape([1] + list(x_test.shape))\n",
    "    \n",
    "    # Variable initializations for models\n",
    "    \n",
    "    val_size = len(y_val)\n",
    "    train_size = len(y_train)\n",
    "    \n",
    "    # PGNNS Model\n",
    "    batch_size = len(pdb_names_train)\n",
    "    PGNNS_model = PGNNS(len(y_train))\n",
    "    PGNNS_model.compile(loss='mse', optimizer=optimizer)\n",
    "    print(f'PGNNS Model Fold # {fold}')\n",
    "    for epoch in range(max_epoch):\n",
    "        PGNNS_model.modify_graphgather(train_size)\n",
    "        PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        PGNNloss = PGNNS_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "        PGNNS_train_losses[fold].append(PGNNloss.history['loss'][0])\n",
    "        PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        PGNNS_model.modify_graphgather(val_size)\n",
    "        PGNNS_val_losses[fold].append(PGNNS_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "        \n",
    "    PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    PGNNS_model.modify_graphgather(len(y_test))\n",
    "    evalu = PGNNS_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # PGNNS Testing RMSE calculation\n",
    "    PGNNS_rmse_test.append(np.sqrt(evalu))\n",
    "    print(PGNNS_rmse_test)\n",
    "    # PGNNS Training RMSE calculation\n",
    "    PGNNS_train_loss = PGNNS_train_losses[fold][-1]\n",
    "    PGNNS_rmse_train.append(math.sqrt(PGNNS_train_loss))\n",
    "    \n",
    "    # Data Driven model\n",
    "    DDS_model = DDS(len(y_train))\n",
    "    DDS_model.compile(loss='mse', optimizer=optimizer)\n",
    "    print(f'DDS Model Fold # {fold}')\n",
    "    for epoch in range(max_epoch):\n",
    "        DDS_model.modify_graphgather(train_size)\n",
    "        DDS_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        DDSloss = DDS_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "        DDS_train_losses[fold].append(DDSloss.history['loss'][0])\n",
    "        DDS_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        DDS_model.modify_graphgather(val_size)\n",
    "        DDS_val_losses[fold].append(DDS_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "    \n",
    "    DDS_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    DDS_model.modify_graphgather(len(y_test))\n",
    "    DDS_evaluate = DDS_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # DDS Testing RMSE calculation\n",
    "    DDS_rmse_test.append(np.sqrt(DDS_evaluate))\n",
    "    print(DDS_rmse_test)\n",
    "    # DDS training RMSE calculation\n",
    "    DDS_train_loss = DDS_train_losses[fold][-1]\n",
    "    DDS_rmse_train.append(math.sqrt(DDS_train_loss))\n",
    "    \n",
    "time.sleep(1)\n",
    "# end time\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Model training and testing runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2fa7465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12811272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.4786399 ],\n",
       "        [ 1.0000123 ],\n",
       "        [ 1.0000095 ],\n",
       "        [ 1.0000448 ],\n",
       "        [ 1.0000551 ],\n",
       "        [-0.9999828 ],\n",
       "        [-0.9999916 ],\n",
       "        [-0.9999815 ],\n",
       "        [-0.9999368 ],\n",
       "        [-1.0016718 ],\n",
       "        [-1.0059055 ],\n",
       "        [-0.99833435],\n",
       "        [-0.9994267 ],\n",
       "        [ 0.9999499 ],\n",
       "        [-1.0000415 ],\n",
       "        [-1.0069034 ],\n",
       "        [-0.9958586 ]], dtype=float32),\n",
       " array([-0.00071792], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the wights after training PGNNS MODEL\n",
    "PGNNS_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d52642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average RMSE on Training set\n",
    "average_DDS_rmse_train = sum(DDS_rmse_train) / len(DDS_rmse_train)\n",
    "average_PGNNS_rmse_train = sum(PGNNS_rmse_train) / len(PGNNS_rmse_train)\n",
    "# calculating the average RMSE on Testing set\n",
    "average_DDS_rmse_test = sum(DDS_rmse_test) / len(DDS_rmse_test)\n",
    "average_PGNNS_rmse_test = sum(PGNNS_rmse_test) / len(PGNNS_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44af65",
   "metadata": {},
   "source": [
    "# Model Performance Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06408c90",
   "metadata": {},
   "source": [
    "<h3>PGNNS Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc3ae960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the average of k-fold losses\n",
    "average_PGNNS_train_losses = [sum(x)/len(x) for x in zip(*PGNNS_train_losses)]\n",
    "average_PGNNS_val_losses = [sum(x)/len(x) for x in zip(*PGNNS_val_losses)]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_PGNNS_train_losses)), average_PGNNS_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_PGNNS_val_losses)), average_PGNNS_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.title(\"PGNNS Model\")\n",
    "# Time stamp with date and time\n",
    "time.strftime(\"%Y-%m-%d %H%M%S\")\n",
    "\n",
    "# save plot\n",
    "plt.savefig(\"PGNNS_loss\" + time.strftime(\"%Y-%m-%d %H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eaf698",
   "metadata": {},
   "source": [
    "<h3>DDS Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4c1a923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the average of k-fold losses\n",
    "average_DDS_train_losses = [sum(x)/len(x) for x in zip(*DDS_train_losses)]\n",
    "average_DDS_val_losses = [sum(x)/len(x) for x in zip(*DDS_val_losses)]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_DDS_train_losses)), average_DDS_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_DDS_val_losses)), average_DDS_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.title('DDS Model')\n",
    "# Time stamp with date and time\n",
    "time.strftime(\"%Y-%m-%d %H%M%S\")\n",
    "\n",
    "# save plot\n",
    "plt.savefig(\"DDS_loss\" + time.strftime(\"%Y-%m-%d %H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0df91",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e821938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+\n",
      "|                    Models Comparison                    |\n",
      "+-------------+---------------+------------+--------------+\n",
      "| DDS (TRAIN) | PGNNS (TRAIN) | DDS (TEST) | PGNNS (TEST) |\n",
      "+-------------+---------------+------------+--------------+\n",
      "|     2.99    |      3.89     |    6.43    |     4.07     |\n",
      "+-------------+---------------+------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Models Comparison\"\n",
    "rmse_table.field_names = [\"DDS (TRAIN)\", \"PGNNS (TRAIN)\", \"DDS (TEST)\", \"PGNNS (TEST)\"]\n",
    "rmse_table.add_row([ \"{:.2f}\".format(average_DDS_rmse_train),\"{:.2f}\".format(average_PGNNS_rmse_train),\n",
    "                   \"{:.2f}\".format(average_DDS_rmse_test),\"{:.2f}\".format(average_PGNNS_rmse_test)])\n",
    "\n",
    "print(rmse_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e005e-5dfe-4ba5-bf88-61f7d6c29054",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
