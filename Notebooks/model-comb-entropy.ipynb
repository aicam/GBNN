{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "max_epoch = 100\n",
    "# optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021.03.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('molecule_parameters.csv')\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.697637870606162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(df.ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7570329320098512"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(df['entropy'].astype(np.float).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['entropy'].astype(np.float) + np.random.normal(np.sqrt(df['entropy'].astype(np.float).mean()), 1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddg = enthalpy - entropy\n",
    "# entropy = enthalpy - ddg\n",
    "# dh complex - (dh p + dh L)\n",
    "# \n",
    "# df['entropy'] = df.enthalpy - df.ddg\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading Mobley PDB files</h1>\n",
    "<p>Here each PDB file will be read and saved in Mol data type defined in RDKit and used by DeepChem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1bai\n",
      "1bdq\n",
      "1bnv\n",
      "1a1e\n",
      "1bnq\n",
      "1bn4\n",
      "1bn3\n",
      "1bhf\n",
      "1c87\n",
      "1c1r\n",
      "1bgq\n",
      "1c1u\n",
      "1c86\n",
      "1c88\n",
      "1a4r\n",
      "1bnw\n",
      "1ai4\n",
      "1b6l\n",
      "1ajp\n",
      "1b6k\n",
      "1d3d\n",
      "1bp0\n",
      "1b5j\n",
      "1ceb\n",
      "1aid\n",
      "1b3f\n",
      "1b3h\n",
      "1ciz\n",
      "1ajx\n",
      "1ajq\n",
      "1b6j\n",
      "1ajv\n",
      "1ai5\n",
      "1b0h\n",
      "1b3g\n",
      "1b52\n",
      "1d3p\n",
      "1b55\n",
      "1add\n",
      "1amw\n",
      "1b46\n",
      "1b4z\n",
      "1b4h\n",
      "1adl\n",
      "1b40\n",
      "1d4l\n",
      "1cbx\n",
      "1d4k\n",
      "1b8y\n",
      "1d7j\n",
      "1b7h\n",
      "1d4p\n",
      "1bq4\n",
      "1bwa\n",
      "1d4y\n",
      "1c5n\n",
      "1bcd\n",
      "1c5s\n",
      "1a99\n",
      "1c3x\n",
      "1a30\n",
      "1c5o\n",
      "1bjv\n",
      "1ax0\n",
      "1a4w\n",
      "1bnu\n",
      "1c84\n",
      "1ctt\n",
      "1c70\n",
      "1c83\n",
      "1atl\n",
      "1a4k\n",
      "1bnn\n",
      "1bma\n",
      "1dgm\n",
      "1dhi\n",
      "1c4u\n",
      "1bn1\n",
      "1ctu\n",
      "1bm7\n",
      "1bnt\n",
      "1bhx\n",
      "1b57\n",
      "1d9i\n",
      "1b3l\n",
      "1b32\n",
      "1b6h\n",
      "1ai7\n",
      "1bzc\n",
      "1cet\n",
      "1d6v\n",
      "1b5i\n",
      "1b58\n",
      "1afk\n",
      "1d09\n",
      "1bv7\n",
      "1afl\n",
      "1bzy\n",
      "1ajn\n",
      "1alw\n",
      "1bv9\n",
      "1b51\n",
      "1b05\n",
      "1aj7\n",
      "1d6w\n",
      "1b5h\n",
      "1b9j\n",
      "1d2e\n",
      "1b8n\n",
      "1aaq\n",
      "1cnx\n",
      "1cgl\n",
      "1bxr\n",
      "1b1h\n",
      "1bty\n",
      "1br6\n",
      "1b8o\n",
      "1bwb\n",
      "1cnw\n",
      "1ado\n",
      "1cny\n",
      "1d7i\n",
      "1b2h\n",
      "1apv\n",
      "1c5c\n",
      "1bcu\n",
      "1c5q\n",
      "1df8\n",
      "1c5x\n",
      "1cps\n",
      "1bju\n",
      "1a9m\n",
      "1avn\n",
      "1det\n",
      "1c5y\n",
      "1a94\n",
      "1a69\n",
      "1c5p\n"
     ]
    }
   ],
   "source": [
    "# Dictionary with complex names as keys and molecule as values\n",
    "PDBs = {}\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# mypath = '../../../../../../Documents/GitHub/Binding-Free-Energy-Prediction-Host-Guest-System/pdbbind/raw-data/'\n",
    "mypath = '../dataset/'\n",
    "onlyfiles = [f for f in listdir(mypath) if f not in ('.DS_Store') and f in (df['complex-name'].tolist())]\n",
    "for f in onlyfiles:\n",
    "    print(f)\n",
    "    PDBs.update({f: rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + f + '/com_new.pqr')})\n",
    "\n",
    "for key, value in dict(PDBs).items():\n",
    "    if value is None:\n",
    "        del PDBs[key]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the PDBs\n",
    "import random\n",
    "l = list(PDBs.items())\n",
    "random.shuffle(l)\n",
    "PDBs = dict(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Featurizing</h1>\n",
    "<p>GraphConv model needs ConvMolFeaturizer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "# featurizer = dc.feat.MolGraphConvFeaturizer(use_)\n",
    "TRAIN_SET = .7\n",
    "VAL_SET = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print(VAL_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDBs.pop('1dl7',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test on a few pdb firs\n",
    "# PDB_subset = {key:PDBs[key] for key in ['1bai',\n",
    "# '1bdq',\n",
    "# '1bnv',\n",
    "# '1a1e',\n",
    "# '1bnq',\n",
    "# '1bn4',\n",
    "# '1bn3',\n",
    "# '1bhf',\n",
    "# '1c87',\n",
    "# '1c1r']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDB_subset.pop('',None)\n",
    "# X = []\n",
    "# X_ids = []\n",
    "# # one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "# for k in PDB_subset.keys():\n",
    "#     X_ids.append(k)\n",
    "#     X.append(featurizer.featurize(PDB_subset[k]))\n",
    "# train_split_index = int(len(X) * TRAIN_SET)\n",
    "# val_split_index = int(len(X) * VAL_SET)\n",
    "# X = [x[0] for x in X]\n",
    "# X_train_featurized = X[:train_split_index]\n",
    "# # X_val_featurized = X[train_split_index: (train_split_index + val_split_index)]\n",
    "# X_val_featurized = X[train_split_index:]\n",
    "# X_test_featurized = X[train_split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBs.pop('',None)\n",
    "X = []\n",
    "X_ids = []\n",
    "# one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "for k in PDBs.keys():\n",
    "    X_ids.append(k)\n",
    "    X.append(featurizer.featurize(PDBs[k]))\n",
    "train_split_index = int(len(X) * TRAIN_SET)\n",
    "val_split_index = int(len(X) * VAL_SET)\n",
    "X = [x[0] for x in X]\n",
    "X_train_featurized = X[:train_split_index]\n",
    "# X_val_featurized = X[train_split_index: (train_split_index + val_split_index)]\n",
    "X_val_featurized = X[train_split_index:]\n",
    "X_test_featurized = X[train_split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_names = [i.split('-')[0] for i in X_ids]\n",
    "# guest_names = ['guest-' + (i.split('-')[1].replace('s', '')) for i in X_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "pdb_names_train = host_names[:train_split_index]\n",
    "# guest_names_train = guest_names[:train_split_index]\n",
    "# Val\n",
    "# host_names_val = host_names[train_split_index:(train_split_index + val_split_index)]\n",
    "# guest_names_val = guest_names[train_split_index:(train_split_index + val_split_index)]\n",
    "pdb_names_val = host_names[train_split_index:]\n",
    "# guest_names_val = guest_names[train_split_index:]\n",
    "# test\n",
    "pdb_names_test = host_names[train_split_index:]\n",
    "# guest_names_test = guest_names[train_split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_add_train, x_add_val, x_add_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "# Train\n",
    "for i in range(len(pdb_names_train)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "    y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_train.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c) and\n",
    "                               ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "y_train = np.array(y_train)\n",
    "# Val\n",
    "for i in range(len(pdb_names_val)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_val[i])]\n",
    "    y_val.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_val.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                         and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Test\n",
    "for i in range(len(pdb_names_test)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "    y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_test.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                         and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gb-complex-1-4-eel</th>\n",
       "      <th>gb-complex-eelec</th>\n",
       "      <th>gb-complex-egb</th>\n",
       "      <th>gb-complex-esurf</th>\n",
       "      <th>gb-protein-1-4-eel</th>\n",
       "      <th>gb-protein-eelect</th>\n",
       "      <th>gb-protein-egb</th>\n",
       "      <th>gb-protein-esurf</th>\n",
       "      <th>gb-ligand-1-4-eel</th>\n",
       "      <th>gb-ligand-eelec</th>\n",
       "      <th>gb-ligand-egb</th>\n",
       "      <th>gb-ligand-esurf</th>\n",
       "      <th>pb-complex-vdwaals</th>\n",
       "      <th>pb-protein-vdwaals</th>\n",
       "      <th>pb-ligand-vdwaals</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>20732.9098</td>\n",
       "      <td>-30373.2656</td>\n",
       "      <td>-4428.3601</td>\n",
       "      <td>101.9718</td>\n",
       "      <td>20728.906</td>\n",
       "      <td>-30323.7424</td>\n",
       "      <td>-4383.172</td>\n",
       "      <td>102.3131</td>\n",
       "      <td>4.0038</td>\n",
       "      <td>-46.6953</td>\n",
       "      <td>-97.3686</td>\n",
       "      <td>3.4958</td>\n",
       "      <td>-525.2142</td>\n",
       "      <td>-477.6023</td>\n",
       "      <td>-4.0711</td>\n",
       "      <td>10.49877001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gb-complex-1-4-eel  gb-complex-eelec  gb-complex-egb  gb-complex-esurf  \\\n",
       "136          20732.9098       -30373.2656      -4428.3601          101.9718   \n",
       "\n",
       "     gb-protein-1-4-eel  gb-protein-eelect  gb-protein-egb  gb-protein-esurf  \\\n",
       "136           20728.906        -30323.7424       -4383.172          102.3131   \n",
       "\n",
       "     gb-ligand-1-4-eel  gb-ligand-eelec  gb-ligand-egb  gb-ligand-esurf  \\\n",
       "136             4.0038         -46.6953       -97.3686           3.4958   \n",
       "\n",
       "     pb-complex-vdwaals  pb-protein-vdwaals  pb-ligand-vdwaals      entropy  \n",
       "136           -525.2142           -477.6023            -4.0711  10.49877001  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                         and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_featurized[0].get_atoms_with_deg(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "x_preprocessed_train, x_preprocessed_val, x_preprocessed_test = [], [], []\n",
    "\n",
    "## for X train\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "## for X val\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "\n",
    "## for X test\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_test.append(np.array(x_add_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "x_train = np.full([15, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "\n",
    "for i,j in enumerate(x_preprocessed_train):\n",
    "    if len(j.shape) > 1:\n",
    "        x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "# Validation\n",
    "x_val = np.full([15, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_val):\n",
    "    if len(j.shape) > 1:\n",
    "        x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "# Test\n",
    "x_test = np.full([15, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_test):\n",
    "    if len(j.shape) > 1:\n",
    "        x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_test = x_test.reshape([1] + list(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Physics Guided Neural Network Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahar_pgnn_test_accuracy = []\n",
    "sahar_pgnn_train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "batch_size = int(len(pdb_names_train)/4)\n",
    "batch_size\n",
    "# batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 21:29:52.145248: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(GBGraphConvModel, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([0.5, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 16])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    return self.dense3(binding_affinity)\n",
    "hybrid_model = GBGraphConvModel(train_split_index)\n",
    "hybrid_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 21:29:53.116345: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_13:0\", shape=(83387, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_16:0\", shape=(205678, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_19:0\", shape=(290367, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Reshape_22:0\", shape=(188, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_11:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_10:0\", shape=(83387, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_13:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_12:0\", shape=(205678, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_15:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_14:0\", shape=(290367, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_16:0\", shape=(188, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_18:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_20:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_22:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_24:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_26:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Reshape_28:0\", shape=(0, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_13:0\", shape=(83387, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_16:0\", shape=(205678, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_19:0\", shape=(290367, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Reshape_22:0\", shape=(188, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 14s 14s/step - loss: 15.2391\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33116.3672\n",
      "1/1 [==============================] - 9s 9s/step - loss: 14412.3359\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2247.6914\n",
      "1/1 [==============================] - 8s 8s/step - loss: 945.1540\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6791.0103\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3106.6887\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18467.3320\n",
      "1/1 [==============================] - 8s 8s/step - loss: 8301.4893\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13961.2100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 6291.5103\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3971.9495\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1824.4684\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.4822\n",
      "1/1 [==============================] - 7s 7s/step - loss: 22.2230\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4052.8389\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1732.6859\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9049.2949\n",
      "1/1 [==============================] - 6s 6s/step - loss: 3896.6687\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8919.7920\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3835.4910\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4637.0718\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1978.5728\n",
      "1/1 [==============================] - 1s 1s/step - loss: 726.8101\n",
      "1/1 [==============================] - 8s 8s/step - loss: 300.3453\n",
      "1/1 [==============================] - 1s 1s/step - loss: 321.0057\n",
      "1/1 [==============================] - 6s 6s/step - loss: 167.5979\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2730.5300\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1260.3998\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4746.4033\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2157.6550\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4247.7305\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1931.0190\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1995.9330\n",
      "1/1 [==============================] - 7s 7s/step - loss: 918.5405\n",
      "1/1 [==============================] - 2s 2s/step - loss: 214.9310\n",
      "1/1 [==============================] - 8s 8s/step - loss: 112.3201\n",
      "1/1 [==============================] - 1s 1s/step - loss: 323.5461\n",
      "1/1 [==============================] - 7s 7s/step - loss: 138.9705\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1755.2734\n",
      "1/1 [==============================] - 8s 8s/step - loss: 753.5539\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2780.6013\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1197.4738\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2371.8682\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1017.0766\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1041.8682\n",
      "1/1 [==============================] - 7s 7s/step - loss: 442.4107\n",
      "1/1 [==============================] - 1s 1s/step - loss: 89.9981\n",
      "1/1 [==============================] - 8s 8s/step - loss: 41.1264\n",
      "1/1 [==============================] - 1s 1s/step - loss: 240.6566\n",
      "1/1 [==============================] - 6s 6s/step - loss: 124.1259\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1036.3584\n",
      "1/1 [==============================] - 8s 8s/step - loss: 484.8245\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1478.1364\n",
      "1/1 [==============================] - 8s 8s/step - loss: 680.7762\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1103.4160\n",
      "1/1 [==============================] - 8s 8s/step - loss: 509.9243\n",
      "1/1 [==============================] - 1s 1s/step - loss: 367.7749\n",
      "1/1 [==============================] - 9s 9s/step - loss: 176.9312\n",
      "1/1 [==============================] - 2s 2s/step - loss: 17.6557\n",
      "1/1 [==============================] - 8s 8s/step - loss: 15.2428\n",
      "1/1 [==============================] - 717s 717s/step - loss: 297.5631\n",
      "1/1 [==============================] - 11s 11s/step - loss: 132.4743\n",
      "1/1 [==============================] - 3s 3s/step - loss: 769.0767\n",
      "1/1 [==============================] - 11s 11s/step - loss: 335.6794\n",
      "1/1 [==============================] - 2s 2s/step - loss: 864.7250\n",
      "1/1 [==============================] - 8s 8s/step - loss: 377.5407\n",
      "1/1 [==============================] - 2s 2s/step - loss: 505.0120\n",
      "1/1 [==============================] - 9s 9s/step - loss: 221.5055\n",
      "1/1 [==============================] - 1s 1s/step - loss: 101.5294\n",
      "1/1 [==============================] - 8s 8s/step - loss: 48.1803\n",
      "1/1 [==============================] - 2s 2s/step - loss: 45.1659\n",
      "1/1 [==============================] - 9s 9s/step - loss: 29.4232\n",
      "1/1 [==============================] - 1s 1s/step - loss: 292.7713\n",
      "1/1 [==============================] - 6s 6s/step - loss: 143.4667\n",
      "1/1 [==============================] - 1s 1s/step - loss: 482.8315\n",
      "1/1 [==============================] - 8s 8s/step - loss: 228.4864\n",
      "1/1 [==============================] - 2s 2s/step - loss: 384.7158\n",
      "1/1 [==============================] - 8s 8s/step - loss: 182.7971\n",
      "1/1 [==============================] - 1s 1s/step - loss: 133.0457\n",
      "1/1 [==============================] - 8s 8s/step - loss: 68.4794\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.9362\n",
      "1/1 [==============================] - 6s 6s/step - loss: 14.6087\n",
      "1/1 [==============================] - 1s 1s/step - loss: 132.0150\n",
      "1/1 [==============================] - 8s 8s/step - loss: 61.3762\n",
      "1/1 [==============================] - 2s 2s/step - loss: 292.4905\n",
      "1/1 [==============================] - 8s 8s/step - loss: 129.1410\n",
      "1/1 [==============================] - 1s 1s/step - loss: 292.2870\n",
      "1/1 [==============================] - 8s 8s/step - loss: 128.3918\n",
      "1/1 [==============================] - 1s 1s/step - loss: 142.9318\n",
      "1/1 [==============================] - 7s 7s/step - loss: 64.4471\n",
      "1/1 [==============================] - 2s 2s/step - loss: 25.1798\n",
      "1/1 [==============================] - 7s 7s/step - loss: 16.3925\n",
      "1/1 [==============================] - 2s 2s/step - loss: 51.3563\n",
      "1/1 [==============================] - 8s 8s/step - loss: 32.1559\n",
      "1/1 [==============================] - 2s 2s/step - loss: 145.3806\n",
      "1/1 [==============================] - 6s 6s/step - loss: 76.7273\n",
      "1/1 [==============================] - 1s 1s/step - loss: 165.3658\n",
      "1/1 [==============================] - 8s 8s/step - loss: 85.9374\n",
      "1/1 [==============================] - 2s 2s/step - loss: 89.2217\n",
      "1/1 [==============================] - 8s 8s/step - loss: 50.3011\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.4599\n",
      "1/1 [==============================] - 8s 8s/step - loss: 16.9109\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.9312\n",
      "1/1 [==============================] - 6s 6s/step - loss: 22.6759\n",
      "1/1 [==============================] - 1s 1s/step - loss: 110.6077\n",
      "1/1 [==============================] - 8s 8s/step - loss: 49.9839\n",
      "1/1 [==============================] - 1s 1s/step - loss: 129.2622\n",
      "1/1 [==============================] - 8s 8s/step - loss: 57.6195\n",
      "1/1 [==============================] - 1s 1s/step - loss: 77.7106\n",
      "1/1 [==============================] - 8s 8s/step - loss: 36.3873\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.4060\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.6592\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.4512\n",
      "1/1 [==============================] - 8s 8s/step - loss: 19.5048\n",
      "1/1 [==============================] - 2s 2s/step - loss: 60.2534\n",
      "1/1 [==============================] - 8s 8s/step - loss: 36.3917\n",
      "1/1 [==============================] - 2s 2s/step - loss: 67.6395\n",
      "1/1 [==============================] - 8s 8s/step - loss: 39.8354\n",
      "1/1 [==============================] - 1s 1s/step - loss: 39.0115\n",
      "1/1 [==============================] - 6s 6s/step - loss: 25.7067\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 14.2979\n",
      "1/1 [==============================] - 1s 1s/step - loss: 32.5871\n",
      "1/1 [==============================] - 8s 8s/step - loss: 18.5147\n",
      "1/1 [==============================] - 2s 2s/step - loss: 58.2758\n",
      "1/1 [==============================] - 8s 8s/step - loss: 28.5111\n",
      "1/1 [==============================] - 2s 2s/step - loss: 58.2979\n",
      "1/1 [==============================] - 7s 7s/step - loss: 28.5216\n",
      "1/1 [==============================] - 2s 2s/step - loss: 34.4308\n",
      "1/1 [==============================] - 8s 8s/step - loss: 19.1225\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.2937\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.8181\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.4901\n",
      "1/1 [==============================] - 8s 8s/step - loss: 18.2159\n",
      "1/1 [==============================] - 1s 1s/step - loss: 34.7105\n",
      "1/1 [==============================] - 6s 6s/step - loss: 23.6380\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.8229\n",
      "1/1 [==============================] - 8s 8s/step - loss: 21.5025\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.7083\n",
      "1/1 [==============================] - 8s 8s/step - loss: 15.4231\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.3659\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.0247\n",
      "1/1 [==============================] - 2s 2s/step - loss: 31.9861\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.8152\n",
      "1/1 [==============================] - 1s 1s/step - loss: 37.6522\n",
      "1/1 [==============================] - 8s 8s/step - loss: 19.8559\n",
      "1/1 [==============================] - 2s 2s/step - loss: 30.0024\n",
      "1/1 [==============================] - 8s 8s/step - loss: 16.9935\n",
      "1/1 [==============================] - 2s 2s/step - loss: 19.8975\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.7668\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.6393\n",
      "1/1 [==============================] - 7s 7s/step - loss: 14.5136\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.5466\n",
      "1/1 [==============================] - 8s 8s/step - loss: 17.0447\n",
      "1/1 [==============================] - 2s 2s/step - loss: 22.3517\n",
      "1/1 [==============================] - 8s 8s/step - loss: 16.9412\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.5704\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.5176\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.7473\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.5023\n",
      "1/1 [==============================] - 1s 1s/step - loss: 23.9651\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.9140\n",
      "1/1 [==============================] - 2s 2s/step - loss: 27.0694\n",
      "1/1 [==============================] - 7s 7s/step - loss: 15.9333\n",
      "1/1 [==============================] - 2s 2s/step - loss: 23.8618\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.8611\n",
      "1/1 [==============================] - 1s 1s/step - loss: 19.0447\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.5005\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.8619\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.7961\n",
      "1/1 [==============================] - 1s 1s/step - loss: 19.0830\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.8196\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.8995\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.6858\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.6603\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.6668\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.5243\n",
      "1/1 [==============================] - 8s 8s/step - loss: 13.3882\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.1695\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.0358\n",
      "1/1 [==============================] - 1s 1s/step - loss: 22.1074\n",
      "1/1 [==============================] - 9s 9s/step - loss: 14.2934\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20.1775\n",
      "1/1 [==============================] - 1806s 1806s/step - loss: 13.7264\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18.0730\n",
      "1/1 [==============================] - 26s 26s/step - loss: 13.2872\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.7702\n",
      "1/1 [==============================] - 30s 30s/step - loss: 13.5705\n",
      "1/1 [==============================] - 5s 5s/step - loss: 18.0284\n",
      "1/1 [==============================] - 29s 29s/step - loss: 13.8991\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.7472\n",
      "1/1 [==============================] - 22s 22s/step - loss: 13.6572\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.8496\n",
      "1/1 [==============================] - 30s 30s/step - loss: 13.2660\n",
      "1/1 [==============================] - 5s 5s/step - loss: 19.2411\n",
      "1/1 [==============================] - 12s 12s/step - loss: 13.3244\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.4270\n",
      "1/1 [==============================] - 10s 10s/step - loss: 13.6019\n",
      "1/1 [==============================] - 2s 2s/step - loss: 20.1714\n"
     ]
    }
   ],
   "source": [
    "sahar_pgnn_losses, sahar_pgnn_val_losses = [], []\n",
    "\n",
    "val_size = len(y_val)\n",
    "train_size = len(y_train)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    hybrid_model.modify_graphgather(train_size)\n",
    "    hybrid_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "    sahar_loss = hybrid_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "#     metric = dc.metrics.Metric(dc.metrics.score_function.rms_score)\n",
    "    sahar_pgnn_losses.append(sahar_loss.history['loss'])\n",
    "    hybrid_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "    hybrid_model.modify_graphgather(val_size)\n",
    "    sahar_pgnn_val_losses.append(hybrid_model.evaluate(x_val, y_val.reshape([1, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.49536362],\n",
       "        [ 1.0000191 ],\n",
       "        [ 1.0000283 ],\n",
       "        [ 1.0000933 ],\n",
       "        [ 0.99995077],\n",
       "        [-0.99997544],\n",
       "        [-0.9999683 ],\n",
       "        [-0.9999262 ],\n",
       "        [-1.0000305 ],\n",
       "        [-1.002259  ],\n",
       "        [-1.0032552 ],\n",
       "        [-0.9999263 ],\n",
       "        [-0.99642336],\n",
       "        [ 0.99991155],\n",
       "        [-1.0000669 ],\n",
       "        [-1.0047604 ],\n",
       "        [-0.9974049 ]], dtype=float32),\n",
       " array([0.00039988], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the wights after training\n",
    "hybrid_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# f, ax = plt.subplots()\n",
    "plt.plot(range(len(sahar_pgnn_losses)), sahar_pgnn_losses, label='train loss')\n",
    "plt.plot(range(len(sahar_pgnn_val_losses)), sahar_pgnn_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.ylim(0,500)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "plt.savefig('Sahar_PGNN_loss_26Mar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "hybrid_model.modify_graphgather(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 20.1714\n"
     ]
    }
   ],
   "source": [
    "evalu = hybrid_model.evaluate(x_test, y_test.reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.491253087260085\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "sahar_pgnn_rmse_test = np.sqrt(evalu)\n",
    "print(sahar_pgnn_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average training loss\n",
    "# sahar_train_loss = [sum(x)/len(x) for x in zip(*sahar_pgnn_losses)]\n",
    "sahar_train_loss = sahar_pgnn_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.601899147033691]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sahar_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6880752632008056"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "import math\n",
    "sahar_pgnn_rmse_train = math.sqrt(sahar_train_loss[0])\n",
    "sahar_pgnn_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.491253087260085"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sahar_pgnn_rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics based model RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# train_sum=0\n",
    "# for i in range(len(host_names_train)):\n",
    "#     new_df = df[(df['complex-name'] == host_names_train[i])]\n",
    "#     train_sum += new_df['gb_Ex_difference'].to_numpy()[0] **2\n",
    "\n",
    "\n",
    "# test_sum = 0\n",
    "# for i in range(len(host_names_test)):\n",
    "#     new_df = df[(df['complex-name'] == host_names_test[i])]\n",
    "#     test_sum += new_df['gb_Ex_difference'].to_numpy()[0] **2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physics_based_rmse_train = math.sqrt(train_sum / len(host_names_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physics_based_rmse_test = math.sqrt((test_sum) / len(host_names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"RMSE on training set is : {physics_based_rmse_train}\")\n",
    "# print(f\"RMSE on testing set is : {physics_based_rmse_test}\")\n",
    "# # Total rmse\n",
    "# total_rmse_physics = np.sqrt(np.mean((df['EX _H_(kcal/mol)'].to_numpy() - df['gb_delta_H'].to_numpy())**2))\n",
    "# print(f\"RMSE of the total data: {total_rmse_physics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE gbnsr6 vs experimental\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import math\n",
    "# mse_gb_ex = mean_squared_error(df['EX _delta_H_(kcal/mol)'], df['gb_delta_H'])\n",
    "# rmse_gbnsr6_ex = math.sqrt(mse_gb_ex)\n",
    "# print(rmse_gbnsr6_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE pbsa vs experimental\n",
    "# mse_pb_ex = mean_squared_error(df['EX _delta_H_(kcal/mol)'], df['pb_delta_H'])\n",
    "# rmse_pbsa_ex = math.sqrt(mse_pb_ex)\n",
    "# print(rmse_pbsa_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE gbnsr6 vs pbsa\n",
    "# mse_gb_pb = mean_squared_error(df['pb_delta_H'], df['gb_delta_H'])\n",
    "# rmse_gb_pb = math.sqrt(mse_gb_pb)\n",
    "# print(rmse_gb_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.title(\"Experimental vs GBNSR6\")\n",
    "# plt.scatter(x=df['EX _H_(kcal/mol)'], y=df['gb_delta_H'])\n",
    "# plt.xlabel(\"Experimental Delta H\")\n",
    "# plt.ylabel(\"GBNSR6 Delta H\")\n",
    "# plt.xlim(-25, 5)\n",
    "# plt.ylim(-25,5)\n",
    "\n",
    "# #reference line\n",
    "# plt.plot([-25, 5], [-25, 5], color='green', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(\"Experimental vs PBSA\")\n",
    "# plt.scatter(x=df['EX _H_(kcal/mol)'] ,y=df['pb_delta_H'], color='orange')\n",
    "# plt.xlabel(\"Experimental Delta H\")\n",
    "# plt.ylabel(\"PBSA Delta H\")\n",
    "# plt.xlim(-25, 5)\n",
    "# plt.ylim(-25,5)\n",
    "# #reference line\n",
    "# plt.plot([-25,5],[-25,5], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.subplot()\n",
    "# # plt.title(\"PBSA vs GBNSR6\")\n",
    "# plt.xlabel('Experimental H (kcal/mol)')\n",
    "# plt.ylabel('Physics-based model H (kcal/mol)')\n",
    "# ax.scatter(x=df[\"EX _H_(kcal/mol)\"], y=df['gb_delta_H'], label=\"GBNSR6\")\n",
    "# ax.scatter(x=df[\"EX _H_(kcal/mol)\"], y=df['pb_delta_H'], label=\"PBSA\", color=\"orange\")\n",
    "# plt.xlim(-25,5)\n",
    "# plt.ylim(-25,5)\n",
    "# #reference line\n",
    "# plt.plot([-25,5],[-25,5],color='green')\n",
    "# plt.legend()\n",
    "# plt.savefig('gb-pb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb_correlation_matrix = np.corrcoef(df['gb_delta_H'], df['EX _H_(kcal/mol)'])\n",
    "# gb_correlation_gbex = gb_correlation_matrix[0,1]\n",
    "# gb_r_squared = gb_correlation_gbex**2\n",
    "# print(gb_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pb_correlation_matrix = np.corrcoef(df['pb_delta_H'], df['EX _H_(kcal/mol)'])\n",
    "# pb_correlation_pbex = pb_correlation_matrix[0,1]\n",
    "# pb_r_squared = pb_correlation_pbex**2\n",
    "# print(pb_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pbgb_correlation_matrix = np.corrcoef(df['gb_delta_H'], df['pb_delta_H'])\n",
    "# pbgb_correlation = pbgb_correlation_matrix[0,1]\n",
    "# pbgb_r_squared = pbgb_correlation**2\n",
    "# print(pbgb_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Driven Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "input_shapes = [i.shape for i in x_preprocessed_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahar_dd_test_accuracy = []\n",
    "sahar_dd_train_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = int(len(pdb_names_train)/4)\n",
    "batch_size\n",
    "# batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# batch_size = int(len(df) / 2)\n",
    "\n",
    "class GBGraphConvModel(tf.keras.Model):\n",
    "   \n",
    "    def modify_graphgather(self, batch_size):\n",
    "        self.readout.batch_size = batch_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        super(GBGraphConvModel, self).__init__()\n",
    "        self.input_shapes = None\n",
    "        self.batch_size = batch_size\n",
    "        self.gc1 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.gp1 = GraphPool()\n",
    "\n",
    "        self.gc2 = GraphConv(32, activation_fn=tf.nn.tanh)\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.gp2 = GraphPool()\n",
    "\n",
    "        self.dense1 = layers.Dense(64, activation=tf.nn.tanh)\n",
    "        self.batch_norm3 = layers.BatchNormalization()\n",
    "        self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "        self.dense2 = layers.Dense(1)\n",
    "    #     self.dense3 = layers.Dense(1, \n",
    "    #          kernel_initializer=initializers.Constant([.5, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
    "    #          bias_initializer=initializers.Zeros())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = inputs[0]\n",
    "        x = []\n",
    "    #     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "    #                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "        for i in range(len(self.input_shapes)):\n",
    "            x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "        for i in range(1, len(self.input_shapes)):\n",
    "            x[i] = tf.cast(x[i], tf.int32)\n",
    "        x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 16])\n",
    "        gc1_output = self.gc1(x)\n",
    "        batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "        gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "        gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "        batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "        gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "        dense1_output = self.dense1(gp2_output)\n",
    "        batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "        readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "\n",
    "        model_var = self.dense2(readout_output)\n",
    "    #     binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "        return model_var #self.dense3(binding_affinity)\n",
    "sahar_dd_model = GBGraphConvModel(train_split_index)\n",
    "sahar_dd_model.compile(loss='mse', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_13:0\", shape=(83387, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_16:0\", shape=(205678, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_19:0\", shape=(290367, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Reshape_22:0\", shape=(188, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_11:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_10:0\", shape=(83387, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_13:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_12:0\", shape=(205678, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_15:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_14:0\", shape=(290367, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_16:0\", shape=(188, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_18:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_20:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_22:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_24:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_26:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Reshape_28:0\", shape=(0, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_conv_3/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_13:0\", shape=(83387, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_16:0\", shape=(205678, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_19:0\", shape=(290367, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Reshape_22:0\", shape=(188, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_1/graph_pool_2/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step - loss: 95.6094\n",
      "1/1 [==============================] - 2s 2s/step - loss: 100.9049\n",
      "1/1 [==============================] - 5s 5s/step - loss: 90.8892\n",
      "1/1 [==============================] - 2s 2s/step - loss: 98.1778\n",
      "1/1 [==============================] - 3s 3s/step - loss: 85.5456\n",
      "1/1 [==============================] - 1s 1s/step - loss: 97.9681\n",
      "1/1 [==============================] - 5s 5s/step - loss: 82.0007\n",
      "1/1 [==============================] - 1s 1s/step - loss: 94.1764\n",
      "1/1 [==============================] - 6s 6s/step - loss: 79.5815\n",
      "1/1 [==============================] - 2s 2s/step - loss: 92.9530\n",
      "1/1 [==============================] - 6s 6s/step - loss: 76.4181\n",
      "1/1 [==============================] - 1s 1s/step - loss: 92.6078\n",
      "1/1 [==============================] - 3s 3s/step - loss: 73.7903\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 92.3156\n",
      "1/1 [==============================] - 5s 5s/step - loss: 71.4124\n",
      "1/1 [==============================] - 1s 1s/step - loss: 92.2393\n",
      "1/1 [==============================] - 5s 5s/step - loss: 67.4285\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 92.1909\n",
      "1/1 [==============================] - 5s 5s/step - loss: 64.7000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 91.9481\n",
      "1/1 [==============================] - 3s 3s/step - loss: 62.7495\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 91.5009\n",
      "1/1 [==============================] - 4s 4s/step - loss: 61.1003\n",
      "1/1 [==============================] - 1s 1s/step - loss: 91.0544\n",
      "1/1 [==============================] - 4s 4s/step - loss: 58.7019\n",
      "1/1 [==============================] - 1s 1s/step - loss: 90.5432\n",
      "1/1 [==============================] - 4s 4s/step - loss: 55.7039\n",
      "1/1 [==============================] - 1s 1s/step - loss: 90.0242\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.6128\n",
      "1/1 [==============================] - 1s 1s/step - loss: 89.8103\n",
      "1/1 [==============================] - 4s 4s/step - loss: 51.4830\n",
      "1/1 [==============================] - 1s 1s/step - loss: 89.4662\n",
      "1/1 [==============================] - 4s 4s/step - loss: 49.5319\n",
      "1/1 [==============================] - 1s 1s/step - loss: 89.2022\n",
      "1/1 [==============================] - 5s 5s/step - loss: 47.5362\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 89.2318\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.6362\n",
      "1/1 [==============================] - 1s 1s/step - loss: 88.8010\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.5960\n",
      "1/1 [==============================] - 1s 1s/step - loss: 88.2261\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.5849\n",
      "1/1 [==============================] - 1s 1s/step - loss: 87.6857\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.4114\n",
      "1/1 [==============================] - 1s 1s/step - loss: 86.4042\n",
      "1/1 [==============================] - 3s 3s/step - loss: 37.4142\n",
      "1/1 [==============================] - 1s 1s/step - loss: 86.1485\n",
      "1/1 [==============================] - 5s 5s/step - loss: 35.7549\n",
      "1/1 [==============================] - 1s 1s/step - loss: 86.6062\n",
      "1/1 [==============================] - 5s 5s/step - loss: 34.2149\n",
      "1/1 [==============================] - 1s 1s/step - loss: 87.4885\n",
      "1/1 [==============================] - 5s 5s/step - loss: 32.3075\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 87.5597\n",
      "1/1 [==============================] - 3s 3s/step - loss: 30.2707\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 87.0753\n",
      "1/1 [==============================] - 4s 4s/step - loss: 28.0015\n",
      "1/1 [==============================] - 1s 1s/step - loss: 86.3010\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.6377\n",
      "1/1 [==============================] - 1s 1s/step - loss: 85.4224\n",
      "1/1 [==============================] - 5s 5s/step - loss: 25.3381\n",
      "1/1 [==============================] - 1s 1s/step - loss: 84.5750\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23.8015\n",
      "1/1 [==============================] - 1s 1s/step - loss: 83.2980\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.7945\n",
      "1/1 [==============================] - 1s 1s/step - loss: 82.2517\n",
      "1/1 [==============================] - 5s 5s/step - loss: 21.5239\n",
      "1/1 [==============================] - 2s 2s/step - loss: 80.5238\n",
      "1/1 [==============================] - 5s 5s/step - loss: 19.8544\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 79.6964\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.7312\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.6481\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.9018\n",
      "1/1 [==============================] - 2s 2s/step - loss: 78.3313\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.8730\n",
      "1/1 [==============================] - 2s 2s/step - loss: 77.3205\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.1868\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 77.9133\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.3690\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 78.0043\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.7123\n",
      "1/1 [==============================] - 1s 1s/step - loss: 77.1423\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.2563\n",
      "1/1 [==============================] - 1s 1s/step - loss: 76.6905\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.7125\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 76.5134\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.2848\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 77.8335\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.8082\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.3066\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.4302\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.2931\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.1017\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 79.0607\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.7809\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.8436\n",
      "1/1 [==============================] - 4s 4s/step - loss: 11.4780\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.8292\n",
      "1/1 [==============================] - 4s 4s/step - loss: 11.1483\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.4424\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.8419\n",
      "1/1 [==============================] - 1s 991ms/step - loss: 80.0643\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.5484\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 80.3611\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.3214\n",
      "1/1 [==============================] - 1s 1s/step - loss: 81.2096\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.1201\n",
      "1/1 [==============================] - 1s 1s/step - loss: 81.9561\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.9563\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 82.6600\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.6704\n",
      "1/1 [==============================] - 1s 1s/step - loss: 82.6210\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.4434\n",
      "1/1 [==============================] - 1s 983ms/step - loss: 82.7523\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.3326\n",
      "1/1 [==============================] - 1s 1s/step - loss: 82.3826\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.2167\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 81.6478\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.1391\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 80.2114\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.1029\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 78.9589\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.0558\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.7097\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.9737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 875ms/step - loss: 77.9349\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.8919\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 77.2897\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.8502\n",
      "1/1 [==============================] - 1s 1s/step - loss: 77.4207\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.8169\n",
      "1/1 [==============================] - 1s 1s/step - loss: 77.3882\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.7673\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 76.4903\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.7324\n",
      "1/1 [==============================] - 1s 1s/step - loss: 76.9749\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.7038\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.4590\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6869\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 78.3754\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.6744\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 78.3830\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6693\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.8724\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6600\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.7772\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6516\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.7574\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.6452\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 79.0832\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6379\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.1408\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6345\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.8976\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6310\n",
      "1/1 [==============================] - 1s 1s/step - loss: 80.4812\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.6239\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 80.2802\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.6049\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 80.0574\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.5905\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.6158\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.5835\n",
      "1/1 [==============================] - 2s 2s/step - loss: 79.4672\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.5733\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 79.3266\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.5694\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 79.1093\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.5607\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.5827\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.5555\n",
      "1/1 [==============================] - 1s 1s/step - loss: 80.3315\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.5397\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 80.0903\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.5317\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.8547\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.5158\n",
      "1/1 [==============================] - 1s 1s/step - loss: 79.8360\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.5083\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 79.1612\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.5020\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.6479\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4982\n",
      "1/1 [==============================] - 1s 1s/step - loss: 78.3289\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4954\n",
      "1/1 [==============================] - 1s 995ms/step - loss: 77.7062\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4913\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 77.4877\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.4862\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 76.3825\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4768\n",
      "1/1 [==============================] - 1s 1s/step - loss: 75.6747\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4693\n",
      "1/1 [==============================] - 1s 1s/step - loss: 74.7101\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4613\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 73.7409\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.4479\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 72.5828\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4405\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 72.2052\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8.4371\n",
      "1/1 [==============================] - 1s 1s/step - loss: 71.3899\n"
     ]
    }
   ],
   "source": [
    "sahar_dd_losses, sahar_dd_val_losses = [], []\n",
    "\n",
    "val_size = len(y_val)\n",
    "train_size = len(y_train)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sahar_dd_model.modify_graphgather(train_size)\n",
    "    sahar_dd_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "    dd_loss = sahar_dd_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "#     metric = dc.metrics.Metric(dc.metrics.score_function.rms_score)\n",
    "    sahar_dd_losses.append(dd_loss.history['loss'])\n",
    "    sahar_dd_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "    sahar_dd_model.modify_graphgather(val_size)\n",
    "    sahar_dd_val_losses.append(sahar_dd_model.evaluate(x_val, y_val.reshape([1, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# f, ax = plt.subplots()\n",
    "plt.plot(range(len(sahar_dd_losses)), sahar_dd_losses, label='train loss')\n",
    "plt.plot(range(len(sahar_dd_val_losses)), sahar_dd_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.savefig('Sahar_DataDriven_loss_26Mar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 957ms/step - loss: 71.3899\n"
     ]
    }
   ],
   "source": [
    "sahar_dd_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "sahar_dd_model.modify_graphgather(len(y_test))\n",
    "sahar_dd_test_loss= sahar_dd_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "# test_pgnn_loss = dd_model.evaluate(x_test, y_test.reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.449255320222521\n"
     ]
    }
   ],
   "source": [
    "sahar_dd_rmse_test = np.sqrt(sahar_dd_test_loss)\n",
    "print(sahar_dd_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sahar_dd_train_loss = sahar_dd_losses[-1]\n",
    "# sahar_dd_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.43713665008545]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average training loss\n",
    "# sahar_dd_train_loss = [sum(x)/len(x) for x in zip(*sahar_dd_losses)]\n",
    "sahar_dd_train_loss = sahar_dd_losses[-1]\n",
    "sahar_dd_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9046749646191827"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "sahar_dd_rmse_train = math.sqrt(sahar_dd_train_loss[0])\n",
    "# train_dd_rmse = math.sqrt(dd_train_loss[0])\n",
    "sahar_dd_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sahar_dd_test_accuracy = sahar_dd_rmse_test\n",
    "sahar_dd_train_accuracy = sahar_dd_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.449255320222521\n"
     ]
    }
   ],
   "source": [
    "print(sahar_dd_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9046749646191827"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sahar_dd_train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model Comparisons </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "| Sahar's model Test Set RMSE |\n",
      "+-------------------+--------+\n",
      "|    Data Driven    |  PGNN  |\n",
      "+-------------------+--------+\n",
      "|        8.45       |  4.49  |\n",
      "+-------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Sahar's model Test Set RMSE\"\n",
    "rmse_table.field_names = [ \"Data Driven\", \"PGNN\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(sahar_dd_rmse_test),\"{:.2f}\".format(sahar_pgnn_rmse_test)])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(np.array([sahar_dd_rmse_test,sahar_pgnn_rmse_test,sahar_dd_rmse_train,sahar_pgnn_rmse_train]).reshape(-1, 4),columns=['test-data-driven-rmse', 'test-pgnn-rmse', 'train-data-driven-rmse','train-pgnn-rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|    Train Set RMSE   |\n",
      "+-------------+-------+\n",
      "| Data Driven |  PGNN |\n",
      "+-------------+-------+\n",
      "|     4.90    | 24.93 |\n",
      "+-------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Train Set RMSE\"\n",
    "rmse_table.field_names = [\"Data Driven\", \"PGNN\"]\n",
    "rmse_table.add_row([ \"{:.2f}\".format(sahar_dd_rmse_train),\"{:.2f}\".format(sahar_pgnn_rmse_train)])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> PGNN and DD model average performance analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_results_dict = {\n",
    "#     \"pgnn_train\" : [x for x in pgnn_train_accuracy],\n",
    "#     \"dd_train\" : [x for x in dd_train_accuracy]\n",
    "# }\n",
    "# test_results_dict ={\n",
    "#     \"pgnn_test\" : [x for x in pgnn_test_accuracy],\n",
    "#     \"dd_test\" : [x for x in dd_test_accuracy]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Train box plot\n",
    "# plt.figure(figsize=(10,12))\n",
    "# plt.title(\"Train RMSE comparison\")\n",
    "# plt.boxplot([x for x in train_results_dict.values()],labels=[x for x in train_results_dict.keys()])\n",
    "# plt.xlabel(\"PGNN and DD train\")\n",
    "# plt.ylabel(\"RMSE\")\n",
    "# plt.ylim(2, 5, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Test box plot\n",
    "# plt.figure(figsize=(10,12))\n",
    "# plt.title(\"Test RMSE comparison\")\n",
    "# plt.boxplot([x for x in test_results_dict.values()],labels=[x for x in test_results_dict.keys()])\n",
    "# plt.xlabel(\"PGNN and DD train\")\n",
    "# plt.ylabel(\"RMSE\")\n",
    "# plt.ylim(0, 8, 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Ali's version</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [col for col in df.columns if (col[:3] == 'gb-' and not col.__contains__('etot')) or (col.__contains__('vdwaals'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gb-overall-1-4-eel'] = df.apply(lambda row: row['gb-complex-1-4-eel'] - row['gb-protein-1-4-eel'] - row['gb-ligand-1-4-eel'], axis=1)\n",
    "df['gb-overall-eelec'] = df.apply(lambda row: row['gb-complex-eelec'] - row['gb-protein-eelect'] - row['gb-ligand-eelec'], axis=1)\n",
    "df['gb-overall-egb'] = df.apply(lambda row: row['gb-complex-egb'] - row['gb-protein-egb'] - row['gb-ligand-egb'], axis=1)\n",
    "df['gb-overall-esurf'] = df.apply(lambda row: row['gb-complex-esurf'] - row['gb-protein-esurf'] - row['gb-ligand-esurf'], axis=1)\n",
    "df['pb-overall-vdwaals'] = df.apply(lambda row: row['pb-complex-vdwaals'] - row['pb-protein-vdwaals'] - row['pb-ligand-vdwaals'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['gb-overall-eelec'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pb-overall-vdwaals', ylabel='Frequency'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('pb-overall-vdwaals')\n",
    "df['pb-overall-vdwaals'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = [f for f in df.columns if f.__contains__('overall')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gb-overall-eelec', ylabel='Frequency'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('gb-overall-eelec')\n",
    "df['gb-overall-eelec'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gb-overall-eelec normalized', ylabel='Frequency'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXOUlEQVR4nO3de7SddX3n8feHi1wEFBaBYgIGO9FyGYoSGLqwLZZWqA6CM1LDqhJvTXVwlq7RqYBWmVkrDrM6goMOIo4ug4NC8Aa2MgosC+MIhoDRcJVUooSkQDuOBGu5+Z0/9u8Muyf7nGcHs8/Z4bxfa+21n/3dz/Ps737Q88lz2b8nVYUkSdPZYbYbkCSNP8NCktTJsJAkdTIsJEmdDAtJUqedZruBUdl3331r4cKFs92GJG1Xbr311r+rqnmT68/asFi4cCGrV6+e7TYkabuS5MeD6h6GkiR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHV61v6CW9KWFp71V7PyuevPe/WsfK62HfcsJEmdRhYWSQ5M8q0kdyW5I8m7Wv3cJA8kWdMer+pb5uwk65Lck+TEvvpRSda29y5MklH1LUna0igPQz0JvKeqbkuyJ3BrkmvbexdU1X/pnznJocAS4DDgBcB1SV5cVU8BnwCWATcDXwdOAq4ZYe+SpD4j27Ooqk1VdVub3gzcBcyfZpFTgMur6rGqug9YBxyT5ABgr6q6qaoKuBQ4dVR9S5K2NCPnLJIsBF4KfLeV3pnkB0k+k2TvVpsP3N+32IZWm9+mJ9cHfc6yJKuTrH744Ye35VeQpDlt5GGRZA/gS8C7q+oReoeUfh04EtgEfGRi1gGL1zT1LYtVl1TV4qpaPG/eFvfukCQ9QyMNiyQ70wuKy6rqywBV9WBVPVVVvwQ+BRzTZt8AHNi3+AJgY6svGFCXJM2QUV4NFeDTwF1VdX5f/YC+2V4L3N6mrwaWJNklycHAImBVVW0CNic5tq3zDOCqUfUtSdrSKK+GOg54I7A2yZpWOwc4PcmR9A4lrQf+FKCq7kiyEriT3pVUZ7YroQDeAXwW2I3eVVBeCSVJM2hkYVFV32bw+YavT7PMcmD5gPpq4PBt150kaWv4C25JUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1GllYJDkwybeS3JXkjiTvavV9klyb5N72vHffMmcnWZfkniQn9tWPSrK2vXdhkoyqb0nSlka5Z/Ek8J6qOgQ4FjgzyaHAWcD1VbUIuL69pr23BDgMOAm4KMmObV2fAJYBi9rjpBH2LUmaZGRhUVWbquq2Nr0ZuAuYD5wCrGizrQBObdOnAJdX1WNVdR+wDjgmyQHAXlV1U1UVcGnfMpKkGTAj5yySLAReCnwX2L+qNkEvUID92mzzgfv7FtvQavPb9OS6JGmGjDwskuwBfAl4d1U9Mt2sA2o1TX3QZy1LsjrJ6ocffnjrm5UkDTTSsEiyM72guKyqvtzKD7ZDS7Tnh1p9A3Bg3+ILgI2tvmBAfQtVdUlVLa6qxfPmzdt2X0SS5rhRXg0V4NPAXVV1ft9bVwNL2/RS4Kq++pIkuyQ5mN6J7FXtUNXmJMe2dZ7Rt4wkaQbsNMJ1Hwe8EVibZE2rnQOcB6xM8lbgJ8BpAFV1R5KVwJ30rqQ6s6qeasu9A/gssBtwTXtIkmbIyMKiqr7N4PMNACdMscxyYPmA+mrg8G3XnSRpa/gLbklSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ2GCoskh4+6EUnS+Bp2z+LiJKuS/Jskzx9lQ5Kk8TNUWFTVy4E/Bg4EVif5fJI/GGlnkqSxMfQ5i6q6F/gA8D7gd4ELk9yd5F+NqjlJ0ngY9pzFEUkuAO4Cfg84uaoOadMXjLA/SdIY2GnI+T4OfAo4p6p+MVGsqo1JPjCSziRJY2PYsHgV8IuqegogyQ7ArlX1D1X1uZF1J0kaC8Oes7gO2K3v9e6tJkmaA4YNi12r6tGJF2169+kWSPKZJA8lub2vdm6SB5KsaY9X9b13dpJ1Se5JcmJf/agka9t7FybJ8F9PkrQtDBsWP0/ysokXSY4CfjHN/ACfBU4aUL+gqo5sj6+39R0KLAEOa8tclGTHNv8ngGXAovYYtE5J0ggNe87i3cCVSTa21wcAr59ugaq6McnCIdd/CnB5VT0G3JdkHXBMkvXAXlV1E0CSS4FTgWuGXK8kaRsYKiyq6pYkvwG8BAhwd1U98Qw/851JzgBWA++pqp8C84Gb++bZ0GpPtOnJ9YGSLKO3F8JBBx30DNuTJE22NQMJHg0cAbwUOL39wd9anwB+HTgS2AR8pNUHnYeoaeoDVdUlVbW4qhbPmzfvGbQnSRpkqD2LJJ+j90d+DfBUKxdw6dZ8WFU92LfOTwF/2V5uoDeUyIQFwMZWXzCgLkmaQcOes1gMHFpVU/6rfhhJDqiqTe3la4GJK6WuBj6f5HzgBfROZK+qqqeSbE5yLPBd4AzgY79KD5KkrTdsWNwO/Bq9Q0dDSfIF4Hhg3yQbgA8Bxyc5kt5eyXrgTwGq6o4kK4E7gSeBMyd+AAi8g96VVbvRO7HtyW1JmmHDhsW+wJ1JVgGPTRSr6jVTLVBVpw8of3qa+ZcDywfUVwPeT0OSZtGwYXHuKJuQJI23YS+dvSHJC4FFVXVdkt2BHbuWkyQ9Oww7RPmfAF8EPtlK84GvjqgnSdKYGfZ3FmcCxwGPwP+/EdJ+o2pKkjRehg2Lx6rq8YkXSXZimh/HSZKeXYYNixuSnAPs1u69fSXwtdG1JUkaJ8OGxVnAw8Baer+N+Dq9+3FLkuaAYa+G+iW926p+arTtSJLG0bBjQ93HgHMUVfWibd6RJGnsbM3YUBN2BU4D9tn27UiSxtFQ5yyq6u/7Hg9U1UeB3xtta5KkcTHsYaiX9b3cgd6exp4j6UiSNHaGPQz1kb7pJ+mNGPtH27wbSdJYGvZqqFeMuhFJ0vga9jDUv5vu/ao6f9u0I0kaR1tzNdTR9O5oB3AycCNw/yiakiSNl625+dHLqmozQJJzgSur6m2jakySND6GHe7jIODxvtePAwu3eTeSpLE07J7F54BVSb5C75fcrwUuHVlXkqSxMuzVUMuTXAP8diu9uaq+N7q2JEnjZNjDUAC7A49U1X8FNiQ5eEQ9SZLGzLC3Vf0Q8D7g7FbaGfgfo2pKkjReht2zeC3wGuDnAFW1EYf7kKQ5Y9iweLyqijZMeZLnjq4lSdK4GTYsVib5JPD8JH8CXIc3QpKkOaPzaqgkAa4AfgN4BHgJ8MGqunbEvUmSxkRnWFRVJflqVR0FGBCSNAcNexjq5iRHj7QTSdLYGvYX3K8A3p5kPb0rokJvp+OIUTUmSRof04ZFkoOq6ifAH85QP5KkMdS1Z/FVeqPN/jjJl6rqX89AT5KkMdN1ziJ90y/amhUn+UySh5Lc3lfbJ8m1Se5tz3v3vXd2knVJ7klyYl/9qCRr23sXtquzJEkzqCssaorpYXwWOGlS7Szg+qpaBFzfXpPkUGAJcFhb5qIkO7ZlPgEsAxa1x+R1SpJGrCssfjPJI0k2A0e06UeSbE7yyHQLVtWNwP+ZVD4FWNGmVwCn9tUvr6rHquo+YB1wTJIDgL2q6qb2C/JL+5aRJM2Qac9ZVNWO073/DOxfVZvaujcl2a/V5wM39823odWeaNOT6wMlWUZvL4SDDjpoG7YtSXPb1gxRPkqDzkPUNPWBquqSqlpcVYvnzZu3zZqTpLlupsPiwXZoifb8UKtvAA7sm28BsLHVFwyoS5Jm0EyHxdXA0ja9FLiqr74kyS7tpkqLgFXtkNXmJMe2q6DO6FtGkjRDhv0F91ZL8gXgeGDfJBuADwHn0RvB9q3AT4DTAKrqjiQrgTuBJ4Ezq+qptqp30LuyajfgmvaQJM2gkYVFVZ0+xVsnTDH/cmD5gPpq4PBt2JokaSuNywluSdIYMywkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqdZCYsk65OsTbImyepW2yfJtUnubc97981/dpJ1Se5JcuJs9CxJc9ls7lm8oqqOrKrF7fVZwPVVtQi4vr0myaHAEuAw4CTgoiQ7zkbDkjRXjdNhqFOAFW16BXBqX/3yqnqsqu4D1gHHzHx7kjR3zVZYFPDNJLcmWdZq+1fVJoD2vF+rzwfu71t2Q6tJkmbITrP0ucdV1cYk+wHXJrl7mnkzoFYDZ+wFzzKAgw466FfvUpIEzNKeRVVtbM8PAV+hd1jpwSQHALTnh9rsG4AD+xZfAGycYr2XVNXiqlo8b968UbUvSXPOjIdFkucm2XNiGnglcDtwNbC0zbYUuKpNXw0sSbJLkoOBRcCqme1akua22TgMtT/wlSQTn//5qvqfSW4BViZ5K/AT4DSAqrojyUrgTuBJ4MyqemoW+pakOWvGw6KqfgT85oD63wMnTLHMcmD5iFuTJE1hnC6dlSSNKcNCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktRpp9luQJprFp71V7PdgrTV3LOQJHUyLCRJnQwLSVInw0KS1MkT3JJGbrZO6q8/79Wz8rnPRtvNnkWSk5Lck2RdkrNmux9Jmku2i7BIsiPw34A/BA4FTk9y6Ox2JUlzx/ZyGOoYYF1V/QggyeXAKcCds9qVpLE2m79pebYdAttewmI+cH/f6w3Av5g8U5JlwLL28tEk98xAbzNpX+DvZruJMeW2mZrbZnoj2T75z9t6jTPmhYOK20tYZECttihUXQJcMvp2ZkeS1VW1eLb7GEdum6m5babn9hnOdnHOgt6exIF9rxcAG2epF0mac7aXsLgFWJTk4CTPAZYAV89yT5I0Z2wXh6Gq6skk7wS+AewIfKaq7pjltmbDs/YQ2zbgtpma22Z6bp8hpGqLQ/+SJP0T28thKEnSLDIsJEmdDIvtSJL3Jqkk+/bVzm5DoNyT5MTZ7G82JPmLJHcn+UGSryR5ft97c3rbgMPk9EtyYJJvJbkryR1J3tXq+yS5Nsm97Xnv2e51HBkW24kkBwJ/APykr3YovSvDDgNOAi5qQ6PMJdcCh1fVEcAPgbPBbQMOkzPAk8B7quoQ4FjgzLY9zgKur6pFwPXttSYxLLYfFwB/xj/9MeIpwOVV9VhV3Qesozc0ypxRVd+sqifby5vp/QYH3DbQN0xOVT0OTAyTMydV1aaquq1Nbwbuojc6xCnAijbbCuDUWWlwzBkW24EkrwEeqKrvT3pr0DAo82essfHzFuCaNu22cRtMKclC4KXAd4H9q2oT9AIF2G8WWxtb28XvLOaCJNcBvzbgrfcD5wCvHLTYgNqz7lro6bZNVV3V5nk/vcMMl00sNmD+Z9226eA2GCDJHsCXgHdX1SPJoM2kyQyLMVFVvz+onuSfAwcD32//o14A3JbkGObIMChTbZsJSZYC/xI4oZ7+4dCc2DYd3AaTJNmZXlBcVlVfbuUHkxxQVZuSHAA8NHsdji8PQ425qlpbVftV1cKqWkjvD8DLqupv6Q15siTJLkkOBhYBq2ax3RmX5CTgfcBrquof+t6a89sGh8n5J9L719angbuq6vy+t64GlrbppcBVM93b9sA9i+1YVd2RZCW9+3o8CZxZVU/Nclsz7ePALsC1bc/r5qp6u9vGYXIGOA54I7A2yZpWOwc4D1iZ5K30rjY8bXbaG28O9yFJ6uRhKElSJ8NCktTJsJAkdTIsJEmdDAtJUifDQrMiyV8nWTzbfUyW5E1JPt6mz03y3m203rH8vlsryaPt+QVJvrgN1rfNtrFGy7DQnJNkTv6+aFuOultVG6vqddtqfRp/hoVGKsmft/tNXJvkC5P+FfmGJN9JcnsbvmTQ8kcmubnvfhV7Jzkkyaq+eRYm+UGbPirJDUluTfKNNnzDxL/sP5zkBuBdSU5O8t0k30tyXZL9t/J7vSHJqiRrknxy4g9xklcmuSnJbUmubOMQTV524DxJjm7b4/tt3XtOWu749j2+2LbpZe1XySQ5oX2XtUk+k2SXVl+f5INJvg2c1l5/uH3+6iQva9vpb5K8vS2zR5LrW39rk2wxUm3b5re36f/etsOaJA8n+VCr//skt7T/dv+hb9n3p3ePjeuAl2zNdtcsqiofPkbyABYDa4DdgD2Be4H3tvf+GvhUm/4d4PYp1vED4Hfb9H8EPtqm1wAvatPvAz4A7Ax8B5jX6q+n96vlic+7qG+9e/P0j1LfBnykTb8J+HibPnei30k9HQJ8Ddi5vb4IOAPYF7gReG5fXx/s+/zFU80DPAf4EXB0q+8F7DTpc48HfkZvjKcdgJuAlwO70htd9sVtvkvpDZIHsB74s751rAfe0aYvaNt3T2Ae8FCr7wTs1ab3pTe8+8S2erQ9L5z83wx4IXB3e34lcAm9wQx3AP6y/Xc+ClgL7N6+47pB29jH+D3m5O64ZszLgauq6hcASb426f0vAFTVjUn2SvL8qvq/E28meR7w/Kq6oZVWAFe26ZXAH9EbquH17fES4HCeHvpjR2BT3+dd0Te9ALii7Xk8B7hvK77XCfT+6N3SPmc3eoPPHUvvJkP/u9WfQ+8Per+p5nkJsKmqbmnb5JEpPntVVW0AaENWLAQ2A/dV1Q/bPCuAM4GPDvje8PT4UGuBPap3b4fNSf4xvTsN/hz4cJLfAX5Jb1jz/YG/nWqDJNmV3n+bd1bVj5P8W3qB8b02yx70xufaE/hKtXG8kszZsaq2N4aFRqlr7OfJY81Ukm/Q+8O0GnjPNMteAVyZ5MtAVdW96Y3Qe0dV/dYUy/y8b/pjwPlVdXWS4+ntRQyU3l0KJ4LuYnrfa0VVnT1pvpOBa6vq9Gn6zqB5khzBcMOHP9Y3/RS9/w93beefT3o9sY5fTlrfL9v6/pjensZRVfVEkvX09l6mczHw5aq6rr0O8J+q6pP9MyV5Nw6Tvl3ynIVG6dvAyUl2bcflXz3p/dcDJHk58LOq+llVnVhVR1bV26rqZ8BPk/x2m/+NwA0AVfU39P5Y/jlP/8v5HmBekt9q6905yWFT9PY84IE2vXSKeWifdX/r6ciqupjerTdfl2S/9jn7JHkhvTv1HZfkn7X67klePGl1U81zN/CCJEe3+p4Z/kT83cDCiXXSt52eoefROyT1RJJX0DusNKUkZwJ7VtV5feVvAG/pOx8zv22vG4HXJtmtnZM5+VfoUzPIPQuNTFXd0g4zfB/4Mb29hZ/1zfLTJN+hd+z6LVOsZilwcZLd6R3Tf3Pfe1cAf0Hvfh9U1eNJXgdc2A5h7UTvUMygkVbPpbdn8gC9P+AHb8X3ujPJB4BvJtkBeILeqLY3J3kT8IWJE8z0zqX8sG/ZhwfNU1U/TPJ64GNJdgN+Afw+8OgQ/fxjkje377MTvaHJLx72+wxwGfC1JKvpnRu6u2P+9wJP5OmRXC+uqouTHALc1A63PQq8oapuS3JFW++Pgf/1K/SpGeSosxqpJHtU1aPtj/2NwLJq90GWtP1wz0KjdkmSQ+kd815hUEjbJ/csJEmdPMEtSepkWEiSOhkWkqROhoUkqZNhIUnq9P8AN9bv7SPp/eEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('gb-overall-eelec normalized')\n",
    "((df['gb-overall-eelec'] - df['gb-overall-eelec'].std()) / df['gb-overall-eelec'].mean()).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save PDB\n",
    "# import pickle\n",
    "# with open('PDBs.pkl', 'wb') as file:\n",
    "#     pickle.dump(PDBs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load PDB\n",
    "# import pickle\n",
    "# PDBs = {}\n",
    "# with open('PDBs.pkl', 'rb') as file:\n",
    "#     PDBs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[training_columns]),\n",
    "                   columns=training_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gb-overall-1-4-eel', ylabel='Frequency'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbZElEQVR4nO3df5BdZZ3n8ffHIL9UFCYBYwImuMExsBpMy8CiIw4qiD9ARyWUSnDQCIO7Wrq1EnUWaqsyxTiDWOgIxJEFHPkRBpHMCovACqwKxAYiIUCGIChNUqQVF9CxgsBn/zhPw6Fzu3P7pG/fvp3Pq+pWn/uc5znn++RHf+85z7nPI9tEREQ08aJuBxAREb0rSSQiIhpLEomIiMaSRCIiorEkkYiIaGyHbgfQKdOnT/ecOXO6HUZERE+5/fbbf217Rrv1p2wSmTNnDv39/d0OIyKip0j65Vjq53ZWREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENDZlv7EeETHn1B907dwPnfHurp17IuVKJCIiGksSiYiIxpJEIiKisY4lEUl7S/qRpHslrZX0mVK+h6TrJN1ffu5ea7NU0npJ6yQdUStfKGlN2Xe2JHUq7oiIaF8nr0SeBj5v+3XAwcApkuYDpwI32J4H3FDeU/YtAvYHjgS+KWlaOdY5wBJgXnkd2cG4IyKiTR1LIrY32r6jbD8J3AvMAo4GLizVLgSOKdtHA5fa3mz7QWA9cJCkmcButm+xbeCiWpuIiOiiCRkTkTQHOBC4DdjL9kaoEg2wZ6k2C3i41myglM0q28PLW51niaR+Sf2Dg4Pj2oeIiNhSx5OIpJcCVwCftf3EaFVblHmU8i0L7eW2+2z3zZjR9uqOERHRUEeTiKQXUyWQ79r+Xil+tNyiovzcVMoHgL1rzWcDG0r57BblERHRZZ18OkvAt4F7bX+1tmslsLhsLwauqpUvkrSTpLlUA+iryi2vJyUdXI55fK1NRER0USenPTkU+BiwRtLqUvZF4AxghaQTgV8BHwKwvVbSCuAeqie7TrH9TGl3MnABsAtwTXlFRESXdSyJ2P4xrcczAA4foc0yYFmL8n7ggPGLLiIixkO+sR4REY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENNbJ5XHPl7RJ0t21ssskrS6vh4ZWPJQ0R9IfavvOrbVZKGmNpPWSzi5L5EZExCTQyeVxLwC+AVw0VGD72KFtSWcCj9fqP2B7QYvjnAMsAW4FrgaOJMvjRkRMCh27ErF9M/BYq33lauLDwCWjHUPSTGA327fYNlVCOmacQ42IiIa6NSbyFuBR2/fXyuZKulPSTZLeUspmAQO1OgOlrCVJSyT1S+ofHBwc/6gjIuIFupVEjuOFVyEbgX1sHwh8DrhY0m5Aq/EPj3RQ28tt99numzFjxrgGHBERW+rkmEhLknYAPgAsHCqzvRnYXLZvl/QAsB/VlcfsWvPZwIaJizYiIkbTjSuRtwP32X7uNpWkGZKmle19gXnAL2xvBJ6UdHAZRzkeuKoLMUdERAudfMT3EuAW4LWSBiSdWHYtYssB9T8H7pL0c+BfgJNsDw3Knwz8E7AeeIA8mRURMWl07HaW7eNGKD+hRdkVwBUj1O8HDhjX4CIiYlzkG+sREdFYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGOdXNnwfEmbJN1dKztd0iOSVpfXUbV9SyWtl7RO0hG18oWS1pR9Z5dlciMiYhLo5JXIBcCRLcrPsr2gvK4GkDSfatnc/Uubbw6tuQ6cAyyhWnd93gjHjIiILuhYErF9M/DYVitWjgYutb3Z9oNU66kfJGkmsJvtW2wbuAg4piMBR0TEmHVjTOTTku4qt7t2L2WzgIdrdQZK2ayyPby8JUlLJPVL6h8cHBzvuCMiYpiJTiLnAK8BFgAbgTNLeatxDo9S3pLt5bb7bPfNmDFjG0ONiIitmdAkYvtR28/Yfhb4FnBQ2TUA7F2rOhvYUMpntyiPiIhJYEKTSBnjGPJ+YOjJrZXAIkk7SZpLNYC+yvZG4ElJB5enso4HrprImCMiYmQ7dOrAki4BDgOmSxoATgMOk7SA6pbUQ8CnAGyvlbQCuAd4GjjF9jPlUCdTPem1C3BNeUVExCTQsSRi+7gWxd8epf4yYFmL8n7ggHEMLSIixkm+sR4REY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ0liQSERGNJYlERERjSSIREdFYkkhERDTWVhKRlAkQIyJiC+1eiZwraZWkv5b0ik4GFBERvaOtJGL7zcBHqFYf7Jd0saR3dDSyiIiY9NoeE7F9P/Bl4AvAW4GzJd0n6QOdCi4iIia3dsdEXi/pLOBe4C+A99p+Xdk+a4Q250vaJOnuWtnfl8Rzl6Qrh26NSZoj6Q+SVpfXubU2CyWtkbRe0tllmdyIiJgE2r0S+QZwB/AG26fYvgPA9gaqq5NWLgCOHFZ2HXCA7dcD/wYsre17wPaC8jqpVn4OsIRq3fV5LY4ZERFd0m4SOQq42PYfACS9SNKuALa/06qB7ZuBx4aV/dD20+XtrcDs0U4qaSawm+1bbBu4CDimzZgjIqLD2k0i1wO71N7vWsq2xV8B19Tez5V0p6SbJL2llM0CBmp1BkpZS5KWSOqX1D84OLiN4UVExNa0m0R2tv27oTdle9emJ5X0JeBp4LulaCOwj+0Dgc8BF0vaDWg1/uGRjmt7ue0+230zZsxoGl5ERLSp3STye0lvHHojaSHwhyYnlLQYeA/wkXKLCtubbf+mbN8OPADsR3XlUb/lNRvY0OS8EREx/nZos95ngcslDf0CnwkcO9aTSTqS8oiw7X+vlc8AHrP9jKR9qQbQf2H7MUlPSjoYuA04Hvj6WM8bERGd0VYSsf0zSX8KvJbqFtN9tv84WhtJlwCHAdMlDQCnUT2NtRNwXXlS99byJNafA/9D0tPAM8BJtocG5U+metJrF6oxlPo4SkREdFG7VyIAbwLmlDYHSsL2RSNVtn1ci+Jvj1D3CuCKEfb1A5m7KyJiEmoriUj6DvAaYDXVlQJUA9wjJpGIiJj62r0S6QPmDw2ER0REQPtPZ90NvLKTgURERO9p90pkOnCPpFXA5qFC2+/rSFQREdET2k0ip3cyiIiI6E3tPuJ7k6RXA/NsX1/mzZrW2dAiImKya3cq+E8C/wKcV4pmAd/vUEwREdEj2h1YPwU4FHgCnlugas9OBRUREb2h3SSy2fZTQ28k7cAoEyFGRMT2od0kcpOkLwK7lLXVLwf+tXNhRUREL2g3iZwKDAJrgE8BVzPyioYREbGdaPfprGeBb5VXREQE0P7cWQ/SYgzE9r7jHlFERPSMscydNWRn4EPAHuMfTkRE9JK2xkRs/6b2esT214C/6GxoEREx2bV7O+uNtbcvoroyeVlHIoqIiJ7R7u2sM2vbTwMPAR8erYGk86nWUt9k+4BStgdwGdXiVg8BH7b927JvKXAi1Xol/8X2taV8Ic+vbHg18JlMSR8RMTm0ezvrbbXXO2x/0va6rTS7ADhyWNmpwA225wE3lPdImg8sAvYvbb4paWhurnOAJVTrrs9rccyIiOiSdm9nfW60/ba/2qLsZklzhhUfTbXuOsCFwI3AF0r5pbY3Aw9KWg8cJOkhYDfbt5Q4LgKOIeusR0RMCmN5OutNwMry/r3AzcDDYzzfXrY3AtjeKGlo/q1ZwK21egOl7I9le3h5S5KWUF21sM8++4wxtIiIGKuxLEr1RttPAkg6Hbjc9ifGKQ61KPMo5S3ZXg4sB+jr68u4SUREh7U77ck+wFO1909RDY6P1aOSZgKUn5tK+QCwd63ebGBDKZ/dojwiIiaBdpPId4BVkk6XdBpwG3BRg/OtBBaX7cXAVbXyRZJ2kjSXagB9Vbn19aSkgyUJOL7WJiIiuqzdubOWSboGeEsp+rjtO0drI+kSqkH06ZIGgNOAM4AVkk4EfkX1zXdsr5W0AriH6hHiU2w/Uw51Ms8/4nsNGVSPiJg02h0TAdgVeML2/5Q0Q9Jc2w+OVNn2cSPsOnyE+suAZS3K+4EDxhBnRERMkHaXxz2N6lHcpaXoxcA/dyqoiIjoDe2OibwfeB/wewDbG8i0JxER2712k8hTZaoRA0h6SedCioiIXtFuElkh6TzgFZI+CVxPFqiKiNjubXVgvTxaexnwp8ATwGuB/277ug7HFhERk9xWk4htS/q+7YVAEkdERDyn3dtZt0p6U0cjiYiIntPu90TeBpxUZtX9PdWcVrb9+k4FFhERk9+oSUTSPrZ/BbxrguKJiIgesrUrke9Tzd77S0lX2P7LCYgpIiJ6xNbGROpTse/byUAiIqL3bC2JeITtiIiIrd7OeoOkJ6iuSHYp2/D8wPpuHY0uIiImtVGTiO1pExVIRET0nna/JxIREbGFJJGIiGhswpOIpNdKWl17PSHps2Xp3Udq5UfV2iyVtF7SOklHTHTMERHR2lhWNhwXttcBCwAkTQMeAa4EPg6cZfsf6vUlzQcWAfsDrwKul7RfbfnciIjokm7fzjoceMD2L0epczRwqe3NZTne9cBBExJdRESMqttJZBFwSe39pyXdJel8SbuXslnAw7U6A6VsC5KWSOqX1D84ONiZiCMi4jldSyKSdqRacvfyUnQO8BqqW10bgTOHqrZo3vKLj7aX2+6z3TdjxozxDTgiIrbQzSuRdwF32H4UwPajtp+x/SzVqolDt6wGgL1r7WYDGyY00oiIaKmbSeQ4areyJM2s7Xs/cHfZXgkskrSTpLnAPGDVhEUZEREjmvCnswAk7Qq8A/hUrfgrkhZQ3ap6aGif7bWSVgD3AE8Dp+TJrIiIyaErScT2vwN/MqzsY6PUXwYs63RcERExNt1+OisiInpYkkhERDSWJBIREY0liURERGNJIhER0ViSSERENJYkEhERjSWJREREY0kiERHRWJJIREQ0liQSERGNJYlERERjSSIREdFYkkhERDSWJBIREY0liURERGNdSSKSHpK0RtJqSf2lbA9J10m6v/zcvVZ/qaT1ktZJOqIbMUdExJa6eSXyNtsLbPeV96cCN9ieB9xQ3iNpPrAI2B84EvimpGndCDgiIl5oMt3OOhq4sGxfCBxTK7/U9mbbDwLrgYMmPryIiBiuW0nEwA8l3S5pSSnby/ZGgPJzz1I+C3i41naglG1B0hJJ/ZL6BwcHOxR6REQM2aFL5z3U9gZJewLXSbpvlLpqUeZWFW0vB5YD9PX1tawTERHjpytXIrY3lJ+bgCupbk89KmkmQPm5qVQfAPauNZ8NbJi4aCMiYiQTnkQkvUTSy4a2gXcCdwMrgcWl2mLgqrK9ElgkaSdJc4F5wKqJjToiIlrpxu2svYArJQ2d/2Lb/1vSz4AVkk4EfgV8CMD2WkkrgHuAp4FTbD/ThbgjImKYCU8itn8BvKFF+W+Aw0doswxY1uHQIiJijCbTI74REdFjkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisW5NBR8R25E5p/6g2yFEh+RKJCIiGsuVSEREB3Tr6uuhM949oefLlUhERDSWJBIREY0liURERGPdWB53b0k/knSvpLWSPlPKT5f0iKTV5XVUrc1SSeslrZN0xETHHBERrXVjYP1p4PO27yhrrd8u6bqy7yzb/1CvLGk+sAjYH3gVcL2k/bJEbkRE9034lYjtjbbvKNtPAvcCs0ZpcjRwqe3Nth8E1gMHdT7SiIjYmq6OiUiaAxwI3FaKPi3pLknnS9q9lM0CHq41G2CEpCNpiaR+Sf2Dg4OdCjsiIoquJRFJLwWuAD5r+wngHOA1wAJgI3DmUNUWzd3qmLaX2+6z3TdjxozxDzoiIl6gK0lE0oupEsh3bX8PwPajtp+x/SzwLZ6/ZTUA7F1rPhvYMJHxRkREa914OkvAt4F7bX+1Vj6zVu39wN1leyWwSNJOkuYC84BVExVvRESMrBtPZx0KfAxYI2l1KfsicJykBVS3qh4CPgVge62kFcA9VE92nZInsyIiJocJTyK2f0zrcY6rR2mzDFjWsaAiIqKRfGM9IiIaSxKJiIjGkkQiIqKxJJGIiGgsSSQiIhpLEomIiMaSRCIiorEkkYiIaCxJJCIiGksSiYiIxpJEIiKisSSRiIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGisZ5KIpCMlrZO0XtKp3Y4nIiJ6JIlImgb8I/AuYD7VUrrzuxtVRET0RBIBDgLW2/6F7aeAS4GjuxxTRMR2b8LXWG9oFvBw7f0A8GfDK0laAiwpb38naV3D800Hft2wba9Kn7cP21uft7f+or/b5j6/eiyVeyWJqEWZtyiwlwPLt/lkUr/tvm09Ti9Jn7cP21uft7f+wsT3uVduZw0Ae9fezwY2dCmWiIgoeiWJ/AyYJ2mupB2BRcDKLscUEbHd64nbWbaflvRp4FpgGnC+7bUdPOU23xLrQenz9mF76/P21l+Y4D7L3mJoISIioi29cjsrIiImoSSRiIhobMolEUl7SLpO0v3l5+4j1Gs5jcpo7SUtLfXXSTqiVr5M0sOSfjfsHDtJuqy0uU3SnA50uVt9XihpTdl3tiSV8n0k/UjSnZLuknTUVO9z2fdhSfdIWivp4u2hz2X/ByVZUkceKZ1MfZb0ufJ3fJekGySN6fsUW+nnqNM6qXJ22X+XpDdOZN9HZXtKvYCvAKeW7VOBv2tRZxrwALAvsCPwc2D+aO2pplv5ObATMLe0n1b2HQzMBH437Dx/DZxbthcBl02hPq8CDqH6Ds81wLtK+XLg5Fr7h7aDPs8D7gR2L+/3nOp9LvteBtwM3Ar0TfU+A28Ddi3bJzNO/59Hi79W56gSi6h+39w20X/fI8bfib/4br6AdcDMsj0TWNeiziHAtbX3S4Glo7Wv1ynvrwUOGXbc4UnkuTpUT8L9mvIwQy/3udS5r1Z+HHBe2T4P+ELtnD+dCn/PW+nzV4BPTLV/26P1ubz/GvAe4EY6l0QmVZ9r5QcCPxmnPo4Yf63sPOC44X8u3ej78NeUu50F7GV7I0D5uWeLOq2mUZm1lfajtRnJc21sPw08DvxJ2z1p30T3eVbZbnWs04GPShoArgb+c7MubdVk6vN+wH6SfiLpVklHNu7V6CZNnyUdCOxt+39tS4faMGn6PMyJVJ/Ux0M7v1tGi3ei+/4CPfE9keEkXQ+8ssWuL7V7iBZlW3vWeaLatD7Q5OrzaMc6DrjA9pmSDgG+I+kA28+2GefzJ++dPu9AdUvrMKrZFP5v6fP/ay/M2sl7oM+SXgScBZzQZkyjn7wH+vyChtJHgT7grW1Ft3XtxN843jGcr9Hvq55MIrbfPtI+SY9Kmml7o6SZwKYW1UabRmWk9k2mXhlqMyBpB+DlwGNbadPSJOvzQNludawTgSNLzLdI2plqErxWMY2qh/o8ANxq+4/Ag6om/pxHNdPCmPRIn18GHADcWMZdXwmslPQ+2/1tdvU5PdLnoXjeTpXc3mp7c1sd3Lp2freMVGfHUdqOa99HMhVvZ60EFpftxcBVLeqMNo3KSO1XAotUPXE1l+qXxKoxxPJB4P+43GwcZxPa53Jp/KSkg8vTG8fX2vwKOBxA0uuAnYHB8enmC0ymPn+fatAVSdOpbm/9Ylx6+UKTos+2H7c93fYc23OoBtYbJZA2TIo+w3O38M6j6uuYPxSNop1pnVYCx5entA4GHi+xTtS/8ZGNx8DQZHpRjTncANxffu5Ryl8FXF2rdxTwb1RPJnxpa+3Lvi+V+ut44VMqX6HK4s+Wn6eX8p2By4H1VAln3ynU5z7g7rLvGzw/+8F84CdUT3+sBt65HfRZwFeBe4A1wKKp3udhcd1I5wbWJ02fgeuBR8u/69XAynHs5xbxAycBJ9X+jf1j2b+m/uc90X/fw1+Z9iQiIhqbirezIiJigiSJREREY0kiERHRWJJIREQ0liQSEbGdkfQhVZOFPqttnDwzSSSmLEk3but/kE6QdIKkb5Tt0yX91xHqnS9pk6S72zjmNFUzJ4/bNCST9c8vxkbSYZIuGFZ8N/ABqgk0t0mSSEQHlBkKttUFlG//t+EzwL3jcM7YDti+1/a68ThWkkhMCZL+RtJ9qtZNuKT26f6jkn4q6W5JB43QdoGqiRPvknSlpN0lvU7SqlqdOZLuKtsLJd0k6XZJ15YpJYY+uf+tpJuAz0h6r6p1ZO6UdL2kvcbSJ9s308Y0OZJmA+8G/mkr9T4qaZWk1ZLOkzStlL9T0i2S7pB0uaSXjiXO2L4liUTPK7dc/pJqeu4PUH3rdshLbP8nqrVdzh/hEBdRTV//eqpvA59m+15gR0n7ljrHAiskvRj4OvBB2wvLMZfVjvUK22+1fSbwY+Bg2wcClwL/bRy628rXyrFHnOSyTEFzLHCo7QXAM8BHyjQtXwbebvuNQD/wuQ7FGROofIBZTfXh4n3lw8Nq1RahGg89OQFjxDBvpprT6Q8Akv61tu8SqD7VS9pN0itcm11X0supfvHfVIoupJqqBmAF8GHgDKpfwMcCr6WafPC6anohpgEba+e7rLY9G7isXKnsCDy47V19IUnvATbZvl3SYaNUPRxYCPysxL0L1YR8B1OmqinlOwK3jHecMfFs/xlUYyLACbZP6MR5kkRiKhhtCc/h8/pY0rXAXlSfuj8/StvLgMslfQ+w7fsl/Udgre1DRmjz+9r214Gv2l5Z/iOfPmIHpL2BoeR3ru1z26kHvJrqU+ZRVHO17Sbpn6kWHqrXE3Ch7aXDjvde4Drbx40UW8RocjsrpoIfA++VtHO5n//u2r5jASS9mWrm08dtH2F7ge1P2H4c+K2kt5T6HwNuArD9ANVtn7/h+SuMdcAMVWulIOnFkvYfIa6XA4+U7cUj1KGc6+ES04KREkireraX2p7tajbdRVQzRX+0xfFuAD4oac8S9x6q1gi/FThU0n8o5btK2m+0WKP3SXq/qoXjDgF+UD5YNZIrkeh5tn8maSXVzMG/pLrCeLzs/q2knwK7AX81wiEWA+dK2pVqCveP1/ZdBvw91VrU2H5K0geBs8utsB2oxiTWtjju6VRXMo9Q/bKeO5Z+SbqEaqGr6eU//Gm2vz2WYwyxfY+kLwM/VLWo1B+BU2zfKukE4BJJO5XqX6aaFTamANs3Us20XC+7ErhyPI6fWXxjSpD0Utu/K4ngZmCJ7Tu6HVfEVJcrkZgqlkuaTzUucGESSMTEyJVIREQ0loH1iIhoLEkkIiIaSxKJiIjGkkQiIqKxJJGIiGjs/wPxGjae0PisNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('gb-overall-1-4-eel')\n",
    "df_scaled['gb-overall-1-4-eel'].plot.hist(range=[0.9999, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC: not required. Done once above.\n",
    "# X = []\n",
    "# X_ids = []\n",
    "# # one_add = 0 if len(PDBs.keys()) % 2 == 0 else 1\n",
    "# for k in PDBs.keys():\n",
    "#     X_ids.append(k)\n",
    "#     X.append(featurizer.featurize(PDBs[k]))\n",
    "# split_index = int(len(X) * TRAIN_SET)\n",
    "# X = [x[0] for x in X]\n",
    "# X_train_featurized = X[:split_index]\n",
    "# X_test_featurized = X[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb_names = [i for i in X_ids]\n",
    "# pdb_names_train = pdb_names[:train_split_index]\n",
    "# pdb_names_test = pdb_names[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_add_train, x_add_test, y_train, y_test = [], [], [], []\n",
    "# for i in range(len(pdb_names_train)):\n",
    "#     new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "#     y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "#     x_add_train.append(-new_df[training_columns].to_numpy()[0])\n",
    "# y_train = np.array(y_train)\n",
    "    \n",
    "# for i in range(len(pdb_names_test)):\n",
    "#     new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "# #     print(pdb_names_test[i])\n",
    "# #     print(new_df['ddg'].to_numpy())\n",
    "#     y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "#     x_add_test.append(-new_df[training_columns].to_numpy()[0])\n",
    "# y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_add_train,x_add_val, x_add_test, y_train,y_val, y_test = [], [], [], [], [], []\n",
    "# Train\n",
    "for i in range(len(pdb_names_train)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "    y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_train.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Val\n",
    "for i in range(len(pdb_names_val)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_val[i])]\n",
    "    y_val.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_val.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "\n",
    "# Test\n",
    "for i in range(len(pdb_names_test)):\n",
    "    new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "#     print(pdb_names_test[i])\n",
    "#     print(new_df['ddg'].to_numpy())\n",
    "    y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "    x_add_test.append(-new_df[training_columns].to_numpy()[0])\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "x_preprocessed_train, x_preprocessed_test = [], []\n",
    "\n",
    "## for X train\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "## for X val\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "## for X test\n",
    "multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "    x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "x_preprocessed_test.append(np.array(x_add_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "x_train = np.full([14, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_train):\n",
    "    if len(j.shape) > 1:\n",
    "        x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "# Validation\n",
    "x_val = np.full([14, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_val):\n",
    "    if len(j.shape) > 1:\n",
    "        x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "# Testing\n",
    "\n",
    "x_test = np.full([14, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                  np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "for i,j in enumerate(x_preprocessed_test):\n",
    "    if len(j.shape) > 1:\n",
    "        x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "    else:\n",
    "        x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "x_test = x_test.reshape([1] + list(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ali's PGNN Model - 5 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "class PGNNAli(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def __init__(self, batch_size):\n",
    "    super(PGNNAli, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(64, activation=tf.nn.sigmoid)\n",
    "    self.dense3 = layers.Dense(1)\n",
    "    \n",
    "    ## Dense for overall\n",
    "    self.dense4 = layers.Dense(1, \n",
    "     kernel_initializer=initializers.Constant([.5, 1, 1, 1, 1, 1]),\n",
    "     bias_initializer=initializers.Zeros())\n",
    "#     self.dense4 = layers.Dense(1, \n",
    "#          kernel_initializer=initializers.Constant([.5, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1]),\n",
    "#          bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     x_feat, x_add = inputs[0], inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\n",
    "\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    model_var = self.dense3(model_var)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    ddg = self.dense4(binding_affinity)\n",
    "    tf.print(self.dense4.weights, output_stream=\"file://weights.txt\", summarize=30)\n",
    "    tf.print(binding_affinity[0], output_stream=\"file://binding_a.txt\", summarize=30)\n",
    "    tf.print(ddg[0], output_stream=\"file://ddg.txt\")\n",
    "    tf.print(model_var, output_stream=\"file://model_var.txt\", summarize=30)\n",
    "    tf.print(\"-------------------------\", output_stream=sys.stdout)\n",
    "    return ddg\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "ali_pgnn_model = PGNNAli(train_split_index)\n",
    "ali_pgnn_model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error)\n",
    "K.set_value(ali_pgnn_model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "# history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_13:0\", shape=(83387, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_16:0\", shape=(205678, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_19:0\", shape=(290367, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Reshape_22:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_11:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_10:0\", shape=(83387, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_13:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_12:0\", shape=(205678, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_15:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_14:0\", shape=(290367, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_16:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_conv_5/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_13:0\", shape=(83387, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_16:0\", shape=(205678, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_19:0\", shape=(290367, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Reshape_22:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/pgnn_ali/graph_pool_4/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "1/1 [==============================] - 15s 15s/step - loss: 45.3552\n",
      "-------------------------\n",
      "1/1 [==============================] - 3s 3s/step - loss: 44.6002\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 45.0083\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.5184\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 44.7851\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.4623\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 44.6294\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.4048\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 44.5190\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.3554\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 44.3759\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.3133\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 44.2596\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.2623\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 44.1427\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.2168\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 44.0397\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.1801\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 43.9457\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.1339\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.8407\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.0982\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.7369\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.0581\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.6431\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.0083\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.5471\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.9529\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.4565\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.9278\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.3583\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.8838\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.2635\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.8309\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.1823\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.7939\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.1097\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.7623\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.0126\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.7248\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 42.9377\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.6810\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.8459\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.6615\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.7588\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.6249\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.6852\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.5420\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 42.6261\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.5235\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.5284\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.4956\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.4583\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.4458\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.3719\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.3937\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 42.2818\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.3517\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.2005\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.3540\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.1431\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.3198\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.0566\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.2649\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.9700\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.2123\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.8969\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.1796\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.8094\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.1350\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.7185\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.1310\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.6459\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.0899\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.5554\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.0822\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.4918\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 43.0044\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.4300\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.9516\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.3406\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.9472\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 41.2440\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.9046\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 41.1762\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.9072\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.1205\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.8599\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.0379\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 42.8274\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.9832\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.7755\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 40.8999\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.7679\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40.8314\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.7681\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.7505\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.7587\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.6763\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.7224\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.5997\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.6816\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40.5256\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.6205\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.4671\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.5856\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.3951\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.5723\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.3527\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.4778\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40.2392\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.4926\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.1744\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.4070\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.0894\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.3419\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.0191\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.3970\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.9557\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.3999\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.8868\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.3037\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.8117\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.1458\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.7312\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.1879\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.6908\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.0800\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.6032\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.0364\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.5736\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.9884\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.4916\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.0430\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.4201\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.1041\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.3592\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.9979\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.2717\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.9108\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.1852\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.8877\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.1142\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.7946\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.0468\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.7516\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.9912\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.6280\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.9248\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.6011\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 38.8512\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.6559\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.7958\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.6860\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.7191\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.5863\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 38.6530\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.5945\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 38.5822\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.4911\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.5175\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.4180\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 38.4526\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.2657\n",
      "-------------------------\n",
      "1/1 [==============================] - 6s 6s/step - loss: 38.4001\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.2698\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 38.3359\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.2542\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.2625\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.2281\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.2079\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.1044\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.1288\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.9962\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 38.0731\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.9826\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.9944\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.9732\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 37.9270\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 41.0022\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.8639\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.9116\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 37.7996\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.8915\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.7246\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.8072\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.6824\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.8308\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.6193\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.7476\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 37.5801\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.5925\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.5303\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.5394\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.4343\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.5262\n",
      "-------------------------\n",
      "1/1 [==============================] - 4s 4s/step - loss: 37.3600\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.5220\n",
      "-------------------------\n",
      "1/1 [==============================] - 5s 5s/step - loss: 37.2806\n",
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.4770\n"
     ]
    }
   ],
   "source": [
    "ali_pgnn_losses, ali_pgnn_val_losses = [], []\n",
    "val_size = len(y_val)\n",
    "train_size = len(y_train)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    ali_pgnn_model.modify_graphgather(train_size)\n",
    "    ali_pgnn_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "    ali_loss = ali_pgnn_model.fit(x_train, -y_train.reshape([1, -1]), epochs=1)\n",
    "#     history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)\n",
    "#     metric = dc.metrics.Metric(dc.metrics.score_function.rms_score)\n",
    "    ali_pgnn_losses.append(ali_loss.history['loss'])\n",
    "    ali_pgnn_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "    ali_pgnn_model.modify_graphgather(val_size)\n",
    "    ali_pgnn_val_losses.append(ali_pgnn_model.evaluate(x_val, y_val.reshape([1, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6208926],\n",
       "        [1.1067361],\n",
       "        [0.8925526],\n",
       "        [0.9125809],\n",
       "        [1.1033266],\n",
       "        [1.0196115]], dtype=float32),\n",
       " array([0.1054638], dtype=float32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the wights after training\n",
    "ali_pgnn_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# f, ax = plt.subplots()\n",
    "plt.plot(range(len(ali_pgnn_losses)), ali_pgnn_losses, label='Ali PGNN train loss')\n",
    "plt.plot(range(len(ali_pgnn_val_losses)), ali_pgnn_val_losses, label='Ali PGNN val loss')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.ylim(0,500)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "plt.savefig('Ali_PGNN_loss_26Mar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.4770\n"
     ]
    }
   ],
   "source": [
    "ali_pgnn_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "ali_pgnn_model.modify_graphgather(len(y_test))\n",
    "ali_pgnn_test_loss= ali_pgnn_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "# test_pgnn_loss = dd_model.evaluate(x_test, y_test.reshape([1, -1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_pgnn_rmse_test = ali_pgnn_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.47704315185547"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_pgnn_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ali_pgnn_rmse_train = ali_pgnn_losses[-1]\n",
    "# ali_pgnn_train_loss = [sum(x)/len(x) for x in zip(*ali_pgnn_losses)]\n",
    "# ali_pgnn_rmse_train = math.sqrt(ali_pgnn_rmse_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.28062438964844]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_pgnn_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ali_pgnn_test_accuracy = ali_pgnn_rmse_test\n",
    "ali_pgnn_train_accuracy = ali_pgnn_rmse_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ali DataDriven Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "class GBGraphConvModelAli(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def __init__(self, batch_size):\n",
    "    super(GBGraphConvModelAli, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(64, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(64, activation=tf.nn.sigmoid)\n",
    "    self.dense3 = layers.Dense(1)\n",
    "    \n",
    "    ## Dense for overall\n",
    "    self.dense4 = layers.Dense(1) \n",
    "#      kernel_initializer=initializers.Constant([.5, 1, 1, 1, 1, 1]),\n",
    "#      bias_initializer=initializers.Zeros())\n",
    "#     self.dense4 = layers.Dense(1, \n",
    "#          kernel_initializer=initializers.Constant([.5, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1]),\n",
    "#          bias_initializer=initializers.Zeros(), activation=tf.keras.activations.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "#     x_feat, x_add = inputs[0], inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 5])\n",
    "\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    model_var = self.dense3(model_var)\n",
    "#     binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "#     ddg = self.dense4(binding_affinity)\n",
    "#     tf.print(self.dense4.weights, output_stream=\"file://weights.txt\", summarize=30)\n",
    "#     tf.print(binding_affinity[0], output_stream=\"file://binding_a.txt\", summarize=30)\n",
    "#     tf.print(ddg[0], output_stream=\"file://ddg.txt\")\n",
    "#     tf.print(model_var, output_stream=\"file://model_var.txt\", summarize=30)\n",
    "#     tf.print(\"-------------------------\", output_stream=sys.stdout)\n",
    "    return model_var\n",
    "\n",
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#         return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "ali_dd_model = GBGraphConvModelAli(train_split_index)\n",
    "ali_dd_model.compile(optimizer = \"rmsprop\", loss = 'mse')\n",
    "K.set_value(ali_dd_model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_13:0\", shape=(83387, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_16:0\", shape=(205678, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_19:0\", shape=(290367, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Reshape_22:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_11:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_10:0\", shape=(83387, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_13:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_12:0\", shape=(205678, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_15:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_14:0\", shape=(290367, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_17:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_16:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_conv_7/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_14:0\", shape=(83387,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_13:0\", shape=(83387, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_17:0\", shape=(205678,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_16:0\", shape=(205678, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_20:0\", shape=(290367,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_19:0\", shape=(290367, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/misspotato/opt/miniconda3/envs/rdkit-deepchem-jupyter/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_23:0\", shape=(188,), dtype=int32), values=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Reshape_22:0\", shape=(188, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/gb_graph_conv_model_ali/graph_pool_6/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 14s 14s/step - loss: 88.2922\n",
      "1/1 [==============================] - 2s 2s/step - loss: 80.5351\n",
      "1/1 [==============================] - 6s 6s/step - loss: 72.1653\n",
      "1/1 [==============================] - 1s 1s/step - loss: 75.8201\n",
      "1/1 [==============================] - 6s 6s/step - loss: 62.7900\n",
      "1/1 [==============================] - 1s 1s/step - loss: 72.0251\n",
      "1/1 [==============================] - 5s 5s/step - loss: 55.4467\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 68.9990\n",
      "1/1 [==============================] - 4s 4s/step - loss: 49.7468\n",
      "1/1 [==============================] - 1s 1s/step - loss: 67.1724\n",
      "1/1 [==============================] - 5s 5s/step - loss: 45.8839\n",
      "1/1 [==============================] - 1s 1s/step - loss: 65.3198\n",
      "1/1 [==============================] - 5s 5s/step - loss: 42.5207\n",
      "1/1 [==============================] - 1s 1s/step - loss: 63.5588\n",
      "1/1 [==============================] - 5s 5s/step - loss: 39.3738\n",
      "1/1 [==============================] - 1s 1s/step - loss: 63.9756\n",
      "1/1 [==============================] - 4s 4s/step - loss: 36.8663\n",
      "1/1 [==============================] - 1s 1s/step - loss: 62.4553\n",
      "1/1 [==============================] - 5s 5s/step - loss: 34.7042\n",
      "1/1 [==============================] - 1s 1s/step - loss: 58.9760\n",
      "1/1 [==============================] - 5s 5s/step - loss: 32.9727\n",
      "1/1 [==============================] - 1s 1s/step - loss: 58.1241\n",
      "1/1 [==============================] - 5s 5s/step - loss: 31.4132\n",
      "1/1 [==============================] - 1s 1s/step - loss: 56.9903\n",
      "1/1 [==============================] - 4s 4s/step - loss: 30.1213\n",
      "1/1 [==============================] - 1s 1s/step - loss: 54.9646\n",
      "1/1 [==============================] - 5s 5s/step - loss: 29.0414\n",
      "1/1 [==============================] - 1s 1s/step - loss: 53.8404\n",
      "1/1 [==============================] - 5s 5s/step - loss: 27.9056\n",
      "1/1 [==============================] - 1s 1s/step - loss: 51.9185\n",
      "1/1 [==============================] - 5s 5s/step - loss: 26.9712\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 50.5840\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.1559\n",
      "1/1 [==============================] - 1s 1s/step - loss: 49.9042\n",
      "1/1 [==============================] - 5s 5s/step - loss: 25.4723\n",
      "1/1 [==============================] - 1s 1s/step - loss: 48.7521\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.7220\n",
      "1/1 [==============================] - 1s 1s/step - loss: 47.7487\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.1295\n",
      "1/1 [==============================] - 1s 1s/step - loss: 45.6711\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23.5682\n",
      "1/1 [==============================] - 1s 1s/step - loss: 45.0027\n",
      "1/1 [==============================] - 5s 5s/step - loss: 23.0459\n",
      "1/1 [==============================] - 1s 1s/step - loss: 44.1066\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.5656\n",
      "1/1 [==============================] - 1s 1s/step - loss: 42.3719\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.1194\n",
      "1/1 [==============================] - 1s 1s/step - loss: 40.6381\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.6980\n",
      "1/1 [==============================] - 1s 1s/step - loss: 39.3053\n",
      "1/1 [==============================] - 5s 5s/step - loss: 21.2964\n",
      "1/1 [==============================] - 1s 1s/step - loss: 38.1602\n",
      "1/1 [==============================] - 6s 6s/step - loss: 20.9382\n",
      "1/1 [==============================] - 1s 1s/step - loss: 37.0998\n",
      "1/1 [==============================] - 5s 5s/step - loss: 20.5904\n",
      "1/1 [==============================] - 1s 1s/step - loss: 35.6968\n",
      "1/1 [==============================] - 6s 6s/step - loss: 20.2673\n",
      "1/1 [==============================] - 1798s 1798s/step - loss: 34.7801\n",
      "1/1 [==============================] - 8s 8s/step - loss: 19.9641\n",
      "1/1 [==============================] - 5s 5s/step - loss: 34.0916\n",
      "1/1 [==============================] - 18s 18s/step - loss: 19.6495\n",
      "1/1 [==============================] - 5s 5s/step - loss: 33.3278\n",
      "1/1 [==============================] - 12s 12s/step - loss: 19.3466\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33.1074\n",
      "1/1 [==============================] - 18s 18s/step - loss: 19.0601\n",
      "1/1 [==============================] - 4s 4s/step - loss: 32.7782\n",
      "1/1 [==============================] - 18s 18s/step - loss: 18.7791\n",
      "1/1 [==============================] - 5s 5s/step - loss: 31.6330\n",
      "1/1 [==============================] - 20s 20s/step - loss: 18.5308\n",
      "1/1 [==============================] - 5s 5s/step - loss: 31.1776\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.2512\n",
      "1/1 [==============================] - 1s 1s/step - loss: 30.6503\n",
      "1/1 [==============================] - 13s 13s/step - loss: 17.9891\n",
      "1/1 [==============================] - 4s 4s/step - loss: 29.7478\n",
      "1/1 [==============================] - 1236s 1236s/step - loss: 17.7516\n",
      "1/1 [==============================] - 2s 2s/step - loss: 28.9806\n",
      "1/1 [==============================] - 10s 10s/step - loss: 17.5060\n",
      "1/1 [==============================] - 5s 5s/step - loss: 29.0936\n",
      "1/1 [==============================] - 12s 12s/step - loss: 17.2716\n",
      "1/1 [==============================] - 7199s 7199s/step - loss: 28.7456\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.0413\n",
      "1/1 [==============================] - 6s 6s/step - loss: 28.3206\n",
      "1/1 [==============================] - 20s 20s/step - loss: 16.8166\n",
      "1/1 [==============================] - 5s 5s/step - loss: 27.2567\n",
      "1/1 [==============================] - 17s 17s/step - loss: 16.5924\n",
      "1/1 [==============================] - 5s 5s/step - loss: 27.4710\n",
      "1/1 [==============================] - 13s 13s/step - loss: 16.3784\n",
      "1/1 [==============================] - 3s 3s/step - loss: 26.8112\n",
      "1/1 [==============================] - 7209s 7209s/step - loss: 16.1677\n",
      "1/1 [==============================] - 7s 7s/step - loss: 26.0269\n",
      "1/1 [==============================] - 20s 20s/step - loss: 15.9587\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.9447\n",
      "1/1 [==============================] - 7205s 7205s/step - loss: 15.7520\n",
      "1/1 [==============================] - 2s 2s/step - loss: 24.8213\n",
      "1/1 [==============================] - 15s 15s/step - loss: 15.5532\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.5437\n",
      "1/1 [==============================] - 17s 17s/step - loss: 15.3566\n",
      "1/1 [==============================] - 5s 5s/step - loss: 23.8368\n",
      "1/1 [==============================] - 20s 20s/step - loss: 15.1610\n",
      "1/1 [==============================] - 5s 5s/step - loss: 23.6799\n",
      "1/1 [==============================] - 15s 15s/step - loss: 14.9680\n",
      "1/1 [==============================] - 5s 5s/step - loss: 23.1753\n",
      "1/1 [==============================] - 12s 12s/step - loss: 14.7783\n",
      "1/1 [==============================] - 2290s 2290s/step - loss: 22.3094\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.5901\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.9743\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.4150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 21.6569\n",
      "1/1 [==============================] - -1s -937302us/step - loss: 14.2437\n",
      "1/1 [==============================] - 2s 2s/step - loss: 21.4252\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.0702\n",
      "1/1 [==============================] - 1s 1s/step - loss: 21.0548\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.9035\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20.6931\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.7356\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20.3113\n",
      "1/1 [==============================] - 7s 7s/step - loss: 13.5764\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20.3589\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.4160\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20.0079\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.2589\n",
      "1/1 [==============================] - 1s 1s/step - loss: 19.6740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 13.1071\n",
      "1/1 [==============================] - 1s 1s/step - loss: 19.3538\n",
      "1/1 [==============================] - 6s 6s/step - loss: 12.9600\n",
      "1/1 [==============================] - 1s 1s/step - loss: 19.0710\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.8143\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.8674\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.6709\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.4883\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.5324\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.1617\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.3932\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.8316\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.2559\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.5311\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.1220\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.3769\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.9884\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.0670\n",
      "1/1 [==============================] - 6s 6s/step - loss: 11.8565\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16.7750\n",
      "1/1 [==============================] - 4s 4s/step - loss: 11.7248\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16.3285\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.5940\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16.3592\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.4646\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16.1543\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.3357\n",
      "1/1 [==============================] - 1s 1s/step - loss: 15.4845\n",
      "1/1 [==============================] - 4s 4s/step - loss: 11.2108\n",
      "1/1 [==============================] - 1s 1s/step - loss: 15.0921\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.0905\n",
      "1/1 [==============================] - 1s 1s/step - loss: 14.7713\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.9718\n",
      "1/1 [==============================] - 1s 1s/step - loss: 14.7348\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.8566\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 14.2763\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.7459\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.6976\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.6387\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.5766\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.5323\n",
      "1/1 [==============================] - 1s 1s/step - loss: 13.3429\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.4302\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 13.0292\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.3306\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.7230\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.2337\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.4619\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.1394\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.3618\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.0476\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.1375\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.9583\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.9756\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.8710\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.8354\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.7859\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.6973\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.7030\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.5888\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.6223\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.4040\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.5437\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.2859\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.4672\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.1652\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.3928\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.0515\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.3204\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.9461\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.2501\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.8314\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.1818\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.7412\n",
      "1/1 [==============================] - 4s 4s/step - loss: 9.1154\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.6381\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.0510\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.5396\n"
     ]
    }
   ],
   "source": [
    "ali_dd_losses, ali_dd_val_losses = [], []\n",
    "val_size = len(y_val)\n",
    "train_size = len(y_train)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    ali_dd_model.modify_graphgather(train_size)\n",
    "    ali_dd_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "    ali_dd_loss = ali_dd_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "#     history = model.fit(x_train, -y_train.reshape([1, -1]), epochs=3)\n",
    "#     metric = dc.metrics.Metric(dc.metrics.score_function.rms_score)\n",
    "    ali_dd_losses.append(ali_dd_loss.history['loss'])\n",
    "    ali_dd_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "    ali_dd_model.modify_graphgather(val_size)\n",
    "    ali_dd_val_losses.append(ali_dd_model.evaluate(x_val, y_val.reshape([1, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9g0lEQVR4nO3dd3xV9f348dc7e0+yGCGAgDIDBERREPdErAOsA1qr31ZbtX5rxfZXa2sH9Wtba6ttXZVWxT1w1G0E3CwZgswAgZiE7D3fvz/OBQKG5Cbk3pvc+34+Hudxzj33jPdhvD/nfs7nfD6iqhhjjAkcQb4OwBhjjHdZ4jfGmABjid8YYwKMJX5jjAkwlviNMSbAhPg6AHf069dPs7KyfB2GMcb0KStXrtynqimHr+8TiT8rK4sVK1b4OgxjjOlTRGRne+utqscYYwKMRxO/iNwkIutFZIOI3OxalyQib4vIFtc80ZMxGGOMOZTHEr+IjAGuBaYA44HzRWQ4sAB4V1WHA++6PhtjjPEST9bxHwd8oqq1ACLyAXARcCFwimubRUAucJsH4zDG45qamsjPz6e+vt7XoZgAFBERwcCBAwkNDXVre08m/vXAb0UkGagDzgVWAGmqWgCgqgUiktreziJyHXAdQGZmpgfDNObo5efnExsbS1ZWFiLi63BMAFFVSkpKyM/PZ8iQIW7t47GqHlXdCPwBeBt4A/gCaO7C/g+qao6q5qSkfKM1kjG9Sn19PcnJyZb0jdeJCMnJyV36tenRh7uq+oiqTlTV6UApsAUoFJEMANe8yJMxGOMtlvSNr3T1356nW/WkuuaZwLeAxcASYJ5rk3nAy546/3ubCnkgd6unDm+MMX2Sp9vxPy8iXwKvADeoahmwEDhDRLYAZ7g+e8TSzfv4+/vbPHV4Y3qdF198ERFh06ZNB9bl5eUxZswYAFasWMGNN974jf1yc3OJj49nwoQJjBw5kunTp/Pqq692er7c3Fw++uijLsXY1XMtWbKEhQs9liYoLy/ngQce6Na+5557LuXl5W5vf+edd3LPPfd061w9yaNv7qrqye2sKwFO8+R590uMCqOqoZmmllZCg+1dNeP/Fi9ezEknncRTTz3FnXfe+Y3vc3JyyMnJaXffk08++UACXrNmDbNnzyYyMpLTTjvyf9fc3FxiYmI48cQTuxSnu+dqbm5m1qxZzJo1q0vH74r9if/666//xnctLS0EBwcfcd/XX3/dY3F5kl9nw6Rop2lTWW2jjyMxxvOqq6v58MMPeeSRR3jqqafa3SY3N5fzzz+/02NlZ2dzxx138Le//Q2AV155heOPP54JEyZw+umnU1hYSF5eHv/4xz/485//THZ2NsuWLWt3u66ea/78+dxyyy3MnDmT2267jccee4wf/vCHVFRUkJWVRWtrKwC1tbUMGjSIpqYmtm3bxtlnn82kSZM4+eSTD/zimT9/PjfeeCMnnngiQ4cO5bnnnvvG+RcsWMC2bdvIzs7m1ltvJTc3l5kzZ/Ltb3+bsWPHAjB79mwmTZrE6NGjefDBBw/sm5WVxb59+8jLy+O4447j2muvZfTo0Zx55pnU1dV1eN1r1qxh6tSpjBs3josuuoiysjIA7rvvPkaNGsW4ceOYO3cuAB988AHZ2dlkZ2czYcIEqqqqOv1z7Uif6KunuxKiwgAor20iNTbCx9GYQPGrVzbw5d7KHj3mqP5x/PKC0R1u89JLL3H22WczYsQIkpKSWLVqFRMnTuz2OSdOnMj//d//AXDSSSfxySefICI8/PDD3H333fzxj3/k+9//PjExMfzkJz8BoKysrN3tunIugM2bN/POO+8QHBzMY489BkB8fDzjx4/ngw8+YObMmbzyyiucddZZhIaGct111/GPf/yD4cOH8+mnn3L99dfz3nvvAVBQUMDy5cvZtGkTs2bN4pJLLjnk3AsXLmT9+vWsWbMGcArHzz77jPXr1x9oHvnoo4+SlJREXV0dkydP5uKLLyY5OfmQ42zZsoXFixfz0EMPcdlll/H8889z5ZVXHvGar776av76178yY8YM7rjjDn71q19x7733snDhQnbs2EF4ePiBaqR77rmH+++/n2nTplFdXU1ExNHlM79O/EnRTuIvrbE7fuP/Fi9ezM033wzA3LlzWbx48VEl/rbjcefn5zNnzhwKCgpobGw8Yntxd7fr6FwAl156abtVLHPmzOHpp59m5syZPPXUU1x//fVUV1fz0Ucfcemllx7YrqGh4cDy7NmzCQoKYtSoUW79AgGYMmXKIbHfd999vPjiiwDs3r2bLVu2fCPxDxkyhOzsbAAmTZpEXl7eEY9fUVFBeXk5M2bMAGDevHkH4h83bhxXXHEFs2fPZvbs2QBMmzaNW265hSuuuIJvfetbDBw40K3rOBK/TvyJB+74LfEb7+nsztwTSkpKeO+991i/fj0iQktLCyLC3Xff3e1jrl69muOOOw6AH/3oR9xyyy3MmjWL3Nzcdp8fdGW7js4FEB0d3e52s2bN4vbbb6e0tJSVK1dy6qmnUlNTQ0JCwoE79sOFh4cfWD68gDmStufPzc3lnXfe4eOPPyYqKopTTjml3Tbzbc8THBzcaVXPkbz22mssXbqUJUuWcNddd7FhwwYWLFjAeeedx+uvv87UqVN55513OPbYY7t1fPDzOv5EVx1/aU2TjyMxxrOee+45rr76anbu3EleXh67d+9myJAhLF++vFvHW7t2LXfddRc33HAD4NyhDhgwAIBFixYd2C42NvaQ+uYjbdeVc3UkJiaGKVOmcNNNN3H++ecTHBxMXFwcQ4YM4dlnnwWc5P7FF1+4d6HtXMPhKioqSExMJCoqik2bNvHJJ5+4fewjiY+PJzExkWXLlgHwn//8hxkzZtDa2sru3buZOXMmd999N+Xl5VRXV7Nt2zbGjh3LbbfdRk5OziGttrrDvxO/647fHu4af7d48WIuuuiiQ9ZdfPHFPPnkk24fY9myZQeaWN5www3cd999B1rZ3HnnnVx66aWcfPLJ9OvX78A+F1xwAS+++OKBh7tH2q4r5+rMnDlzePzxx5kzZ86BdU888QSPPPII48ePZ/To0bz8svuvByUnJzNt2jTGjBnDrbfe+o3vzz77bJqbmxk3bhy/+MUvmDp1qtvH7siiRYu49dZbGTduHGvWrOGOO+6gpaWFK6+8krFjxzJhwgR+/OMfk5CQwL333suYMWMYP348kZGRnHPOOUd1bnH3p48v5eTkaHcHYjnuF29wxfGZ/L/zR/VwVMYctHHjxkOqKozxtvb+DYrISlX9Rvtdv77jB+cBb6nd8RtjzAF+n/gTokIpr7U6fmOM2c/vE39SdJg15zTGmDb8PvEnRoVZc05jjGkjABJ/qN3xG2NMG/6f+KPDqKxvprml1dehGGNMr+D/iX//27t19oDX+D/rltk7YmJiurS+t/HrLhvAueMHp9uGfjHhnWxtTN9m3TIbdwTAHb9122ACg3XL3L1umW+77bZDBmK58847+eMf/0h1dTWnnXYaEydOZOzYsV16G1hVufXWWxkzZgxjx47l6aefBpyeQqdPn052djZjxoxh2bJltLS0MH/+/APb/vnPf3b7PN3l0Tt+Efkx8D1AgXXAd4Ao4GkgC8gDLnONzNXzGmtJr98OWA+dxov+uwC+Xtezx0wfC+d0XN1h3TJ3r1vmuXPncvPNNx8YiOWZZ57hjTfeICIighdffJG4uDj27dvH1KlTmTVrllvj277wwgusWbOGL774gn379jF58mSmT5/Ok08+yVlnncXPf/5zWlpaqK2tZc2aNezZs4f169cDdGlEr+7yWOIXkQHAjcAoVa0TkWeAucAo4F1VXSgiC4AFwG0eCeK1Wxi6+S2Ev1iTTuP3rFvm7nXLPGHCBIqKiti7dy/FxcUkJiaSmZlJU1MTP/vZz1i6dClBQUHs2bOHwsJC0tPTO72e5cuXc/nllxMcHExaWhozZszg888/Z/LkyXz3u9+lqamJ2bNnk52dzdChQ9m+fTs/+tGPOO+88zjzzDPd+jM7Gp6u4w8BIkWkCedOfy9wO3CK6/tFQC6eSvxZJxP8xWJGSj6ltdaPivGSTu7MPcG6ZT66bpkvueQSnnvuOb7++usDo1498cQTFBcXs3LlSkJDQ8nKymq3O+b2HOk806dPZ+nSpbz22mtcddVV3HrrrVx99dV88cUXvPnmm9x///0888wzPProo26dp7s8VsevqnuAe4BdQAFQoapvAWmqWuDapgBIbW9/EblORFaIyIri4uLuBTHUGeRgRugG67bB+DXrlrn73TKD8wvpqaee4rnnnjtQFVRRUUFqaiqhoaG8//777Ny50+3jTZ8+naeffpqWlhaKi4tZunQpU6ZMYefOnaSmpnLttddyzTXXsGrVKvbt20draysXX3wxd911F6tWrepS7N3hscQvIonAhcAQoD8QLSJHHofsMKr6oKrmqGpOSkpK94KIHwhJw5ge8qXV8Ru/Zt0yd79bZoDRo0dTVVXFgAEDyMjIAOCKK65gxYoV5OTk8MQTT3Rp4JOLLrqIcePGMX78eE499VTuvvtu0tPTyc3NPTBu7vPPP89NN93Enj17OOWUU8jOzmb+/Pn8/ve/71Ls3eGxbplF5FLgbFW9xvX5amAqcBpwiqoWiEgGkKuqIzs61tF0y8yrP6Z2xWJ+nPUi/5x/QveOYUwnrFtm42u9pVvmXcBUEYkS5zH4acBGYAkwz7XNPKBrRXNXDZlBFHUkVmzw6GmMMaav8NjDXVX9VESeA1YBzcBq4EEgBnhGRK7BKRwuPfJResCQ6bQijKjxfL2ZMcb0BR5t1aOqvwR+edjqBpy7f++ISuLryOGMrVvjtVOawKSqbrXxNqandbXK3u/f3AXYmziFcfoVLQ01vg7F+KmIiAhKSkq6/B/QmKOlqpSUlBAREeH2Pn7fVw9AWdoJhO99nMqtHxI32vMvR5jAM3DgQPLz8+l202NjjkJERAQDBw50e/uASPwNA46ncVUwLVtzwRK/8YDQ0FC331I1xtcCoqonLi6B1TqcsF3LfB2KMcb4XEAk/sSoMJa3jCGqZB1UF/k6HGOM8anASPzRobzVmoOgsKnzwSWMMcafBUbijwrjKx1EeWQmfLnE1+EYY4xPBUTijwoLJiwkmC8TToG8ZVBb6uuQjDHGZwIi8YsIiVGhrIg6CVqb4av/+jokY4zxmYBI/OBU96xtGQrxmfClZ7sHMsaY3ixgEn9SdBjldU1w3AWw/X2or/R1SMYY4xMBk/gTo8IorW2EUbOgpRE2v+nrkIwxxicCJ/FHhzqjcA2cAjHpsNGqe4wxgSlgEn9SdDhltY00KU51z5Z3oKGq0/2MMcbfBEziH5gQiSoUlNfDuDnQXAfrnvV1WMYY43UBk/gHJUUBsKu0FgbmQNpY+PxRsG50jTEBxpODrY8UkTVtpkoRuVlEkkTkbRHZ4poneiqGtjKTncS/u6wWRCDnO1C4Dvas9MbpjTGm1/BY4lfVr1Q1W1WzgUlALfAisAB4V1WHA++6PntcelwEocHi3PEDjLsMwmJgxaPeOL0xxvQa3qrqOQ3Ypqo7gQuBRa71i4DZ3gggOEgYkBDJ7v2JPzzWSf7rn7cuHIwxAcVbiX8usNi1nKaqBQCueWp7O4jIdSKyQkRW9NSoRoOSog4mfoCc70JzPXzxVI8c3xhj+gKPJ34RCQNmAV1qQqOqD6pqjqrmpKSk9Egsg5KiDlb1AKSPhYGTneoee8hrjAkQ3rjjPwdYpaqFrs+FIpIB4Jp7bWSUzKQoymqbqKpvOrhy8rVQsgVWP+6tMIwxxqe8kfgv52A1D8ASYJ5reR7gtVdoByW6WvaU1h1cOfZSGHwSvPkzKN/trVCMMcZnPJr4RSQKOAN4oc3qhcAZIrLF9d1CT8bQVmbbtvz7BQXBhX+D1hZY8iOr8jHG+D2PJn5VrVXVZFWtaLOuRFVPU9XhrrnXmtTsT/z5ZbWHfpE0BM68y+m105p3GmP8XMC8uQsQHxVKbETIoXf8++V8F4aeAm/9Akp3eD02Y4zxloBK/ODc9beb+EVg1t9Agpwqn9ZW7wdnjDFeEJCJf3d7iR8gYRCc9VtnXN6VVuVjjPFPAZf4ByVFsbusjtbWIzzEnXg1DJ0Jb90BZTu9G5wxxnhBQCb+xuZWiqoa2t9ABGb91VXl80Or8jHG+J2AS/z7W/bsPrxlT1sJg+Cs38COpfD5w16KzBhjvCPgEv+gxEgAdpV0kPgBJs6DY86At38BxV95ITJjjPGOgEv8AxIjEaH9lj1ticCF90NYNLxwLTQ3eidAY4zxsIBL/OEhwaTHRXRc1bNfbBpccB8UfAEfLIR9WyD3D/Dw6bDxVc8Ha4wxHhDi6wB84RvdM3fkuPNhwpWw7I/OhEBUkvMr4Jq3nB4+jTGmDwnIxJ+ZFMWyLV3o4//shRAUAinHwqgLnRY/D86Exd+G63IhOtljsRpjTE8LuKoecHrpLKxsoL6pxb0dwmPhgr/A1B9AXH+ITYe5j0N1ITw7D1qaOj+GMcb0Ep0mfhEZKCI/EZGXReRzEVkqIg+IyHki0icLjqEp0QBsL67p/kEGTHIKg7xl8PHfeigyY4zxvA4Tt4j8C3gUaAT+gNO3/vXAO8DZwHIRme7pIHvaiLRYALYUVR3dgbIvh8HTYPUT1p2zMabP6KyO/4+qur6d9euBF1zDKmb2fFieNaRfNCFBwubCo0z84Azk8urNTsuf/tlHfzxjjPGwDu/4j5D0237fqKpbezYkzwsLCSKrXzSbC6uP/mCjLoSgUFjXpSGFjTHGZzq84xeRdUB7dRgCqKqO62T/BOBhYIzrON8FvgKeBrKAPOAyVS3rYtxHbURaDF/urTz6A0UlwfAzYN1zcMavISj46I9pjDEe1FlVz/lHefy/AG+o6iWuaqEo4GfAu6q6UEQWAAuA247yPF02PDWW/67/mvqmFiJCjzJZj70UvnrdedA79JQeic8YYzyls6qenfsnoB4Y65rqXOuOSETigOnAI65jNapqOXAhsMi12SJg9tFcQHeNSItFFbYW9UB1z8hzICwG1lp1jzGm93OrOaaIXAZ8BlwKXAZ8KiKXdLLbUKAY+JeIrBaRh0UkGkhT1QIA1zz1COe8TkRWiMiK4uIuvGzlphFpMUAPtOwBCI2E4y6AjUugqf7oj2eMMR7kbjv8nwOTVXWeql4NTAF+0ck+IcBE4O+qOgGowanWcYuqPqiqOaqak5KS4u5ubsvqF01osPTMA15wqnsaKmHzf3vmeMYY4yHuJv4gVS1q87nEjX3zgXxV/dT1+TmcgqBQRDIAXPOiI+zvUaHBQQzpF82WnmjSCTBkBsRnwks3wMrHrF2/MabXcjfxvyEib4rIfBGZD7wGdHhrq6pfA7tFZKRr1WnAl8ASYJ5r3Tzg5S5H3UOGp8X23B1/cAh853UYMBFeuQkWz4Vqn5RpxhjTIbcSv6reCjwIjAPGAw+q6k/d2PVHwBMishbIBn4HLATOEJEtwBmuzz4xIjWW3WW11DW62WdPZxIGwdVL4Kzfw7b34aHToGRbzxzbGGN6iNu9c6rq8yLy9v59RCRJVUs72WcNkNPOV6d1JUhPGZEWc6Blz9iB8T1z0KAgOOF6GHwCPH4JPHImXPm8vdVrjOk13G3V8z8iUgisBVYAK13zPm24q8+eHum64XD9J8B333Ra/Dx2PuQt7/lzGGNMN7hbx/8TYLSqZqnqUFUdoqpDPRmYN2QlRxEWHMTmnmjS2Z5+xziDtcRlwLPzoa7cM+cxxpgucDfxbwPcHLKq7wgJDmJoSjRbeuoBb3vi+sO3HoLaEnjvN547jzHGuMndOv7bgY9E5FOgYf9KVb3RI1F50fC0WFbv8nBXQf2zYfK18PlDMOEKpxrIGGN8xN07/n8C7wGf4NTv75/6vBGpMeSX1VHT0OzZE536c4jqB6/eAq091IrIGGO6wd07/mZVvcWjkfjIsRlxAGwsqCQnK8lzJ4qIh7N+6wzSvvIxmHyN585ljDEdcPeO/31X3zkZIpK0f/JoZF4yfpDTjHPN7nLPn2zspTBkOryxADa86PnzGWNMO9y94/+2a357m3WK0xFbn5YaG8GAhEhWeyPxi8Bl/4Yn58Kz33Ee+E7+nufPa4wxbXQ2EEuGqhao6hBvBeQL2ZkJrNlV7p2TRSbCVS/Cc9+F1/7XaeI5/SfeObcxxtB5Vc+jIvKJiCwUkVNExO03ffuSCYMS2FNeR1GVl7pUDouCOY/D2Mvgvbtg58feOa8xxtD5QCznAKcAucBFwCci8oKrvr/PDbJ+JBMyEwC8d9cPTqduF9wLCZnwyo3Wj78xxms6fbirqvWq+oaq3qSqOcD/4lQR/U1EPvN4hF4wun88IUHinQe8bYVFw/l/hn2bYdkfvXtuY0zAcrdVzwGqukNVH1DVWcBJHojJ6yJCgxnVP47V3rzj3++Y02HcXFj+Jyjc4P3zG2MCToeJX0SqRKSyzVTVdq6qjd4K1NOyByWwNr+cllYfDKBy1u+cdv4v3wBNdd4/vzEmoHRWxx+rqnFtpti2c28F6Q3ZgxKoaWzpmTF4uyo6GS74C+xd4zTzbGnyfgzGmIDRpaoeEUkVkcz9k6eC8oUJmYmAlx/wtnXcBXDePc6YvS//EFpbfROHMcbvudsf/yzXiFk7gA+APDoZetG1X56IrBORNSKywrUuSUTeFpEtrnniUcTfY7KSo0iICvX+A962Jn8PZv4/WPsUvHEbNPtNTZoxphdx947/LmAqsNn1MtdpwIdu7jtTVbNdLYIAFgDvqupw4F3XZ58TEcYPTPDNA962pv8Ept4Anz0I90+BDS/ZwO3GmB7lbuJvUtUSIEhEglT1fZwxdLvjQmCRa3kRMLubx+lxEzIT2FxURbWne+rsiIjTmdsVz0FIBDw7Dx49G6q+9l1Mxhi/4m7iLxeRGGApzuDpfwHcyY4KvCUiK0XkOte6NFUtAHDNU9vb0fWS2AoRWVFcXOxmmEdnYmYiqvD5jg6HEvY8ERh+Bnx/OVxwH3y9zkn+ZXm+jcsY4xfcTfwX4ozA9WPgDZwRuS5wY79pqjoROAe4QUSmuxuYqj6oqjmqmpOSkuLubkdlypAkYsJDeHNDL7m7Dg6BSfPg6pehrsxJ/kWbfB2VMaaPczfxpwJhqtqsqouAh4DYznZS1b2ueRHwIjAFKBSRDHA6gQOKuhO4J0SEBjPz2FTe/rLQN+35j2TQZPjO66Ct8K+zIc/dxyvGGPNN7ib+Z4G27QtbXOuOSESiRSR2/zJwJrAeWALMc202D3i5KwF72lmj0yipaWRFno+rew6XNhq++wZEJcO/Z8Hnj/g6ImNMH+Vu4g9p+5auazmsk33SgOUi8gXwGfCaqr4BLATOcDUPPcP1udc4ZWQqYSFBvNFbqnvaShoK33sXhp0Kr90Cr9wMLT58EG2M6ZPcTfzFIjJr/wcRuRDY19EOqrpdVce7ptGq+lvX+hJVPU1Vh7vmverWOiY8hOnD+/HWhkK0NzajjEyAy5+CaTfDyn/Bp3/3dUTGmD7G3cT/feBnIrJLRHYBtwHXdbJPn3XW6HT2lNexfk+lr0NpX1AwnPErGH4W5P7BmnoaY7qks07a4gFUdZuqTgVGAaNV9UTAL8bcbc/px6URHCS8saHA16F07OzfQ0sDvP1LX0dijOlDOrvjf7dtlwqqWq2qVSJyBvCCZ0PzncToMI4fksSbGwp9HUrHkofBiT9yuniwUbyMMW7qLPH/E3hfRA40pBeRbwMPAud5MjBfO3tMOluLqtnqi946u+Lk/4W4AfD6rdDa4utojDF9QGfdMj8E/BF4T0QyRORm4A6c/nfWeiE+nzlrdDpBAkvW7PV1KB0Li3a6eChcBw+fDjuW+ToiY0wv587Qi/8Bfg2sBr6N8zZunofj8rm0uAimHdOPF1bvobU3vczVnlGz4aJ/QnUhLDofnrgUSrf7OipjTC/V2cPddSKyFucuPwpIxqn62b/er108cSD5ZXV83tte5jqcCIyfCz9aCWf8GnZ9Cv84GdY+4+vIjDG9UEgn35/vlSh6qTNHpxEdFswLq/Zw/NBkX4fTudBImHYTjP4WvHCtM217D869B8JjfB2dMaaX6KyqZ5eq7jzSBCAi4oU4fSIqLISzx2Tw+roC6pv60IPThEEw71WYsQDWPg0v/cD69DfGHNBZ4n9fRH50+DCLIhImIqeKyCIO9rvjly6eOICqhmbe/rKXN+08XHAIzLwdTvslbFwCa57wdUTGmF6is8R/Nk6HbItFZK+IfCki24EtwOXAn1X1MQ/H6FNThybTPz6CF1bl+zqU7jnxRsg6GV7/KZRs83U0xpheoLPmnPWq+oCqTgMG4wy5OFFVB6vqtaq6xhtB+lJQkDB7wgCWbtlHUVW9r8PpuqAguOgfEBzq1Pm3NPk6ImOMj7nbVw+q2qSqBapa7sF4eqVvTRxAS6vy0uo9vg6le+IHwgX3wp6VkNurOkM1xviA24k/kB2TGsvEzASe/nx37+yx0x2jL4LsK2H5n2DnR76OxhjjQ5b43TR3SibbimtYubPM16F03zkLIWEwvHAd1JX7OhpjjI+4lfhdo2kFuZZHiMgsEQn1bGi9y3ljM4gJD2HxZ7t9HUr3hcfCxQ9D5V54/Se+jsYY4yPu3vEvBSJEZADwLvAd4DF3dhSRYBFZLSKvuj4nicjbIrLFNU/s7Bi9QXR4CBeM789r6/ZSWd+HH5AOzIFTbod1z8KaJ30djTHGB9xN/KKqtcC3gL+q6kU4ffO74yZgY5vPC4B3VXU4TiGywN1gfW3u5EHUN7X2/o7bOnPyLU4TzyU3wtZ3fB2NMcbL3E78InICcAXwmmtdZ909ICIDcbpvfrjN6guBRa7lRcBsN2PwuXED4zk2PZanP+/D1T3gjOA153FIORaevgp2f+briIwxXuRu4r8ZuB14UVU3iMhQ4H039rsX+CnQ2mZdmqoWALjmqe3tKCLXicgKEVlRXFzsZpieJSLMnTyIdXsqWL+nwtfhHJ3IBLjqBYhNd3rzLNzg64iMMV7iVuJX1Q9UdZaq/sH1kHefqt7Y0T4icj5QpKoruxOYqj6oqjmqmpOSktL5Dl5y0YSBRIYG8+jyHb4O5ejFpMJVLzqduy26APau9nVExhgvcLdVz5MiEici0cCXwFcicmsnu00DZolIHvAUcKqIPA4UikiG67gZQFG3o/eB+KhQrpyayUtr9pC3r8bX4Ry9xCyY/xqERsNjF9hALsYEAHerekapaiVOffzrQCZwVUc7qOrtqjpQVbOAucB7qnolsISDHbvNA17uRtw+de30oYQGB3H/+1t9HUrPSB4G17wJ8QPg8Yth0+u+jsgY40HuJv5QV7v92cDLqtoEdPcV1oXAGSKyBTjD9blPSY2N4NvHZ/LC6j3sLq31dTg9I64/fOe/kD4Gnr4CPn3Q1xEZYzzE3cT/TyAPiAaWishgoNLdk6hqrqqe71ouUdXTVHW4a97Lh7dq3/dnDCM4SHgg10/u+gGikmDeKzDiHPjvrfDG7TaAuzF+yN2Hu/ep6gBVPVcdO4GZHo6tV0uLi2Du5EE8tzKfPeV1vg6n54RFw5z/wNQb4JMH4Nn50NLs66iMMT3I3Ye78SLyp/3NK0Xkjzh3/wHt+zOGAfCXdzb7OJIeFhQMZ/8OzvytM4jLf39qI3gZ40fcrep5FKgCLnNNlcC/PBVUX9E/IZL5J2bx7Mr8vt+uvz0n/tAZw3fFI/Dhvb6OxhjTQ9xN/MNU9Zequt01/QoY6snA+oofnjqcxKgw7nr1y77bZXNHTrsTxlwM79wJa5/xdTTGmB7gbuKvE5GT9n8QkWmAH1Vsd198ZCi3nDGCT3eU8uaGPjYurzuCgmD232HwSU53zu//zh74GtPHuZv4vw/cLyJ5rhey/gb8j8ei6mPmTh7EyLRYfvf6Rhqa/TAphoTDFc9A9rfhgz/AollO187GmD7J3VY9X6jqeGAcME5VJwCnejSyPiQkOIj/d/5x7Cqt5eFlftCVQ3vComH2AzD7H7B3FTxwAnzyd2hu9HVkxpgu6tIIXKpa6XqDF+AWD8TTZ508PIVzx6Zz7zub/fNB737Zl8N1H0D/bHhjATwwFTa+aq1+jOlDjmboRemxKPzEb2ePJTk6nJueWk1dox9W+eyXMgKuegm+/SwEhThv+j55GZTt9HVkxhg3HE3it1u8wyRGh/Gny8azfV8Nv3ntS1+H41kiMOJM+MFHcNbvIO9DuP94+OBuyF8JjX7QgZ0xfko6aoIoIlW0n+AFiFTVTgdj6Qk5OTm6YsUKb5yqR/z+9Y38c+l2HrxqEmeOTvd1ON5RkQ//vQ02vepaIU7nb4OnwbCZMGSG0yWEMcZrRGSlquZ8Y31faHve1xJ/Y3Mr3/r7h+wqqWXJD08iq18AveRclgdfr3cGdilYA3nLoaESJBjO+QNMudbXERoTMCzxe9nu0lou+Nty0uMieOH6E4kK88qPo96npdkZ4GXZPbD5DZj5/2D6T5yqImOMRx0p8R9NHb/pwKCkKO6bO4GvCqu47fl1/vlWrzuCQ2DQZJjzBIy/HN7/Dbz5c2ht7XxfY4xHWOL3oOkjUvjJmSN55Yu9PLRsu6/D8a3gELjwATj++/DJ/XDvGHjnV1DsZx3cGdMHeCzxi0iEiHwmIl+IyAYR+ZVrfZKIvC0iW1zzRE/F0Btcf8owzhubwe9e38Qzn+/2dTi+FRQEZy+Ey/4NaaOdjt/unwz/Ohe+fNm6fzbGSzxWxy8iAkSrarVr9K7lwE3At4BSVV0oIguARFW9raNj9cU6/rYamlu49t8rWbalmL/MncCs8f19HVLvUFUIa5+Czx+G8l0QNxBOuwPGz/F1ZMb4Ba/X8bsGbKl2fQx1TQpcCCxyrV+EM5yjXwsPCeafV05iclYStzy9hrc2fO3rkHqH2DSn2+cb18DcJyE2HV68Dl78PjRUd7q7MaZ7PFrHLyLBIrIGKALeVtVPgTRVLQBwzVM9GUNvERkWzKPzJzN6QDw/eGIVT3++y9ch9R5BwXDsefDdN2HGAlj7NPxzOuxZ6evIjPFLHk38qtqiqtnAQGCKiIxxd18RuW7/iF/FxcUei9GbYsJDePyaKUw7ph+3Pb+OP731VeC29mlPcAjMvN0Z97epDh4+HV7/KdS7PbyzMcYNXmvHLyK/BGqAa4FTVLVARDKAXFUd2dG+fb2O/3BNLa38/MV1PLMin4snDmThxWMJDbYGVoeor4B373Lq/2PT4ZjToGYfVBdCZBIcc7oz9Rtu7wQYcwRer+MXkRQRSXAtRwKnA5uAJcA812bzgJc9FUNvFRocxB8uHsfNpw/n+VX5fP8/K6lv8uNO3bojIh7Ouwe+9y7EDYAtb0PlHifpV+yGN293WgTdN8EpIAr9vG8kY3qQJ1v1jMN5eBuMU8A8o6q/FpFk4BkgE9gFXKqqpR0dy9/u+Nv6zyc7uePl9UwenMRD83KIjwz1dUh9Q1kebH3H6RJ6xwegrTBoKly2yPmFYIyxLht6s1fX7uXHT69hWEoM/7hyUmD17dMTqotg/fPw7q8hKhm+/QykjfJ1VMb4nCX+Xm7ZlmJ++ORqWlqVuy8Zx7ljM3wdUt+zdw08OQeaap33AerKoOhLaG6AE34IWdN8HaExXmWJvw/IL6vlh0+uZs3ucuafmMWCc44lIjTY12H1LeW7neRftMH5nJgFjbVQUwTDz3IKhHS3G5cZ06dZ4u8jGptbWfjfTTz64Q6G9ovm7kvGkZNl/dh3SVMdlGyFxCEQHuMk/s/+Ccv/DA1VTn9BM3/ufGeMH7PE38d8tHUfP31+LXvK65h/YhY/PmMEcRH24Peo1JbCe7+BFY9AfCac/ycYfoavozLGY6xb5j7mxGP68ebN07lq6mAe+yiPGXe/z6KP8mhqse6Muy0qyUn233kDQiPgiUvg/d/bQPEm4Ngdfx+wfk8Fv3t9Ix9tK2Fov2h+OWs0M0ak+Dqsvq25AV79Max5ArKvhAvuhWD7RWX8i1X19HGqyvtfFfGbVzeyfV8N545N5xfnjyIjPtLXofVdqpC7ED5Y6IwJPOZiiM2AuAzoNxJCwnwdoTFHxRK/n2hobuGhpdv563tbCQ4SrjphMN87aSgpseG+Dq3vWv04vPa/0Fx/cF1wOPSfAIOmwKT5zsDxxvQxlvj9zO7SWu5+8yteW7uX0OAg5k4exPdOHsqgpChfh9Y3NTc4/QBVFULFLtizCnZ/5owXDHD8/8CMnzpdSRjTR1ji91M79tXw99ytvLBqDwqcOzaD/5k+lDEDLEH1iKpCeO/XsPoJ563g4WdAwmBIyIQh0yFhkK8jNOaILPH7ub3ldfzrwx0s/mw31Q3NTMlKYt6JWZw5Os16/uwJe1c7zwO+XgeVewEFCYLhZ0LONU7voUH2sp3pXSzxB4jK+iae/mw3//4kj92ldaTFhTNnciaXThpo1UA9pbkRynbA2mdg1b+dt4L7T4RvPQT9jvF1dMYcYIk/wLS0KrlfFbHo450s2+IMZHPSMf24ZNJAzhyVTmSY3Z32iOZGp4O4NxZASyOc9TvnYbCNEWB6AUv8ASy/rJZnV+Tz7Ird7K2oJyY8hLPHpDM7ewBThyYRYlVBR69yL7z0A9ieC+ljnSqgYafCwCnWLNT4jCV+Q2ur8smOEl5avYfX131NdUMz/WLCOGdMBueNy2ByVhLBQXan2m2trbDyX04VUP7noC0QGgWZJ8CQk2HwNEgbDWHW7bbxDkv85hD1TS3kflXEK18U8O6mQuqbWukXE8aZo9M5a3Q6xw9Jsp5Bj0Z9BeQth+0fwI6lULzR9YVA8jEwYKLzq+CY0yEywZeRGj/m9cQvIoOAfwPpQCvwoKr+RUSSgKeBLCAPuExVyzo6liV+z6ppaCb3q2JeX1/A+5uKqG1sITI0mGnHJHPKyFRmjEixB8NHq6oQ9qx0WgV9vRZ2fQy1JRAU4vwiGHGW0220jSFsepAvEn8GkKGqq0QkFlgJzAbmA6WqulBEFgCJqnpbR8eyxO899U0tfLy9hPc3FfHepiLyy+oAGJYSzfQRKUwb1o/jhyYRaz2FHp3WFshfAZv/C5vfdAaMAacr6ZHnwrHnwaDjITjE2ba1xZ4VmC7zeVWPiLwM/M01naKqBa7CIVdVR3a0ryV+31BVtu+rIferYnK/KuKzHaU0NLcSHCSMGxjP8UOSOX5oEjmDE60gOFrlu5wCYPObzhjCLY0QEuH0J9TSAIhTPXTMGc5LZP0n2HsDplM+TfwikgUsBcYAu1Q1oc13Zaqa2NH+lvh7h/qmFlbtKuOjrSV8vL2EtfnlNLUowUHCmAHxnDA0mROHJTNpcCLR4SG+DrfvaqhyBpLf/bnTY2holFMQ7PjA+ZWAQkSC8+bwsFNh6Aznl4JVEZnD+Czxi0gM8AHwW1V9QUTK3Un8InIdcB1AZmbmpJ07d3o0TtN1dY1OQfDJ9hI+3lbCmt3lNLcqIa6C4PihSUwenMSkwYkkRls1RY+oLYVt78H292Hb+1C5x1kfnwlDp0PmiZA5FZKGWkFgfJP4RSQUeBV4U1X/5Fr3FVbV45dqG5tZkVfGpztK+HR7KV+4fhEAHJMaQ87gRCYOTmTS4ESGJEcTZE1Hj44q7Nvi/BLY8QHsWAb15c53Uf0gYxykHAspI50HyP1GWGEQYHzxcFeARTgPcm9us/7/gJI2D3eTVPWnHR3LEn/fVN/Uwtr8Cj7PK2VFXikrd5ZRWd8MQGxECGP6xzNuYDwTMhOYODiR1NgIH0fcx7W2wr6vYPenTs+ihRtg32ZoqnW+TxoGI89xWhANOh5CrCtvf+eLxH8SsAxYh9OcE+BnwKfAM0AmsAu4VFVLOzqWJX7/0NqqbN9XzcqdZazNr2D9ngo2FlTR6BpOclBSJBMGJTJ+UALZgxIYlRFnXUscrdZWKM9zqoc2ve68U9DaBCGRMPgEGHoKDJ0JaWMgyN7g9jc+b9VzNCzx+6/G5lbW761g1c4yVuSV8UV+OQUVzoAoQeJUEY3uH8/o/nGMG5jA6P5x9uD4aDRUQd6HTtcS29+H4k3O+qh+B98uHjzNqSKygqDPs8Rv+ozCynpW7ypnw94KNuytZP2eCoqqGgCninpIv2hGZcQxun88o/rHMSojzkYg667KgoOFQN7ygw+LQ6OdMQcSMp03jbOmweATIbLDBniml7HEb/q0oqp61u+pYF1+5YECYU953YHvU2LDOS4jjuMyYhmVEcex6XEMTYm2sQi6QhXK8mDnh84bxuW7nfcLSra4hqUUSB/jtBwafIIzj03zddSmA5b4jd+pqG3iy4JKZ9rrzLcWVR1oSRQWHMTwtBiOy4hjZFosI9JjOTY9ltTYcMRat7ivucF5fyBvOexc7iw31QICWSfBuDkw6sKD7xtoK4TH+DpqgyV+EyCaWlrZVlzNxoJKNhVU8WVBJZu+rqLYVVUEEB8Zysi0WIanxTAyPZbhqbGMSIshOcaqi9zS0gQFa52XzNY+BaXbv7lNVDKkHAdpo2DiPOeXgvE6S/wmoJXWNLK5sIqvvq5ic2HVgeX9zUsBkqPDGJ4Ww4i0WIanxjAsNYZjUmNIibFfCEek6nQ+t+09QJw3jVGnMCja5DQpbaqF8ZfDzJ/ZGMVeZonfmMOoKkVVDYcUBluKqtlSWE11w8ECIT4ylGEp0RyTGsOwFKcwOCY1hoGJUTZ+QWfqymDZn+DTfzqfjz0XjrvA6ZI6PNa3sQUAS/zGuElVKaxsYEtRFVuLqtlaVM224mq2FtWwr/pglVFYSBBDkqMZlhrNsJQYhqbsn8cQY01OD1W+G5b/GTYugZpiCA5zupYYMsN5lyBhsNP7aEiEvVjWgyzxG9MDKmqb2FpczTZXYeAUCNXsKq2ltc1/pdTYcIamRDOkXwxD+kUxODmarORoMpOiAvultNYW563iTa86zUgL139zm34jYfxc56Fx/ACvh+hPLPEb40ENzS3sKqllW3EN2/dVs724hu3F1ezYV0NZbdMh26bFhbsKgoMFwuDkKAYlRREfGWDdW9fsc1oL1RQ7rYeaap3nBbs+BsTpXmLazU7zUdNllviN8ZGK2iZ2ltawY18Nu0pqySupZWdJDTtLaw9pbQSQEBXK4KQoMpOjGZwUxaCkSAYlOoVCRnwEIYHyXkLJNvhiMXz+CNSVOp3MjZsDcQOcdwcSMu1lMjdY4jemF6ppaGZnSS27SmvYVVrrWnbme8rraGlTfxQcJPRPiHAKgsQoBiZGMijJmQ9IjCQ1NsL/HjY31sCq/8BHf4XK/EO/ix8E6eOcQWmyToIBk2yUssNY4jemj2luaaWgop7dpbXsLqtld2mda17L7rK6b/xaCA0WMuIj6Z8QwYCEKAYkRjIgIYL+CZHOFB/Zd58vtLY43UlUfe1Mpdtc4xevc7qmRp0XyAYd7xQCWSdB/4kBXxAcKfFb0wNjeqmQ4CAGJUUdcaD7+qYW8stqyS+rI7+sjj3ldewpq2NveR0fbdtHYWX9IQ+cARKjQg8UDhnxkWQkRNA/PpL0eGeeFh9OeEgvLByCgg/2HXS42lKnm4kdyyBvGbx3l7M+JAIyxsOAHGcem+Z0RheTCtEpAT02gd3xG+OnmlpaKaysdwqDijr2ltezp7yOgvI6CirqKaiop6Ku6Rv79YsJIyM+krS4CDLiI0iPbzuPJD0uonf/cqgpcQqCXR/DnlVQsMbV11AbkYlOV9RpYyB5mNOcNHEwxA+EsGifhO0JVtVjjPmG2sZm9pbXU1DhKgzK6/m60ikkCiuPXDjERYSQHh9Benwk6XHhpMe5luPDSYuLID0ugqTosN7xxnNLk/MmcXUR1JY4VUVFXzpNSYs2HhyoZr/IRIgb6DQljRvgzGPSnV8J0f2cXx1RyX3iF4NV9RhjviEqLOTAm8hHUtfYwteVrsKhvJ6vKw8WCoWV9WwqqKS4uoHD7yHDgoNIiQ13Coi4CKdAiA8nNTaC1LiD89jwEM8WEMGhzvCTKe2M8KrqFAhleVC+Eyp2Q8Ue53lCxR5nNLO6sm/uF5HgdFedkAkxaU41UkwaxKY7hURsurNNLx3TwJMjcD0KnA8UqeoY17ok4GkgC8gDLlPVdv5UD2V3/Mb0bk0trRRXNTiFQoVTOOxfLqxsOFBQ1DW1fGPfyNBgUmLDSY0NJzUunJSYcFJinalfjGuKDadfTJhvnj801kJNEVQXO/OyPCjZ6jxUrtzjFByN1d/cLygEolMhJsX1a8H1iyHGVUhE94PIJIhKcn5BeKCKyRdDL04HqoF/t0n8d+OMwbt/vN1EVb2ts2NZ4jem71NVqhuaKaxsoKiynqKqBoqq6imqbKC4uoGiSudzcVXDIZ3ntRUbHkJyTBjJMU5BkBwTTnJ0GEnRB5cTo8JIjnHmYSFeuuNuqIbqQmeqKoCqwkMLi5pi52W16iJoaWj/GCGRTmEQ3c8pCKJc80nz2v+14gavV/Wo6lIRyTps9YXAKa7lRUAu0GniN8b0fSJCbEQosRGhHVYtgdNiqbiqgZKaRvZVNbCv2lluu27HvhpW5JVRWtv4jWqm/WIjQkhyFQaJUaEktrOcEBVKQmQYidHOPCI0qOtVT+ExzpQ8rOPtVKGh0ikAqoucl9PqypxnDzX72sz3wb7NzoPqEWd1O/Efibfr+NNUtQBAVQtEJNXL5zfG9AERocEdNmVtq6VVKa9tpLSmkZKaNvPqRspqnam0ppHi6gY2F1ZTVttIbeM3q5z2CwsJIiEylISoUOIjQ4mPDGuzfHCKiwxx5hGhxLnWhYd0UmiIQES8M/Ub7t4fhgdqZXrtw10RuQ64DiAzs522u8YYg/NGc3JMOMkx4biZSqlvaqG8tomy2kbKa5sor22krLaJiromyusaKa9xlivqmsgvq+XLvc5yTQcFBjgv0e0vCOIiQly/cEJcU+ih83BnOSYihJhwZ5uY8BCiwoIPLTw88ODb24m/UEQyXHf7GUDRkTZU1QeBB8Gp4/dWgMYY/xcRGkx6fDDp8RFd2q+xuZWq+oOFQmV984HlqvomKuuanXm9a17XxNeV9VTVN1FV39zhL439RCAmLITo8BCiw4P53UVjOX5ocncvtV3eTvxLgHnAQtf8ZS+f3xhjui0sJOjAr4vuaG5ppaahhUpXQVDT2HygUKhpaKG6oYnq+maqXcs1DS3ERvR8j60eS/wishjnQW4/EckHfomT8J8RkWuAXcClnjq/Mcb0NiHBQcRHBREf5dvutz3ZqufyI3x1mqfOaYwxpnO987UyY4wxHmOJ3xhjAowlfmOMCTCW+I0xJsBY4jfGmABjid8YYwKMJX5jjAkwfWIELhEpBnZ2c/d+wL4eDKevCMTrDsRrhsC87kC8Zuj6dQ9W1ZTDV/aJxH80RGRFe/1R+7tAvO5AvGYIzOsOxGuGnrtuq+oxxpgAY4nfGGMCTCAk/gd9HYCPBOJ1B+I1Q2BedyBeM/TQdft9Hb8xxphDBcIdvzHGmDYs8RtjTIDx68QvImeLyFcislVEFvg6Hk8QkUEi8r6IbBSRDSJyk2t9koi8LSJbXPNEX8fa00QkWERWi8irrs+BcM0JIvKciGxy/Z2f4O/XLSI/dv3bXi8ii0Ukwh+vWUQeFZEiEVnfZt0Rr1NEbnfltq9E5KyunMtvE7+IBAP3A+cAo4DLRWSUb6PyiGbgf1X1OGAqcIPrOhcA76rqcOBd12d/cxOwsc3nQLjmvwBvqOqxwHic6/fb6xaRAcCNQI6qjgGCgbn45zU/Bpx92Lp2r9P1f3wuMNq1zwOunOcWv038wBRgq6puV9VG4CngQh/H1ONUtUBVV7mWq3ASwQCca13k2mwRMNsnAXqIiAwEzgMebrPa3685DpgOPAKgqo2qWo6fXzfOSIGRIhICRAF78cNrVtWlQOlhq490nRcCT6lqg6ruALbi5Dy3+HPiHwDsbvM537XOb4lIFjAB+BRIU9UCcAoHINWHoXnCvcBPgdY26/z9mocCxcC/XFVcD4tINH583aq6B7gHZ4zuAqBCVd/Cj6/5MEe6zqPKb/6c+KWddX7bdlVEYoDngZtVtdLX8XiSiJwPFKnqSl/H4mUhwETg76o6AajBP6o4jshVp30hMAToD0SLyJW+japXOKr85s+JPx8Y1ObzQJyfiH5HREJxkv4TqvqCa3WhiGS4vs8AinwVnwdMA2aJSB5OFd6pIvI4/n3N4PybzlfVT12fn8MpCPz5uk8Hdqhqsao2AS8AJ+Lf19zWka7zqPKbPyf+z4HhIjJERMJwHoQs8XFMPU5EBKfOd6Oq/qnNV0uAea7lecDL3o7NU1T1dlUdqKpZOH+v76nqlfjxNQOo6tfAbhEZ6Vp1GvAl/n3du4CpIhLl+rd+Gs5zLH++5raOdJ1LgLkiEi4iQ4DhwGduH1VV/XYCzgU2A9uAn/s6Hg9d40k4P/HWAmtc07lAMk4rgC2ueZKvY/XQ9Z8CvOpa9vtrBrKBFa6/75eARH+/buBXwCZgPfAfINwfrxlYjPMcownnjv6ajq4T+Lkrt30FnNOVc1mXDcYYE2D8uarHGGNMOyzxG2NMgLHEb4wxAcYSvzHGBBhL/MYYE2As8RsDiEiLiKxpM/XYG7EiktW2x0VjfC3E1wEY00vUqWq2r4Mwxhvsjt+YDohInoj8QUQ+c03HuNYPFpF3RWSta57pWp8mIi+KyBeu6UTXoYJF5CFXv/JviUikzy7KBDxL/MY4Ig+r6pnT5rtKVZ0C/A2nV1Bcy/9W1XHAE8B9rvX3AR+o6nicfnQ2uNYPB+5X1dFAOXCxR6/GmA7Ym7vGACJSraox7azPA05V1e2uzvC+VtVkEdkHZKhqk2t9gar2E5FiYKCqNrQ5RhbwtjqDaSAitwGhqvobL1yaMd9gd/zGdE6PsHykbdrT0Ga5BXu+ZnzIEr8xnZvTZv6xa/kjnJ5BAa4AlruW3wV+AAfGBI7zVpDGuMvuOoxxRIrImjaf31DV/U06w0XkU5wbpctd624EHhWRW3FGxfqOa/1NwIMicg3Onf0PcHpcNKbXsDp+YzrgquPPUdV9vo7FmJ5iVT3GGBNg7I7fGGMCjN3xG2NMgLHEb4wxAcYSvzHGBBhL/MYYE2As8RtjTID5//YONdKexdzIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# f, ax = plt.subplots()\n",
    "plt.plot(range(len(ali_dd_losses)), ali_dd_losses, label='Ali Data Driven train loss')\n",
    "plt.plot(range(len(ali_dd_val_losses)), ali_dd_val_losses, label='Ali Data Driven val loss')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.ylim(0,500)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "plt.savefig('Ali_DD_loss_26Mar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 10.5396\n"
     ]
    }
   ],
   "source": [
    "ali_dd_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "ali_dd_model.modify_graphgather(len(y_test))\n",
    "ali_dd_test_loss = ali_dd_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "# calculate RMSE\n",
    "# ali_dd_rmse_test = np.sqrt(ali_dd_test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_dd_rmse_test = ali_dd_test_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average training loss\n",
    "# ali_dd_rmse_loss = [sum(x)/len(x) for x in zip(*ali_dd_losses)]\n",
    "ali_dd_rmse_loss = ali_dd_losses[-1]\n",
    "# ali_dd_rmse_train = math.sqrt(ali_dd_test_loss)\n",
    "ali_dd_rmse_train = ali_dd_rmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.05095386505127]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_dd_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ali_dd_test_accuracy = ali_dd_rmse_test\n",
    "# ali_dd_train_accuracy = ali_dd_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.246477712606718"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_dd_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "| Ali's model Test Set RMSE |\n",
      "+------------------+--------+\n",
      "|   Data Driven    |  PGNN  |\n",
      "+------------------+--------+\n",
      "|       3.25       |  6.36  |\n",
      "+------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Ali's model Test Set RMSE\"\n",
    "rmse_table.field_names = [ \"Data Driven\", \"PGNN\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(ali_dd_rmse_test),\"{:.2f}\".format(ali_pgnn_rmse_test)])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40.78380676269531]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali_pgnn_rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "| Ali's model Train Set RMSE |\n",
      "+-----------------+---------+\n",
      "|   Data Driven   |   PGNN  |\n",
      "+-----------------+---------+\n",
      "|      19.44      |  40.78  |\n",
      "+-----------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Ali's model Train Set RMSE\"\n",
    "rmse_table.field_names = [\"Data Driven\", \"PGNN\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(ali_dd_rmse_train[0]),\"{:.2f}\".format(ali_pgnn_rmse_train[0])])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|              All Models Comparison Training Set             |\n",
      "+-------------------+------------+-----------------+----------+\n",
      "| Sahar Data Driven | Sahar PGNN | Ali Data Driven | Ali PGNN |\n",
      "+-------------------+------------+-----------------+----------+\n",
      "|        2.90       |    3.69    |       9.05      |  37.28   |\n",
      "+-------------------+------------+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"All Models Comparison Training Set\"\n",
    "rmse_table.field_names = [\"Sahar Data Driven\", \"Sahar PGNN\", \"Ali Data Driven\", \"Ali PGNN\"]\n",
    "rmse_table.add_row([ \"{:.2f}\".format(sahar_dd_rmse_train),\"{:.2f}\".format(sahar_pgnn_rmse_train),\n",
    "                    \"{:.2f}\".format(ali_dd_rmse_train[0]),\"{:.2f}\".format(ali_pgnn_rmse_train[0])])\n",
    "\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|              All Models Comparison Testing Set              |\n",
      "+-------------------+------------+-----------------+----------+\n",
      "| Sahar Data Driven | Sahar PGNN | Ali Data Driven | Ali PGNN |\n",
      "+-------------------+------------+-----------------+----------+\n",
      "|        8.45       |    4.49    |      10.54      |  40.48   |\n",
      "+-------------------+------------+-----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"All Models Comparison Testing Set\"\n",
    "rmse_table.field_names = [\"Sahar Data Driven\", \"Sahar PGNN\", \"Ali Data Driven\", \"Ali PGNN\"]\n",
    "rmse_table.add_row([ \"{:.2f}\".format(sahar_dd_rmse_test),\"{:.2f}\".format(sahar_pgnn_rmse_test),\n",
    "                    \"{:.2f}\".format(ali_dd_rmse_test),\"{:.2f}\".format(ali_pgnn_rmse_test)])\n",
    "print(rmse_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-deepchem-jupyter",
   "language": "python",
   "name": "rdkit-deepchem-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
